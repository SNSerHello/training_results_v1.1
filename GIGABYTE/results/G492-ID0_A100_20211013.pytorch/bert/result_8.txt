+ echo 'Beginning trial 4 of 5'
Beginning trial 4 of 5
+ docker exec -it language_model python -c '
import mlperf_logger 
from mlperf_logging.mllog import constants 
mlperf_logger.mlperf_submission_log(constants.BERT)'
+ '[' 1 -eq 1 ']'
+ sync
+ sudo /sbin/sysctl vm.drop_caches=3
vm.drop_caches = 3
+ docker exec -it language_model python -c '
from mlperf_logging.mllog import constants 
from mlperf_logger import log_event 
log_event(key=constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1634634204913, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ docker exec -it --env=BATCHSIZE --env=CHECKPOINTDIR --env=CHECKPOINTDIR_PHASE1 --env=DATADIR --env=DATADIR_PHASE2 --env=DGXHT --env=DGXNGPU --env=DGXNNODES --env=DGXNSOCKET --env=DGXSOCKETCORES --env=DGXSYSTEM --env=EVALDIR --env=EVAL_ITER_SAMPLES --env=EVAL_ITER_START_SAMPLES --env=EXTRA_PARAMS --env=GRADIENT_STEPS --env=LR --env=MAX_SAMPLES_TERMINATION --env=MAX_STEPS --env=OPT_LAMB_BETA_1 --env=OPT_LAMB_BETA_2 --env=PHASE --env=SLURM_NTASKS --env=START_WARMUP_STEP --env=UNITTESTDIR --env=WALLTIME --env=WARMUP_PROPORTION --env=SEED language_model sh -c ./run_and_time.sh
Run vars: id 30902 gpus 8 mparams ''
STARTING TIMING RUN AT 2021-10-19 09:03:25 AM
:::MLLOG {"namespace": "", "time_ms": 1634634207528, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1634634207598, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1634634207658, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1634634207673, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1634634207684, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1634634207697, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1634634207703, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1634634207707, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
device: cuda:0 n_gpu: 8, distributed training: True, 16-bits training: True
device: cuda:6 n_gpu: 8, distributed training: True, 16-bits training: True
:::MLLOG {"namespace": "", "time_ms": 1634634208779, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 66}}
:::MLLOG {"namespace": "", "time_ms": 1634634208780, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "GIGABYTE", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 71}}
:::MLLOG {"namespace": "", "time_ms": 1634634208780, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1634634208780, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 79}}
:::MLLOG {"namespace": "", "time_ms": 1634634208780, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "NVIDIA_DGX_A100", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 83}}
:::MLLOG {"namespace": "", "time_ms": 1634634208780, "event_type": "POINT_IN_TIME", "key": "seed", "value": 12370, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1095}}
:::MLLOG {"namespace": "", "time_ms": 1634634208780, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 448, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1097}}
:::MLLOG {"namespace": "", "time_ms": 1634634208780, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 56, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1099}}
:::MLLOG {"namespace": "", "time_ms": 1634634208780, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1101}}
:::MLLOG {"namespace": "", "time_ms": 1634634208780, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1103}}
:::MLLOG {"namespace": "", "time_ms": 1634634208780, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 7100.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1105}}
:::MLLOG {"namespace": "", "time_ms": 1634634208780, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1107}}
parsed args:
Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=150000, eval_iter_start_samples=150000, exchange_padding=True, fp16=True, fused_bias_fc=True, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_mha=False, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.00035, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=7100.0, min_samples_to_start_checkpoints=3000000, n_gpu=8, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.9, opt_lamb_beta_2=0.999, output_dir='/results', pad=False, pad_fmha=False, phase2=True, resume_from_checkpoint=False, seed=12370, skip_checkpoint=True, start_warmup_step=0.0, target_mlm_accuracy=0.72, train_batch_size=56, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=0.0, weight_decay_rate=0.01)
device: cuda:4 n_gpu: 8, distributed training: True, 16-bits training: True
device: cuda:2 n_gpu: 8, distributed training: True, 16-bits training: True
device: cuda:7 n_gpu: 8, distributed training: True, 16-bits training: True
device: cuda:1 n_gpu: 8, distributed training: True, 16-bits training: True
device: cuda:3 n_gpu: 8, distributed training: True, 16-bits training: True
device: cuda:5 n_gpu: 8, distributed training: True, 16-bits training: True
:::MLLOG {"namespace": "", "time_ms": 1634634215089, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.00035, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 699}}
:::MLLOG {"namespace": "", "time_ms": 1634634222340, "event_type": "POINT_IN_TIME", "key": "opt_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 731}}
:::MLLOG {"namespace": "", "time_ms": 1634634222340, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.9, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 734}}
:::MLLOG {"namespace": "", "time_ms": 1634634222341, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.999, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 735}}
:::MLLOG {"namespace": "", "time_ms": 1634634222341, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 736}}
:::MLLOG {"namespace": "", "time_ms": 1634634222356, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1634634222357, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 87}}
:::MLLOG {"namespace": "", "time_ms": 1634634222357, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 88}}
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
:::MLLOG {"namespace": "", "time_ms": 1634634233562, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1370}}
:::MLLOG {"namespace": "", "time_ms": 1634634233563, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1371}}
:::MLLOG {"namespace": "", "time_ms": 1634634233586, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1382, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634634233589, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1384, "first_epoch_num": 1, "epoch_count": 1}}
parsed args:
Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=150000, eval_iter_start_samples=150000, exchange_padding=True, fp16=True, fused_bias_fc=True, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_mha=False, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.00035, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=7100.0, min_samples_to_start_checkpoints=3000000, n_gpu=8, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.9, opt_lamb_beta_2=0.999, output_dir='/results', pad=False, pad_fmha=False, phase2=True, resume_from_checkpoint=False, resume_step=0, seed=12370, skip_checkpoint=True, start_warmup_step=0.0, target_mlm_accuracy=0.72, train_batch_size=56, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=0.0, weight_decay_rate=0.01)
epoch: 1
:::MLLOG {"namespace": "", "time_ms": 1634634357199, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3714292347431183, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 335, 'eval_loss': 4.122872829437256, 'eval_mlm_accuracy': 0.3714292347431183}
:::MLLOG {"namespace": "", "time_ms": 1634634476994, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.39405232667922974, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 670, 'eval_loss': 3.9067249298095703, 'eval_mlm_accuracy': 0.39405232667922974}
:::MLLOG {"namespace": "", "time_ms": 1634634596834, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.4699452519416809, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 1005, 'eval_loss': 3.25178599357605, 'eval_mlm_accuracy': 0.4699452519416809}
:::MLLOG {"namespace": "", "time_ms": 1634634716670, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5668990015983582, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 1340, 'eval_loss': 2.4305508136749268, 'eval_mlm_accuracy': 0.5668990015983582}
:::MLLOG {"namespace": "", "time_ms": 1634634836243, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.669828474521637, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 1675, 'eval_loss': 1.6462234258651733, 'eval_mlm_accuracy': 0.669828474521637}
:::MLLOG {"namespace": "", "time_ms": 1634634955189, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.702254593372345, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 2009, 'eval_loss': 1.4201782941818237, 'eval_mlm_accuracy': 0.702254593372345}
:::MLLOG {"namespace": "", "time_ms": 1634635074672, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7072378396987915, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 2344, 'eval_loss': 1.3878954648971558, 'eval_mlm_accuracy': 0.7072378396987915}
:::MLLOG {"namespace": "", "time_ms": 1634635194087, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7097014784812927, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 2679, 'eval_loss': 1.3685064315795898, 'eval_mlm_accuracy': 0.7097014784812927}
:::MLLOG {"namespace": "", "time_ms": 1634635313889, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7120366096496582, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 3014, 'eval_loss': 1.3558954000473022, 'eval_mlm_accuracy': 0.7120366096496582}
:::MLLOG {"namespace": "", "time_ms": 1634635433444, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7135918140411377, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 3349, 'eval_loss': 1.3444780111312866, 'eval_mlm_accuracy': 0.7135918140411377}
:::MLLOG {"namespace": "", "time_ms": 1634635552996, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7144021391868591, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 3684, 'eval_loss': 1.3410007953643799, 'eval_mlm_accuracy': 0.7144021391868591}
:::MLLOG {"namespace": "", "time_ms": 1634635672264, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7152894735336304, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 4018, 'eval_loss': 1.332502007484436, 'eval_mlm_accuracy': 0.7152894735336304}
:::MLLOG {"namespace": "", "time_ms": 1634635792347, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7162142395973206, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 4353, 'eval_loss': 1.3291939496994019, 'eval_mlm_accuracy': 0.7162142395973206}
:::MLLOG {"namespace": "", "time_ms": 1634635912148, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7168143391609192, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 4688, 'eval_loss': 1.3227933645248413, 'eval_mlm_accuracy': 0.7168143391609192}
:::MLLOG {"namespace": "", "time_ms": 1634636031952, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7173187732696533, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 5023, 'eval_loss': 1.3193535804748535, 'eval_mlm_accuracy': 0.7173187732696533}
:::MLLOG {"namespace": "", "time_ms": 1634636151759, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7178184986114502, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 5358, 'eval_loss': 1.3173162937164307, 'eval_mlm_accuracy': 0.7178184986114502}
:::MLLOG {"namespace": "", "time_ms": 1634636271591, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7188459634780884, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 5692, 'eval_loss': 1.3121660947799683, 'eval_mlm_accuracy': 0.7188459634780884}
:::MLLOG {"namespace": "", "time_ms": 1634636391497, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7193783521652222, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 6027, 'eval_loss': 1.3105173110961914, 'eval_mlm_accuracy': 0.7193783521652222}
:::MLLOG {"namespace": "", "time_ms": 1634636511451, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7195441722869873, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 6362, 'eval_loss': 1.3069524765014648, 'eval_mlm_accuracy': 0.7195441722869873}
:::MLLOG {"namespace": "", "time_ms": 1634636631347, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7199855446815491, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 6697, 'eval_loss': 1.3053001165390015, 'eval_mlm_accuracy': 0.7199855446815491}
:::MLLOG {"namespace": "", "time_ms": 1634636751780, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7200672626495361, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 7032, 'eval_loss': 1.3047475814819336, 'eval_mlm_accuracy': 0.7200672626495361}
0.720067 > 0.720000, Target MLM Accuracy reached at 7032
(1, 7040.0) {'final_loss': 0.0}
:::MLLOG {"namespace": "", "time_ms": 1634636751820, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1710, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634636751820, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1713, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634636751820, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 3150336, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1726}}
:::MLLOG {"namespace": "", "time_ms": 1634636751820, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1729}}
:::MLLOG {"namespace": "", "time_ms": 1634636751820, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1732, "status": "success"}}
{'e2e_time': 2544.154210329056, 'training_sequences_per_second': 1258.2081624938041, 'final_loss': 0.0, 'raw_train_time': 2528.03955245018}
ENDING TIMING RUN AT 2021-10-19 09:45:54 AM
RESULT,bert,12370,2549,,2021-10-19 09:03:25 AM
