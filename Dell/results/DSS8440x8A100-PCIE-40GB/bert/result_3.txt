+ echo 'Beginning trial 3 of 10'
Beginning trial 3 of 10
+ docker exec -it language_model python -c '
import mlperf_logger 
from mlperf_logging.mllog import constants 
mlperf_logger.mlperf_submission_log(constants.BERT)'
:::MLLOG {"namespace": "", "time_ms": 1635299917579, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 66}}
:::MLLOG {"namespace": "", "time_ms": 1635299917599, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 71}}
:::MLLOG {"namespace": "", "time_ms": 1635299917599, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1635299917600, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 79}}
:::MLLOG {"namespace": "", "time_ms": 1635299917600, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xDSS8440x8A100-PCIE-40GB", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 83}}
+ '[' 1 -eq 1 ']'
+ sync
+ sudo /sbin/sysctl vm.drop_caches=3
vm.drop_caches = 3
+ docker exec -it language_model python -c '
from mlperf_logging.mllog import constants 
from mlperf_logger import log_event 
log_event(key=constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1635299937770, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ docker exec -it --env=BATCHSIZE --env=CUDA_VISIBLE_DEVICES --env=DGXHT --env=DGXNGPU --env=DGXNNODES --env=DGXNSOCKET --env=DGXSOCKETCORES --env=DGXSYSTEM --env=EVAL_ITER_SAMPLES --env=EVAL_ITER_START_SAMPLES --env=EXTRA_PARAMS --env=GRADIENT_STEPS --env=LR --env=MAX_SAMPLES_TERMINATION --env=MAX_STEPS --env=NCCL_P2P_LEVEL --env=NCCL_SOCKET_IFNAME --env=OPT_LAMB_BETA_1 --env=OPT_LAMB_BETA_2 --env=PHASE --env=SLURM_NTASKS --env=START_WARMUP_STEP --env=WALLTIME --env=WARMUP_PROPORTION --env=SEED language_model sh -c ./run_and_time.sh
+ '[' '' = 1 ']'
+ : 48
+ : 1
+ : 3.5e-4
+ : 15000
+ : 2
+ : ''
+ : ''
+ : ''\'''\'''
+ : ''
+ : 4285
+ : 3351
+ : ''
+ : 0
+ : ''
+ : ''
+ : 0
+ : 150000
+ : 150000
+ : 4500000
+ : 0.9
+ : 0.999
+ : 0
+ : 0.720
+ : 0
+ : 0.0
+ : 0.0
+ : 0.01
+ echo 'Run vars: id 3351 gpus  mparams '\'''\'''
Run vars: id 3351 gpus  mparams ''
++ date +%s
+ START=1635299938
++ date '+%Y-%m-%d %r'
+ START_FMT='2021-10-27 01:58:58 AM'
+ echo 'STARTING TIMING RUN AT 2021-10-27 01:58:58 AM'
STARTING TIMING RUN AT 2021-10-27 01:58:58 AM
+ '[' '!' -z '' ']'
+ PHASE1='    --train_batch_size=48     --learning_rate=3.5e-4     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
+ PHASE2='    --train_batch_size=48     --learning_rate=3.5e-4     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=15000     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
+ PHASES=("$PHASE1" "$PHASE2")
+ cluster=
+ [[ DSS8440x8A100-PCIE-40GB == DGX2* ]]
+ [[ DSS8440x8A100-PCIE-40GB == DGXA100* ]]
+ source ./config_DSS8440x8A100-PCIE-40GB.sh
++ export BATCHSIZE=48
++ BATCHSIZE=48
++ export GRADIENT_STEPS=1
++ GRADIENT_STEPS=1
++ export LR=3.5e-4
++ LR=3.5e-4
++ export MAX_SAMPLES_TERMINATION=4500000
++ MAX_SAMPLES_TERMINATION=4500000
++ export MAX_STEPS=15000
++ MAX_STEPS=15000
++ export OPT_LAMB_BETA_1=0.9
++ OPT_LAMB_BETA_1=0.9
++ export OPT_LAMB_BETA_2=0.999
++ OPT_LAMB_BETA_2=0.999
++ export START_WARMUP_STEP=0
++ START_WARMUP_STEP=0
++ export WARMUP_PROPORTION=0.0
++ WARMUP_PROPORTION=0.0
++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding'
++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding'
++ export PHASE=2
++ PHASE=2
++ export EVAL_ITER_START_SAMPLES=150000
++ EVAL_ITER_START_SAMPLES=150000
++ export EVAL_ITER_SAMPLES=150000
++ EVAL_ITER_SAMPLES=150000
++ export DGXNNODES=1
++ DGXNNODES=1
+++ sed 's/^config_//'
+++ sed 's/\.sh$//'
++++ readlink -f ./config_DSS8440x8A100-PCIE-40GB.sh
+++ basename /workspace/bert/config_DSS8440x8A100-PCIE-40GB.sh
++ export DGXSYSTEM=DSS8440x8A100-PCIE-40GB
++ DGXSYSTEM=DSS8440x8A100-PCIE-40GB
++ export WALLTIME=01:15:00
++ WALLTIME=01:15:00
++ source ./config_DSS8440x8A100-PCIE-40GB_common.sh
+++ export DGXNGPU=8
+++ DGXNGPU=8
+++ export DGXSOCKETCORES=24
+++ DGXSOCKETCORES=24
+++ export DGXNSOCKET=2
+++ DGXNSOCKET=2
+++ export DGXHT=2
+++ DGXHT=2
+++ export SLURM_NTASKS=8
+++ SLURM_NTASKS=8
+++ export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
+++ CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
+++ export NCCL_SOCKET_IFNAME=
+++ NCCL_SOCKET_IFNAME=
+++ export NCCL_P2P_LEVEL=1
+++ NCCL_P2P_LEVEL=1
++ export NCCL_DEBUG=INFO
++ NCCL_DEBUG=INFO
+ declare -a CMD
+ '[' -n '' ']'
+ CMD=('python' '-u' '-m' 'bind_pyt' "--nsockets_per_node=${DGXNSOCKET}" "--ncores_per_socket=${DGXSOCKETCORES}" "--nproc_per_node=${DGXNGPU}")
+ BERT_CMD='    python -u -m bind_pyt --nsockets_per_node=2 --ncores_per_socket=24 --nproc_per_node=8          /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=3.5e-4     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=15000     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16 --fused_bias_fc --fused_bias_mha --fused_dropout_add     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_config.json '
+ '[' -n '' ']'
+ [[ 0 != 1 ]]
+ BERT_CMD='    python -u -m bind_pyt --nsockets_per_node=2 --ncores_per_socket=24 --nproc_per_node=8          /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=3.5e-4     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=15000     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16 --fused_bias_fc --fused_bias_mha --fused_dropout_add     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_config.json  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
+ BERT_CMD='    python -u -m bind_pyt --nsockets_per_node=2 --ncores_per_socket=24 --nproc_per_node=8          /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=3.5e-4     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=15000     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16 --fused_bias_fc --fused_bias_mha --fused_dropout_add     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_config.json  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding '
+ [[ 0 != 0 ]]
+ '[' '' = apiLog.sh ']'
+ '[' '' = 1 ']'
+ eval '     python -u -m bind_pyt --nsockets_per_node=2 --ncores_per_socket=24 --nproc_per_node=8          /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=3.5e-4     --opt_lamb_beta_1=0.9     --opt_lamb_beta_2=0.999     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=15000     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=150000 --eval_iter_samples=150000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16 --fused_bias_fc --fused_bias_mha --fused_dropout_add     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_config.json  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding  --seed=4285'
++ python -u -m bind_pyt --nsockets_per_node=2 --ncores_per_socket=24 --nproc_per_node=8 /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=3.5e-4 --opt_lamb_beta_1=0.9 --opt_lamb_beta_2=0.999 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=15000 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=150000 --eval_iter_samples=150000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --fused_bias_fc --fused_bias_mha --fused_dropout_add --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dense_seq_output --unpad --unpad_fmha --exchange_padding --seed=4285
:::MLLOG {"namespace": "", "time_ms": 1635299940352, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635299940352, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635299940352, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635299940407, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635299940429, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635299940440, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635299940447, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635299940453, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
device: cuda:0 n_gpu: 8, distributed training: True, 16-bits training: True
:::MLLOG {"namespace": "", "time_ms": 1635299941466, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 66}}
:::MLLOG {"namespace": "", "time_ms": 1635299941466, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 71}}
:::MLLOG {"namespace": "", "time_ms": 1635299941466, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1635299941467, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 79}}
:::MLLOG {"namespace": "", "time_ms": 1635299941467, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xDSS8440x8A100-PCIE-40GB", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 83}}
:::MLLOG {"namespace": "", "time_ms": 1635299941467, "event_type": "POINT_IN_TIME", "key": "seed", "value": 4285, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1095}}
:::MLLOG {"namespace": "", "time_ms": 1635299941467, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 384, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1097}}
:::MLLOG {"namespace": "", "time_ms": 1635299941467, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 48, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1099}}
:::MLLOG {"namespace": "", "time_ms": 1635299941467, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1101}}
:::MLLOG {"namespace": "", "time_ms": 1635299941467, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1103}}
:::MLLOG {"namespace": "", "time_ms": 1635299941467, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 15000.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1105}}
:::MLLOG {"namespace": "", "time_ms": 1635299941467, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1107}}
parsed args:
Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=150000, eval_iter_start_samples=150000, exchange_padding=True, fp16=True, fused_bias_fc=True, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_mha=False, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.00035, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=15000.0, min_samples_to_start_checkpoints=3000000, n_gpu=8, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.9, opt_lamb_beta_2=0.999, output_dir='/results', pad=False, pad_fmha=False, phase2=True, resume_from_checkpoint=False, seed=4285, skip_checkpoint=True, start_warmup_step=0.0, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=0.0, weight_decay_rate=0.01)
device: cuda:2 n_gpu: 8, distributed training: True, 16-bits training: True
device: cuda:6 n_gpu: 8, distributed training: True, 16-bits training: True
device: cuda:7 n_gpu: 8, distributed training: True, 16-bits training: True
device: cuda:3 n_gpu: 8, distributed training: True, 16-bits training: True
device: cuda:4 n_gpu: 8, distributed training: True, 16-bits training: True
device: cuda:5 n_gpu: 8, distributed training: True, 16-bits training: True
device: cuda:1 n_gpu: 8, distributed training: True, 16-bits training: True
:::MLLOG {"namespace": "", "time_ms": 1635299950499, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.00035, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 699}}
node071:13376:13376 [0] NCCL INFO Bootstrap : Using eth0:10.141.0.71<0>
node071:13376:13376 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
node071:13376:13376 [0] NCCL INFO P2P plugin IBext
node071:13376:13376 [0] NCCL INFO NET/IB : No device found.
node071:13376:13376 [0] NCCL INFO NET/IB : No device found.
node071:13376:13376 [0] NCCL INFO NET/Socket : Using [0]eth0:10.141.0.71<0>
node071:13376:13376 [0] NCCL INFO Using network Socket
NCCL version 2.11.4+cuda11.4
node071:13377:13377 [1] NCCL INFO Bootstrap : Using eth0:10.141.0.71<0>
node071:13380:13380 [4] NCCL INFO Bootstrap : Using eth0:10.141.0.71<0>
node071:13379:13379 [3] NCCL INFO Bootstrap : Using eth0:10.141.0.71<0>
node071:13382:13382 [6] NCCL INFO Bootstrap : Using eth0:10.141.0.71<0>
node071:13378:13378 [2] NCCL INFO Bootstrap : Using eth0:10.141.0.71<0>
node071:13380:13380 [4] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
node071:13380:13380 [4] NCCL INFO P2P plugin IBext
node071:13377:13377 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
node071:13377:13377 [1] NCCL INFO P2P plugin IBext
node071:13379:13379 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
node071:13379:13379 [3] NCCL INFO P2P plugin IBext
node071:13380:13380 [4] NCCL INFO NET/IB : No device found.
node071:13377:13377 [1] NCCL INFO NET/IB : No device found.
node071:13378:13378 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
node071:13382:13382 [6] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
node071:13378:13378 [2] NCCL INFO P2P plugin IBext
node071:13382:13382 [6] NCCL INFO P2P plugin IBext
node071:13377:13377 [1] NCCL INFO NET/IB : No device found.
node071:13379:13379 [3] NCCL INFO NET/IB : No device found.
node071:13380:13380 [4] NCCL INFO NET/IB : No device found.
node071:13382:13382 [6] NCCL INFO NET/IB : No device found.
node071:13378:13378 [2] NCCL INFO NET/IB : No device found.
node071:13379:13379 [3] NCCL INFO NET/IB : No device found.
node071:13380:13380 [4] NCCL INFO NET/Socket : Using [0]eth0:10.141.0.71<0>
node071:13377:13377 [1] NCCL INFO NET/Socket : Using [0]eth0:10.141.0.71<0>
node071:13380:13380 [4] NCCL INFO Using network Socket
node071:13377:13377 [1] NCCL INFO Using network Socket
node071:13378:13378 [2] NCCL INFO NET/IB : No device found.
node071:13382:13382 [6] NCCL INFO NET/IB : No device found.
node071:13379:13379 [3] NCCL INFO NET/Socket : Using [0]eth0:10.141.0.71<0>
node071:13379:13379 [3] NCCL INFO Using network Socket
node071:13378:13378 [2] NCCL INFO NET/Socket : Using [0]eth0:10.141.0.71<0>
node071:13382:13382 [6] NCCL INFO NET/Socket : Using [0]eth0:10.141.0.71<0>
node071:13378:13378 [2] NCCL INFO Using network Socket
node071:13382:13382 [6] NCCL INFO Using network Socket
node071:13381:13381 [5] NCCL INFO Bootstrap : Using eth0:10.141.0.71<0>
node071:13383:13383 [7] NCCL INFO Bootstrap : Using eth0:10.141.0.71<0>
node071:13381:13381 [5] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
node071:13383:13383 [7] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
node071:13381:13381 [5] NCCL INFO P2P plugin IBext
node071:13383:13383 [7] NCCL INFO P2P plugin IBext
node071:13381:13381 [5] NCCL INFO NET/IB : No device found.
node071:13383:13383 [7] NCCL INFO NET/IB : No device found.
node071:13381:13381 [5] NCCL INFO NET/IB : No device found.
node071:13383:13383 [7] NCCL INFO NET/IB : No device found.
node071:13381:13381 [5] NCCL INFO NET/Socket : Using [0]eth0:10.141.0.71<0>
node071:13383:13383 [7] NCCL INFO NET/Socket : Using [0]eth0:10.141.0.71<0>
node071:13381:13381 [5] NCCL INFO Using network Socket
node071:13383:13383 [7] NCCL INFO Using network Socket
node071:13376:13626 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to PIX
node071:13379:13629 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to PIX
node071:13381:13632 [5] NCCL INFO NCCL_P2P_LEVEL set by environment to PIX
node071:13380:13628 [4] NCCL INFO NCCL_P2P_LEVEL set by environment to PIX
node071:13383:13633 [7] NCCL INFO NCCL_P2P_LEVEL set by environment to PIX
node071:13378:13630 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to PIX
node071:13382:13631 [6] NCCL INFO NCCL_P2P_LEVEL set by environment to PIX
node071:13377:13627 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to PIX
node071:13377:13627 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
node071:13382:13631 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
node071:13381:13632 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
node071:13383:13633 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
node071:13377:13627 [1] NCCL INFO Setting affinity for GPU 1 to 05400000,00000540
node071:13376:13626 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
node071:13382:13631 [6] NCCL INFO Setting affinity for GPU 6 to 02a00000,000002a0,00000000
node071:13378:13630 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
node071:13381:13632 [5] NCCL INFO Setting affinity for GPU 5 to 0a8000,0000000a,80000000
node071:13380:13628 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
node071:13379:13629 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
node071:13383:13633 [7] NCCL INFO Setting affinity for GPU 7 to a8000000,0000a800,00000000
node071:13376:13626 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
node071:13378:13630 [2] NCCL INFO Setting affinity for GPU 2 to 01,50000000,00015000
node071:13380:13628 [4] NCCL INFO Setting affinity for GPU 4 to 2a00,00000000,2a000000
node071:13379:13629 [3] NCCL INFO Setting affinity for GPU 3 to 54,00000000,00540000
node071:13376:13626 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
node071:13376:13626 [0] NCCL INFO Setting affinity for GPU 0 to 150000,00000015
node071:13379:13629 [3] NCCL INFO Channel 00 : 3[4a000] -> 4[89000] via direct shared memory
node071:13377:13627 [1] NCCL INFO Channel 00 : 1[14000] -> 2[48000] via direct shared memory
node071:13383:13633 [7] NCCL INFO Channel 00 : 7[c3000] -> 0[12000] via direct shared memory
node071:13381:13632 [5] NCCL INFO Channel 00 : 5[8b000] -> 6[c1000] via direct shared memory
node071:13379:13629 [3] NCCL INFO Channel 01 : 3[4a000] -> 4[89000] via direct shared memory
node071:13377:13627 [1] NCCL INFO Channel 01 : 1[14000] -> 2[48000] via direct shared memory
node071:13383:13633 [7] NCCL INFO Channel 01 : 7[c3000] -> 0[12000] via direct shared memory
node071:13381:13632 [5] NCCL INFO Channel 01 : 5[8b000] -> 6[c1000] via direct shared memory
node071:13378:13630 [2] NCCL INFO Channel 00 : 2[48000] -> 3[4a000] via P2P/IPC
node071:13382:13631 [6] NCCL INFO Channel 00 : 6[c1000] -> 7[c3000] via P2P/IPC
node071:13376:13626 [0] NCCL INFO Channel 00 : 0[12000] -> 1[14000] via P2P/IPC
node071:13380:13628 [4] NCCL INFO Channel 00 : 4[89000] -> 5[8b000] via P2P/IPC
node071:13378:13630 [2] NCCL INFO Channel 01 : 2[48000] -> 3[4a000] via P2P/IPC
node071:13382:13631 [6] NCCL INFO Channel 01 : 6[c1000] -> 7[c3000] via P2P/IPC
node071:13376:13626 [0] NCCL INFO Channel 01 : 0[12000] -> 1[14000] via P2P/IPC
node071:13380:13628 [4] NCCL INFO Channel 01 : 4[89000] -> 5[8b000] via P2P/IPC
node071:13378:13630 [2] NCCL INFO Connected all rings
node071:13383:13633 [7] NCCL INFO Connected all rings
node071:13382:13631 [6] NCCL INFO Connected all rings
node071:13379:13629 [3] NCCL INFO Connected all rings
node071:13377:13627 [1] NCCL INFO Connected all rings
node071:13381:13632 [5] NCCL INFO Connected all rings
node071:13376:13626 [0] NCCL INFO Connected all rings
node071:13383:13633 [7] NCCL INFO Channel 00 : 7[c3000] -> 6[c1000] via P2P/IPC
node071:13380:13628 [4] NCCL INFO Connected all rings
node071:13378:13630 [2] NCCL INFO Channel 00 : 2[48000] -> 1[14000] via direct shared memory
node071:13383:13633 [7] NCCL INFO Channel 01 : 7[c3000] -> 6[c1000] via P2P/IPC
node071:13378:13630 [2] NCCL INFO Channel 01 : 2[48000] -> 1[14000] via direct shared memory
node071:13382:13631 [6] NCCL INFO Channel 00 : 6[c1000] -> 5[8b000] via direct shared memory
node071:13382:13631 [6] NCCL INFO Channel 01 : 6[c1000] -> 5[8b000] via direct shared memory
node071:13383:13633 [7] NCCL INFO Connected all trees
node071:13383:13633 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13383:13633 [7] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13380:13628 [4] NCCL INFO Channel 00 : 4[89000] -> 3[4a000] via direct shared memory
node071:13380:13628 [4] NCCL INFO Channel 01 : 4[89000] -> 3[4a000] via direct shared memory
node071:13379:13629 [3] NCCL INFO Channel 00 : 3[4a000] -> 2[48000] via P2P/IPC
node071:13377:13627 [1] NCCL INFO Channel 00 : 1[14000] -> 0[12000] via P2P/IPC
node071:13381:13632 [5] NCCL INFO Channel 00 : 5[8b000] -> 4[89000] via P2P/IPC
node071:13379:13629 [3] NCCL INFO Channel 01 : 3[4a000] -> 2[48000] via P2P/IPC
node071:13377:13627 [1] NCCL INFO Channel 01 : 1[14000] -> 0[12000] via P2P/IPC
node071:13381:13632 [5] NCCL INFO Channel 01 : 5[8b000] -> 4[89000] via P2P/IPC
node071:13376:13626 [0] NCCL INFO Connected all trees
node071:13376:13626 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13376:13626 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13379:13629 [3] NCCL INFO Connected all trees
node071:13379:13629 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13379:13629 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13377:13627 [1] NCCL INFO Connected all trees
node071:13377:13627 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13377:13627 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13381:13632 [5] NCCL INFO Connected all trees
node071:13381:13632 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13381:13632 [5] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13382:13631 [6] NCCL INFO Connected all trees
node071:13382:13631 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13382:13631 [6] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13378:13630 [2] NCCL INFO Connected all trees
node071:13378:13630 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13378:13630 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13380:13628 [4] NCCL INFO Connected all trees
node071:13380:13628 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13380:13628 [4] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13376:13626 [0] NCCL INFO comm 0x7ffd1c008fb0 rank 0 nranks 8 cudaDev 0 busId 12000 - Init COMPLETE
node071:13379:13629 [3] NCCL INFO comm 0x7ffd2c008fb0 rank 3 nranks 8 cudaDev 3 busId 4a000 - Init COMPLETE
node071:13378:13630 [2] NCCL INFO comm 0x7ffd34008fb0 rank 2 nranks 8 cudaDev 2 busId 48000 - Init COMPLETE
node071:13382:13631 [6] NCCL INFO comm 0x7ffd34008fb0 rank 6 nranks 8 cudaDev 6 busId c1000 - Init COMPLETE
node071:13381:13632 [5] NCCL INFO comm 0x7ffd30008fb0 rank 5 nranks 8 cudaDev 5 busId 8b000 - Init COMPLETE
node071:13383:13633 [7] NCCL INFO comm 0x7ffd30008fb0 rank 7 nranks 8 cudaDev 7 busId c3000 - Init COMPLETE
node071:13380:13628 [4] NCCL INFO comm 0x7ffd34008fb0 rank 4 nranks 8 cudaDev 4 busId 89000 - Init COMPLETE
node071:13377:13627 [1] NCCL INFO comm 0x7ffd34008fb0 rank 1 nranks 8 cudaDev 1 busId 14000 - Init COMPLETE
node071:13376:13376 [0] NCCL INFO Launch mode Parallel
node071:13376:13651 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
node071:13376:13651 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
node071:13383:13655 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
node071:13382:13654 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
node071:13377:13658 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
node071:13376:13651 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
node071:13383:13655 [7] NCCL INFO Setting affinity for GPU 7 to a8000000,0000a800,00000000
node071:13377:13658 [1] NCCL INFO Setting affinity for GPU 1 to 05400000,00000540
node071:13382:13654 [6] NCCL INFO Setting affinity for GPU 6 to 02a00000,000002a0,00000000
node071:13380:13656 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
node071:13381:13657 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
node071:13376:13651 [0] NCCL INFO Setting affinity for GPU 0 to 150000,00000015
node071:13379:13653 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
node071:13378:13652 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
node071:13380:13656 [4] NCCL INFO Setting affinity for GPU 4 to 2a00,00000000,2a000000
node071:13381:13657 [5] NCCL INFO Setting affinity for GPU 5 to 0a8000,0000000a,80000000
node071:13379:13653 [3] NCCL INFO Setting affinity for GPU 3 to 54,00000000,00540000
node071:13378:13652 [2] NCCL INFO Setting affinity for GPU 2 to 01,50000000,00015000
node071:13379:13653 [3] NCCL INFO Channel 00 : 3[4a000] -> 4[89000] via direct shared memory
node071:13377:13658 [1] NCCL INFO Channel 00 : 1[14000] -> 2[48000] via direct shared memory
node071:13383:13655 [7] NCCL INFO Channel 00 : 7[c3000] -> 0[12000] via direct shared memory
node071:13381:13657 [5] NCCL INFO Channel 00 : 5[8b000] -> 6[c1000] via direct shared memory
node071:13379:13653 [3] NCCL INFO Channel 01 : 3[4a000] -> 4[89000] via direct shared memory
node071:13377:13658 [1] NCCL INFO Channel 01 : 1[14000] -> 2[48000] via direct shared memory
node071:13383:13655 [7] NCCL INFO Channel 01 : 7[c3000] -> 0[12000] via direct shared memory
node071:13381:13657 [5] NCCL INFO Channel 01 : 5[8b000] -> 6[c1000] via direct shared memory
node071:13382:13654 [6] NCCL INFO Channel 00 : 6[c1000] -> 7[c3000] via P2P/IPC
node071:13378:13652 [2] NCCL INFO Channel 00 : 2[48000] -> 3[4a000] via P2P/IPC
node071:13376:13651 [0] NCCL INFO Channel 00 : 0[12000] -> 1[14000] via P2P/IPC
node071:13380:13656 [4] NCCL INFO Channel 00 : 4[89000] -> 5[8b000] via P2P/IPC
node071:13382:13654 [6] NCCL INFO Channel 01 : 6[c1000] -> 7[c3000] via P2P/IPC
node071:13378:13652 [2] NCCL INFO Channel 01 : 2[48000] -> 3[4a000] via P2P/IPC
node071:13376:13651 [0] NCCL INFO Channel 01 : 0[12000] -> 1[14000] via P2P/IPC
node071:13380:13656 [4] NCCL INFO Channel 01 : 4[89000] -> 5[8b000] via P2P/IPC
node071:13382:13654 [6] NCCL INFO Connected all rings
node071:13378:13652 [2] NCCL INFO Connected all rings
node071:13376:13651 [0] NCCL INFO Connected all rings
node071:13380:13656 [4] NCCL INFO Connected all rings
node071:13377:13658 [1] NCCL INFO Connected all rings
node071:13383:13655 [7] NCCL INFO Connected all rings
node071:13381:13657 [5] NCCL INFO Connected all rings
node071:13379:13653 [3] NCCL INFO Connected all rings
node071:13383:13655 [7] NCCL INFO Channel 00 : 7[c3000] -> 6[c1000] via P2P/IPC
node071:13382:13654 [6] NCCL INFO Channel 00 : 6[c1000] -> 5[8b000] via direct shared memory
node071:13383:13655 [7] NCCL INFO Channel 01 : 7[c3000] -> 6[c1000] via P2P/IPC
node071:13378:13652 [2] NCCL INFO Channel 00 : 2[48000] -> 1[14000] via direct shared memory
node071:13380:13656 [4] NCCL INFO Channel 00 : 4[89000] -> 3[4a000] via direct shared memory
node071:13382:13654 [6] NCCL INFO Channel 01 : 6[c1000] -> 5[8b000] via direct shared memory
node071:13378:13652 [2] NCCL INFO Channel 01 : 2[48000] -> 1[14000] via direct shared memory
node071:13380:13656 [4] NCCL INFO Channel 01 : 4[89000] -> 3[4a000] via direct shared memory
node071:13383:13655 [7] NCCL INFO Connected all trees
node071:13383:13655 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13383:13655 [7] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13377:13658 [1] NCCL INFO Channel 00 : 1[14000] -> 0[12000] via P2P/IPC
node071:13381:13657 [5] NCCL INFO Channel 00 : 5[8b000] -> 4[89000] via P2P/IPC
node071:13379:13653 [3] NCCL INFO Channel 00 : 3[4a000] -> 2[48000] via P2P/IPC
node071:13377:13658 [1] NCCL INFO Channel 01 : 1[14000] -> 0[12000] via P2P/IPC
node071:13376:13651 [0] NCCL INFO Connected all trees
node071:13376:13651 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13376:13651 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13381:13657 [5] NCCL INFO Channel 01 : 5[8b000] -> 4[89000] via P2P/IPC
node071:13379:13653 [3] NCCL INFO Channel 01 : 3[4a000] -> 2[48000] via P2P/IPC
node071:13377:13658 [1] NCCL INFO Connected all trees
node071:13377:13658 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13377:13658 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13381:13657 [5] NCCL INFO Connected all trees
node071:13381:13657 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13381:13657 [5] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13379:13653 [3] NCCL INFO Connected all trees
node071:13379:13653 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13379:13653 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13382:13654 [6] NCCL INFO Connected all trees
node071:13382:13654 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13382:13654 [6] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13378:13652 [2] NCCL INFO Connected all trees
node071:13378:13652 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13378:13652 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13380:13656 [4] NCCL INFO Connected all trees
node071:13380:13656 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13380:13656 [4] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13376:13651 [0] NCCL INFO comm 0x7ffd08008fb0 rank 0 nranks 8 cudaDev 0 busId 12000 - Init COMPLETE
node071:13376:13376 [0] NCCL INFO Launch mode Parallel
node071:13379:13653 [3] NCCL INFO comm 0x7ffd2c384af0 rank 3 nranks 8 cudaDev 3 busId 4a000 - Init COMPLETE
node071:13378:13652 [2] NCCL INFO comm 0x7ffd34384b30 rank 2 nranks 8 cudaDev 2 busId 48000 - Init COMPLETE
node071:13377:13658 [1] NCCL INFO comm 0x7ffd34384af0 rank 1 nranks 8 cudaDev 1 busId 14000 - Init COMPLETE
node071:13382:13654 [6] NCCL INFO comm 0x7ffd34384d10 rank 6 nranks 8 cudaDev 6 busId c1000 - Init COMPLETE
node071:13381:13657 [5] NCCL INFO comm 0x7ffd30384cd0 rank 5 nranks 8 cudaDev 5 busId 8b000 - Init COMPLETE
node071:13383:13655 [7] NCCL INFO comm 0x7ffd30381510 rank 7 nranks 8 cudaDev 7 busId c3000 - Init COMPLETE
node071:13380:13656 [4] NCCL INFO comm 0x7ffd34384b30 rank 4 nranks 8 cudaDev 4 busId 89000 - Init COMPLETE
:::MLLOG {"namespace": "", "time_ms": 1635299953603, "event_type": "POINT_IN_TIME", "key": "opt_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 731}}
:::MLLOG {"namespace": "", "time_ms": 1635299953604, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.9, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 734}}
:::MLLOG {"namespace": "", "time_ms": 1635299953604, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.999, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 735}}
:::MLLOG {"namespace": "", "time_ms": 1635299953604, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 736}}
:::MLLOG {"namespace": "", "time_ms": 1635299953872, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1635299953873, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 87}}
:::MLLOG {"namespace": "", "time_ms": 1635299953873, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 88}}
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.Torch distributed is available.

Torch distributed is initialized.Torch distributed is initialized.

Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
node071:13376:13744 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
node071:13376:13744 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
node071:13376:13744 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
node071:13376:13744 [0] NCCL INFO Setting affinity for GPU 0 to 150000,00000015
node071:13377:13746 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
node071:13377:13746 [1] NCCL INFO Setting affinity for GPU 1 to 05400000,00000540
node071:13378:13743 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
node071:13378:13743 [2] NCCL INFO Setting affinity for GPU 2 to 01,50000000,00015000
node071:13379:13741 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2
node071:13379:13741 [3] NCCL INFO Setting affinity for GPU 3 to 54,00000000,00540000
node071:13380:13745 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3
node071:13380:13745 [4] NCCL INFO Setting affinity for GPU 4 to 2a00,00000000,2a000000
node071:13381:13742 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
node071:13381:13742 [5] NCCL INFO Setting affinity for GPU 5 to 0a8000,0000000a,80000000
node071:13382:13740 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
node071:13382:13740 [6] NCCL INFO Setting affinity for GPU 6 to 02a00000,000002a0,00000000
node071:13383:13747 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
node071:13383:13747 [7] NCCL INFO Setting affinity for GPU 7 to a8000000,0000a800,00000000
node071:13379:13741 [3] NCCL INFO Channel 00 : 3[4a000] -> 4[89000] via direct shared memory
node071:13377:13746 [1] NCCL INFO Channel 00 : 1[14000] -> 2[48000] via direct shared memory
node071:13381:13742 [5] NCCL INFO Channel 00 : 5[8b000] -> 6[c1000] via direct shared memory
node071:13383:13747 [7] NCCL INFO Channel 00 : 7[c3000] -> 0[12000] via direct shared memory
node071:13379:13741 [3] NCCL INFO Channel 01 : 3[4a000] -> 4[89000] via direct shared memory
node071:13377:13746 [1] NCCL INFO Channel 01 : 1[14000] -> 2[48000] via direct shared memory
node071:13381:13742 [5] NCCL INFO Channel 01 : 5[8b000] -> 6[c1000] via direct shared memory
node071:13383:13747 [7] NCCL INFO Channel 01 : 7[c3000] -> 0[12000] via direct shared memory
node071:13376:13744 [0] NCCL INFO Channel 00 : 0[12000] -> 1[14000] via P2P/IPC
node071:13378:13743 [2] NCCL INFO Channel 00 : 2[48000] -> 3[4a000] via P2P/IPC
node071:13382:13740 [6] NCCL INFO Channel 00 : 6[c1000] -> 7[c3000] via P2P/IPC
node071:13380:13745 [4] NCCL INFO Channel 00 : 4[89000] -> 5[8b000] via P2P/IPC
node071:13376:13744 [0] NCCL INFO Channel 01 : 0[12000] -> 1[14000] via P2P/IPC
node071:13378:13743 [2] NCCL INFO Channel 01 : 2[48000] -> 3[4a000] via P2P/IPC
node071:13382:13740 [6] NCCL INFO Channel 01 : 6[c1000] -> 7[c3000] via P2P/IPC
node071:13380:13745 [4] NCCL INFO Channel 01 : 4[89000] -> 5[8b000] via P2P/IPC
node071:13378:13743 [2] NCCL INFO Connected all rings
node071:13376:13744 [0] NCCL INFO Connected all rings
node071:13382:13740 [6] NCCL INFO Connected all rings
node071:13380:13745 [4] NCCL INFO Connected all rings
node071:13377:13746 [1] NCCL INFO Connected all rings
node071:13383:13747 [7] NCCL INFO Connected all rings
node071:13381:13742 [5] NCCL INFO Connected all rings
node071:13379:13741 [3] NCCL INFO Connected all rings
node071:13383:13747 [7] NCCL INFO Channel 00 : 7[c3000] -> 6[c1000] via P2P/IPC
node071:13383:13747 [7] NCCL INFO Channel 01 : 7[c3000] -> 6[c1000] via P2P/IPC
node071:13378:13743 [2] NCCL INFO Channel 00 : 2[48000] -> 1[14000] via direct shared memory
node071:13382:13740 [6] NCCL INFO Channel 00 : 6[c1000] -> 5[8b000] via direct shared memory
node071:13380:13745 [4] NCCL INFO Channel 00 : 4[89000] -> 3[4a000] via direct shared memory
node071:13378:13743 [2] NCCL INFO Channel 01 : 2[48000] -> 1[14000] via direct shared memory
node071:13382:13740 [6] NCCL INFO Channel 01 : 6[c1000] -> 5[8b000] via direct shared memory
node071:13380:13745 [4] NCCL INFO Channel 01 : 4[89000] -> 3[4a000] via direct shared memory
node071:13383:13747 [7] NCCL INFO Connected all trees
node071:13383:13747 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13383:13747 [7] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13377:13746 [1] NCCL INFO Channel 00 : 1[14000] -> 0[12000] via P2P/IPC
node071:13377:13746 [1] NCCL INFO Channel 01 : 1[14000] -> 0[12000] via P2P/IPC
node071:13381:13742 [5] NCCL INFO Channel 00 : 5[8b000] -> 4[89000] via P2P/IPC
node071:13379:13741 [3] NCCL INFO Channel 00 : 3[4a000] -> 2[48000] via P2P/IPC
node071:13376:13744 [0] NCCL INFO Connected all trees
node071:13376:13744 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13376:13744 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13381:13742 [5] NCCL INFO Channel 01 : 5[8b000] -> 4[89000] via P2P/IPC
node071:13379:13741 [3] NCCL INFO Channel 01 : 3[4a000] -> 2[48000] via P2P/IPC
node071:13377:13746 [1] NCCL INFO Connected all trees
node071:13377:13746 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13377:13746 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13381:13742 [5] NCCL INFO Connected all trees
node071:13381:13742 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13381:13742 [5] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13379:13741 [3] NCCL INFO Connected all trees
node071:13379:13741 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13379:13741 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13382:13740 [6] NCCL INFO Connected all trees
node071:13382:13740 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13382:13740 [6] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13380:13745 [4] NCCL INFO Connected all trees
node071:13380:13745 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13380:13745 [4] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13378:13743 [2] NCCL INFO Connected all trees
node071:13378:13743 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512
node071:13378:13743 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
node071:13381:13742 [5] NCCL INFO comm 0x7ff36c008fb0 rank 5 nranks 8 cudaDev 5 busId 8b000 - Init COMPLETE
node071:13376:13744 [0] NCCL INFO comm 0x7ff360008fb0 rank 0 nranks 8 cudaDev 0 busId 12000 - Init COMPLETE
node071:13376:13376 [0] NCCL INFO Launch mode Parallel
node071:13379:13741 [3] NCCL INFO comm 0x7ff374008fb0 rank 3 nranks 8 cudaDev 3 busId 4a000 - Init COMPLETE
node071:13378:13743 [2] NCCL INFO comm 0x7ff378008fb0 rank 2 nranks 8 cudaDev 2 busId 48000 - Init COMPLETE
node071:13382:13740 [6] NCCL INFO comm 0x7ff4e4008fb0 rank 6 nranks 8 cudaDev 6 busId c1000 - Init COMPLETE
node071:13383:13747 [7] NCCL INFO comm 0x7ff4e0008fb0 rank 7 nranks 8 cudaDev 7 busId c3000 - Init COMPLETE
node071:13377:13746 [1] NCCL INFO comm 0x7ff4ec008fb0 rank 1 nranks 8 cudaDev 1 busId 14000 - Init COMPLETE
node071:13380:13745 [4] NCCL INFO comm 0x7ff374008fb0 rank 4 nranks 8 cudaDev 4 busId 89000 - Init COMPLETE
:::MLLOG {"namespace": "", "time_ms": 1635299963796, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1370}}
:::MLLOG {"namespace": "", "time_ms": 1635299964047, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1371}}
:::MLLOG {"namespace": "", "time_ms": 1635299964116, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1382, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1635299964118, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1384, "first_epoch_num": 1, "epoch_count": 1}}
parsed args:
Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=150000, eval_iter_start_samples=150000, exchange_padding=True, fp16=True, fused_bias_fc=True, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_mha=False, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.00035, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=15000.0, min_samples_to_start_checkpoints=3000000, n_gpu=8, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.9, opt_lamb_beta_2=0.999, output_dir='/results', pad=False, pad_fmha=False, phase2=True, resume_from_checkpoint=False, resume_step=0, seed=4285, skip_checkpoint=True, start_warmup_step=0.0, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=0.0, weight_decay_rate=0.01)
epoch: 1
:::MLLOG {"namespace": "", "time_ms": 1635300143566, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3758964240550995, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 391, 'eval_loss': 4.088744163513184, 'eval_mlm_accuracy': 0.3758964240550995}
:::MLLOG {"namespace": "", "time_ms": 1635300319569, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.4032178521156311, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 782, 'eval_loss': 3.8576407432556152, 'eval_mlm_accuracy': 0.4032178521156311}
:::MLLOG {"namespace": "", "time_ms": 1635300495415, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.45626115798950195, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 1172, 'eval_loss': 3.3651278018951416, 'eval_mlm_accuracy': 0.45626115798950195}
:::MLLOG {"namespace": "", "time_ms": 1635300673662, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5556131601333618, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 1563, 'eval_loss': 2.532090425491333, 'eval_mlm_accuracy': 0.5556131601333618}
:::MLLOG {"namespace": "", "time_ms": 1635300860295, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.693257212638855, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 1954, 'eval_loss': 1.4813429117202759, 'eval_mlm_accuracy': 0.693257212638855}
:::MLLOG {"namespace": "", "time_ms": 1635301046037, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7068782448768616, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 2344, 'eval_loss': 1.3942835330963135, 'eval_mlm_accuracy': 0.7068782448768616}
:::MLLOG {"namespace": "", "time_ms": 1635301227701, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7102689146995544, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 2735, 'eval_loss': 1.3702690601348877, 'eval_mlm_accuracy': 0.7102689146995544}
:::MLLOG {"namespace": "", "time_ms": 1635301408740, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7117937803268433, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 3125, 'eval_loss': 1.3623448610305786, 'eval_mlm_accuracy': 0.7117937803268433}
:::MLLOG {"namespace": "", "time_ms": 1635301587001, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7130594253540039, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 3516, 'eval_loss': 1.3528623580932617, 'eval_mlm_accuracy': 0.7130594253540039}
:::MLLOG {"namespace": "", "time_ms": 1635301764451, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7139444351196289, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 3907, 'eval_loss': 1.3437995910644531, 'eval_mlm_accuracy': 0.7139444351196289}
:::MLLOG {"namespace": "", "time_ms": 1635301939545, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7150115966796875, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 4297, 'eval_loss': 1.3397620916366577, 'eval_mlm_accuracy': 0.7150115966796875}
:::MLLOG {"namespace": "", "time_ms": 1635302116520, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7154809832572937, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 4688, 'eval_loss': 1.3359884023666382, 'eval_mlm_accuracy': 0.7154809832572937}
:::MLLOG {"namespace": "", "time_ms": 1635302293790, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7158733010292053, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 5079, 'eval_loss': 1.3314427137374878, 'eval_mlm_accuracy': 0.7158733010292053}
:::MLLOG {"namespace": "", "time_ms": 1635302472337, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7165014743804932, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 5469, 'eval_loss': 1.3296990394592285, 'eval_mlm_accuracy': 0.7165014743804932}
:::MLLOG {"namespace": "", "time_ms": 1635302651480, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7169451117515564, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 5860, 'eval_loss': 1.3238753080368042, 'eval_mlm_accuracy': 0.7169451117515564}
:::MLLOG {"namespace": "", "time_ms": 1635302829814, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7172743678092957, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 6250, 'eval_loss': 1.3249343633651733, 'eval_mlm_accuracy': 0.7172743678092957}
:::MLLOG {"namespace": "", "time_ms": 1635303006484, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7179375886917114, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 6641, 'eval_loss': 1.32119882106781, 'eval_mlm_accuracy': 0.7179375886917114}
:::MLLOG {"namespace": "", "time_ms": 1635303185791, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7188459634780884, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 7032, 'eval_loss': 1.315673828125, 'eval_mlm_accuracy': 0.7188459634780884}
:::MLLOG {"namespace": "", "time_ms": 1635303365043, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7186404466629028, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 7422, 'eval_loss': 1.3151861429214478, 'eval_mlm_accuracy': 0.7186404466629028}
:::MLLOG {"namespace": "", "time_ms": 1635303550453, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7191798686981201, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 7813, 'eval_loss': 1.3110846281051636, 'eval_mlm_accuracy': 0.7191798686981201}
:::MLLOG {"namespace": "", "time_ms": 1635303737664, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7197192907333374, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 8204, 'eval_loss': 1.3082592487335205, 'eval_mlm_accuracy': 0.7197192907333374}
:::MLLOG {"namespace": "", "time_ms": 1635303922356, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7204082012176514, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 8594, 'eval_loss': 1.305195689201355, 'eval_mlm_accuracy': 0.7204082012176514}
0.720408 > 0.720000, Target MLM Accuracy reached at 8594
(1, 8602.0) {'final_loss': 0.0}
:::MLLOG {"namespace": "", "time_ms": 1635303922480, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1710, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1635303922480, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1713, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1635303922480, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 3300096, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1726}}
:::MLLOG {"namespace": "", "time_ms": 1635303922481, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1729}}
:::MLLOG {"namespace": "", "time_ms": 1635303922481, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1732, "status": "success"}}
{'e2e_time': 3982.165992498398, 'training_sequences_per_second': 1452.00878133853, 'final_loss': 0.0, 'raw_train_time': 3966.9181578159332}
+ set +x
ENDING TIMING RUN AT 2021-10-27 03:05:24 AM
RESULT,bert,4285,3986,,2021-10-27 01:58:58 AM
