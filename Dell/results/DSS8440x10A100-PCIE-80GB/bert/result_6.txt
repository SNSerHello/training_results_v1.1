+ echo 'Beginning trial 6 of 10'
Beginning trial 6 of 10
+ docker exec -it language_model python -c '
import mlperf_logger 
from mlperf_logging.mllog import constants 
mlperf_logger.mlperf_submission_log(constants.BERT)'
:::MLLOG {"namespace": "", "time_ms": 1635375397338, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 66}}
:::MLLOG {"namespace": "", "time_ms": 1635375397359, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 71}}
:::MLLOG {"namespace": "", "time_ms": 1635375397359, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1635375397360, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 79}}
:::MLLOG {"namespace": "", "time_ms": 1635375397360, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xDSS8440x10A100-PCIE-80GB", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 83}}
+ '[' 1 -eq 1 ']'
+ sync
+ sudo /sbin/sysctl vm.drop_caches=3
vm.drop_caches = 3
+ docker exec -it language_model python -c '
from mlperf_logging.mllog import constants 
from mlperf_logger import log_event 
log_event(key=constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1635375400949, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
+ docker exec -it --env=BATCHSIZE --env=CHECKPOINTDIR --env=CHECKPOINTDIR_PHASE1 --env=DATADIR --env=DATADIR_PHASE2 --env=DGXHT --env=DGXNGPU --env=DGXNNODES --env=DGXNSOCKET --env=DGXSOCKETCORES --env=DGXSYSTEM --env=EVALDIR --env=EVAL_ITER_SAMPLES --env=EVAL_ITER_START_SAMPLES --env=EXTRA_PARAMS --env=GRADIENT_STEPS --env=LR --env=MAX_SAMPLES_TERMINATION --env=MAX_STEPS --env=NCCL_SOCKET_IFNAME --env=OPT_LAMB_BETA_1 --env=OPT_LAMB_BETA_2 --env=PHASE --env=SLURM_NTASKS --env=START_WARMUP_STEP --env=WALLTIME --env=WARMUP_PROPORTION --env=SEED language_model sh -c ./run_and_time.sh
Run vars: id 13713 gpus 10 mparams ''
STARTING TIMING RUN AT 2021-10-27 10:56:41 PM
##binding cmd: ['/usr/bin/numactl', '--physcpubind=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,86,88,90,92,94', '--membind=0', '/opt/conda/bin/python', '-u', '/workspace/bert/run_pretraining.py', '--local_rank=0', '--train_batch_size=64', '--learning_rate=3.5e-4', '--opt_lamb_beta_1=0.9', '--opt_lamb_beta_2=0.999', '--warmup_proportion=0.0', '--warmup_steps=0.0', '--start_warmup_step=0', '--max_steps=7100', '--phase2', '--max_seq_length=512', '--max_predictions_per_seq=76', '--input_dir=/workspace/data_phase2', '--init_checkpoint=/workspace/phase1/model.ckpt-28252.pt', '--do_train', '--skip_checkpoint', '--train_mlm_accuracy_window_size=0', '--target_mlm_accuracy=0.720', '--weight_decay_rate=0.01', '--max_samples_termination=4500000', '--eval_iter_start_samples=150000', '--eval_iter_samples=150000', '--eval_batch_size=16', '--eval_dir=/workspace/evaldata', '--num_eval_examples', '10000', '--cache_eval_data', '--output_dir=/results', '--fp16', '--fused_bias_fc', '--fused_bias_mha', '--fused_dropout_add', '--distributed_lamb', '--dwu-num-rs-pg=1', '--dwu-num-ar-pg=1', '--dwu-num-ag-pg=1', '--dwu-num-blocks=1', '--gradient_accumulation_steps=1', '--log_freq=0', '--bert_config_path=/workspace/phase1/bert_config.json', '--allreduce_post_accumulation', '--allreduce_post_accumulation_fp16', '--dense_seq_output', '--unpad', '--unpad_fmha', '--exchange_padding', '--seed=7507']
##binding cmd: ['/usr/bin/numactl', '--physcpubind=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,86,88,90,92,94', '--membind=0', '/opt/conda/bin/python', '-u', '/workspace/bert/run_pretraining.py', '--local_rank=1', '--train_batch_size=64', '--learning_rate=3.5e-4', '--opt_lamb_beta_1=0.9', '--opt_lamb_beta_2=0.999', '--warmup_proportion=0.0', '--warmup_steps=0.0', '--start_warmup_step=0', '--max_steps=7100', '--phase2', '--max_seq_length=512', '--max_predictions_per_seq=76', '--input_dir=/workspace/data_phase2', '--init_checkpoint=/workspace/phase1/model.ckpt-28252.pt', '--do_train', '--skip_checkpoint', '--train_mlm_accuracy_window_size=0', '--target_mlm_accuracy=0.720', '--weight_decay_rate=0.01', '--max_samples_termination=4500000', '--eval_iter_start_samples=150000', '--eval_iter_samples=150000', '--eval_batch_size=16', '--eval_dir=/workspace/evaldata', '--num_eval_examples', '10000', '--cache_eval_data', '--output_dir=/results', '--fp16', '--fused_bias_fc', '--fused_bias_mha', '--fused_dropout_add', '--distributed_lamb', '--dwu-num-rs-pg=1', '--dwu-num-ar-pg=1', '--dwu-num-ag-pg=1', '--dwu-num-blocks=1', '--gradient_accumulation_steps=1', '--log_freq=0', '--bert_config_path=/workspace/phase1/bert_config.json', '--allreduce_post_accumulation', '--allreduce_post_accumulation_fp16', '--dense_seq_output', '--unpad', '--unpad_fmha', '--exchange_padding', '--seed=7507']
##binding cmd: ['/usr/bin/numactl', '--physcpubind=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,86,88,90,92,94', '--membind=0', '/opt/conda/bin/python', '-u', '/workspace/bert/run_pretraining.py', '--local_rank=2', '--train_batch_size=64', '--learning_rate=3.5e-4', '--opt_lamb_beta_1=0.9', '--opt_lamb_beta_2=0.999', '--warmup_proportion=0.0', '--warmup_steps=0.0', '--start_warmup_step=0', '--max_steps=7100', '--phase2', '--max_seq_length=512', '--max_predictions_per_seq=76', '--input_dir=/workspace/data_phase2', '--init_checkpoint=/workspace/phase1/model.ckpt-28252.pt', '--do_train', '--skip_checkpoint', '--train_mlm_accuracy_window_size=0', '--target_mlm_accuracy=0.720', '--weight_decay_rate=0.01', '--max_samples_termination=4500000', '--eval_iter_start_samples=150000', '--eval_iter_samples=150000', '--eval_batch_size=16', '--eval_dir=/workspace/evaldata', '--num_eval_examples', '10000', '--cache_eval_data', '--output_dir=/results', '--fp16', '--fused_bias_fc', '--fused_bias_mha', '--fused_dropout_add', '--distributed_lamb', '--dwu-num-rs-pg=1', '--dwu-num-ar-pg=1', '--dwu-num-ag-pg=1', '--dwu-num-blocks=1', '--gradient_accumulation_steps=1', '--log_freq=0', '--bert_config_path=/workspace/phase1/bert_config.json', '--allreduce_post_accumulation', '--allreduce_post_accumulation_fp16', '--dense_seq_output', '--unpad', '--unpad_fmha', '--exchange_padding', '--seed=7507']
##binding cmd: ['/usr/bin/numactl', '--physcpubind=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,86,88,90,92,94', '--membind=0', '/opt/conda/bin/python', '-u', '/workspace/bert/run_pretraining.py', '--local_rank=3', '--train_batch_size=64', '--learning_rate=3.5e-4', '--opt_lamb_beta_1=0.9', '--opt_lamb_beta_2=0.999', '--warmup_proportion=0.0', '--warmup_steps=0.0', '--start_warmup_step=0', '--max_steps=7100', '--phase2', '--max_seq_length=512', '--max_predictions_per_seq=76', '--input_dir=/workspace/data_phase2', '--init_checkpoint=/workspace/phase1/model.ckpt-28252.pt', '--do_train', '--skip_checkpoint', '--train_mlm_accuracy_window_size=0', '--target_mlm_accuracy=0.720', '--weight_decay_rate=0.01', '--max_samples_termination=4500000', '--eval_iter_start_samples=150000', '--eval_iter_samples=150000', '--eval_batch_size=16', '--eval_dir=/workspace/evaldata', '--num_eval_examples', '10000', '--cache_eval_data', '--output_dir=/results', '--fp16', '--fused_bias_fc', '--fused_bias_mha', '--fused_dropout_add', '--distributed_lamb', '--dwu-num-rs-pg=1', '--dwu-num-ar-pg=1', '--dwu-num-ag-pg=1', '--dwu-num-blocks=1', '--gradient_accumulation_steps=1', '--log_freq=0', '--bert_config_path=/workspace/phase1/bert_config.json', '--allreduce_post_accumulation', '--allreduce_post_accumulation_fp16', '--dense_seq_output', '--unpad', '--unpad_fmha', '--exchange_padding', '--seed=7507']
##binding cmd: ['/usr/bin/numactl', '--physcpubind=0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,86,88,90,92,94', '--membind=0', '/opt/conda/bin/python', '-u', '/workspace/bert/run_pretraining.py', '--local_rank=4', '--train_batch_size=64', '--learning_rate=3.5e-4', '--opt_lamb_beta_1=0.9', '--opt_lamb_beta_2=0.999', '--warmup_proportion=0.0', '--warmup_steps=0.0', '--start_warmup_step=0', '--max_steps=7100', '--phase2', '--max_seq_length=512', '--max_predictions_per_seq=76', '--input_dir=/workspace/data_phase2', '--init_checkpoint=/workspace/phase1/model.ckpt-28252.pt', '--do_train', '--skip_checkpoint', '--train_mlm_accuracy_window_size=0', '--target_mlm_accuracy=0.720', '--weight_decay_rate=0.01', '--max_samples_termination=4500000', '--eval_iter_start_samples=150000', '--eval_iter_samples=150000', '--eval_batch_size=16', '--eval_dir=/workspace/evaldata', '--num_eval_examples', '10000', '--cache_eval_data', '--output_dir=/results', '--fp16', '--fused_bias_fc', '--fused_bias_mha', '--fused_dropout_add', '--distributed_lamb', '--dwu-num-rs-pg=1', '--dwu-num-ar-pg=1', '--dwu-num-ag-pg=1', '--dwu-num-blocks=1', '--gradient_accumulation_steps=1', '--log_freq=0', '--bert_config_path=/workspace/phase1/bert_config.json', '--allreduce_post_accumulation', '--allreduce_post_accumulation_fp16', '--dense_seq_output', '--unpad', '--unpad_fmha', '--exchange_padding', '--seed=7507']
##binding cmd: ['/usr/bin/numactl', '--physcpubind=1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95', '--membind=1', '/opt/conda/bin/python', '-u', '/workspace/bert/run_pretraining.py', '--local_rank=5', '--train_batch_size=64', '--learning_rate=3.5e-4', '--opt_lamb_beta_1=0.9', '--opt_lamb_beta_2=0.999', '--warmup_proportion=0.0', '--warmup_steps=0.0', '--start_warmup_step=0', '--max_steps=7100', '--phase2', '--max_seq_length=512', '--max_predictions_per_seq=76', '--input_dir=/workspace/data_phase2', '--init_checkpoint=/workspace/phase1/model.ckpt-28252.pt', '--do_train', '--skip_checkpoint', '--train_mlm_accuracy_window_size=0', '--target_mlm_accuracy=0.720', '--weight_decay_rate=0.01', '--max_samples_termination=4500000', '--eval_iter_start_samples=150000', '--eval_iter_samples=150000', '--eval_batch_size=16', '--eval_dir=/workspace/evaldata', '--num_eval_examples', '10000', '--cache_eval_data', '--output_dir=/results', '--fp16', '--fused_bias_fc', '--fused_bias_mha', '--fused_dropout_add', '--distributed_lamb', '--dwu-num-rs-pg=1', '--dwu-num-ar-pg=1', '--dwu-num-ag-pg=1', '--dwu-num-blocks=1', '--gradient_accumulation_steps=1', '--log_freq=0', '--bert_config_path=/workspace/phase1/bert_config.json', '--allreduce_post_accumulation', '--allreduce_post_accumulation_fp16', '--dense_seq_output', '--unpad', '--unpad_fmha', '--exchange_padding', '--seed=7507']
##binding cmd: ['/usr/bin/numactl', '--physcpubind=1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95', '--membind=1', '/opt/conda/bin/python', '-u', '/workspace/bert/run_pretraining.py', '--local_rank=6', '--train_batch_size=64', '--learning_rate=3.5e-4', '--opt_lamb_beta_1=0.9', '--opt_lamb_beta_2=0.999', '--warmup_proportion=0.0', '--warmup_steps=0.0', '--start_warmup_step=0', '--max_steps=7100', '--phase2', '--max_seq_length=512', '--max_predictions_per_seq=76', '--input_dir=/workspace/data_phase2', '--init_checkpoint=/workspace/phase1/model.ckpt-28252.pt', '--do_train', '--skip_checkpoint', '--train_mlm_accuracy_window_size=0', '--target_mlm_accuracy=0.720', '--weight_decay_rate=0.01', '--max_samples_termination=4500000', '--eval_iter_start_samples=150000', '--eval_iter_samples=150000', '--eval_batch_size=16', '--eval_dir=/workspace/evaldata', '--num_eval_examples', '10000', '--cache_eval_data', '--output_dir=/results', '--fp16', '--fused_bias_fc', '--fused_bias_mha', '--fused_dropout_add', '--distributed_lamb', '--dwu-num-rs-pg=1', '--dwu-num-ar-pg=1', '--dwu-num-ag-pg=1', '--dwu-num-blocks=1', '--gradient_accumulation_steps=1', '--log_freq=0', '--bert_config_path=/workspace/phase1/bert_config.json', '--allreduce_post_accumulation', '--allreduce_post_accumulation_fp16', '--dense_seq_output', '--unpad', '--unpad_fmha', '--exchange_padding', '--seed=7507']
##binding cmd: ['/usr/bin/numactl', '--physcpubind=1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95', '--membind=1', '/opt/conda/bin/python', '-u', '/workspace/bert/run_pretraining.py', '--local_rank=7', '--train_batch_size=64', '--learning_rate=3.5e-4', '--opt_lamb_beta_1=0.9', '--opt_lamb_beta_2=0.999', '--warmup_proportion=0.0', '--warmup_steps=0.0', '--start_warmup_step=0', '--max_steps=7100', '--phase2', '--max_seq_length=512', '--max_predictions_per_seq=76', '--input_dir=/workspace/data_phase2', '--init_checkpoint=/workspace/phase1/model.ckpt-28252.pt', '--do_train', '--skip_checkpoint', '--train_mlm_accuracy_window_size=0', '--target_mlm_accuracy=0.720', '--weight_decay_rate=0.01', '--max_samples_termination=4500000', '--eval_iter_start_samples=150000', '--eval_iter_samples=150000', '--eval_batch_size=16', '--eval_dir=/workspace/evaldata', '--num_eval_examples', '10000', '--cache_eval_data', '--output_dir=/results', '--fp16', '--fused_bias_fc', '--fused_bias_mha', '--fused_dropout_add', '--distributed_lamb', '--dwu-num-rs-pg=1', '--dwu-num-ar-pg=1', '--dwu-num-ag-pg=1', '--dwu-num-blocks=1', '--gradient_accumulation_steps=1', '--log_freq=0', '--bert_config_path=/workspace/phase1/bert_config.json', '--allreduce_post_accumulation', '--allreduce_post_accumulation_fp16', '--dense_seq_output', '--unpad', '--unpad_fmha', '--exchange_padding', '--seed=7507']
##binding cmd: ['/usr/bin/numactl', '--physcpubind=1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95', '--membind=1', '/opt/conda/bin/python', '-u', '/workspace/bert/run_pretraining.py', '--local_rank=8', '--train_batch_size=64', '--learning_rate=3.5e-4', '--opt_lamb_beta_1=0.9', '--opt_lamb_beta_2=0.999', '--warmup_proportion=0.0', '--warmup_steps=0.0', '--start_warmup_step=0', '--max_steps=7100', '--phase2', '--max_seq_length=512', '--max_predictions_per_seq=76', '--input_dir=/workspace/data_phase2', '--init_checkpoint=/workspace/phase1/model.ckpt-28252.pt', '--do_train', '--skip_checkpoint', '--train_mlm_accuracy_window_size=0', '--target_mlm_accuracy=0.720', '--weight_decay_rate=0.01', '--max_samples_termination=4500000', '--eval_iter_start_samples=150000', '--eval_iter_samples=150000', '--eval_batch_size=16', '--eval_dir=/workspace/evaldata', '--num_eval_examples', '10000', '--cache_eval_data', '--output_dir=/results', '--fp16', '--fused_bias_fc', '--fused_bias_mha', '--fused_dropout_add', '--distributed_lamb', '--dwu-num-rs-pg=1', '--dwu-num-ar-pg=1', '--dwu-num-ag-pg=1', '--dwu-num-blocks=1', '--gradient_accumulation_steps=1', '--log_freq=0', '--bert_config_path=/workspace/phase1/bert_config.json', '--allreduce_post_accumulation', '--allreduce_post_accumulation_fp16', '--dense_seq_output', '--unpad', '--unpad_fmha', '--exchange_padding', '--seed=7507']
##binding cmd: ['/usr/bin/numactl', '--physcpubind=1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87,89,91,93,95', '--membind=1', '/opt/conda/bin/python', '-u', '/workspace/bert/run_pretraining.py', '--local_rank=9', '--train_batch_size=64', '--learning_rate=3.5e-4', '--opt_lamb_beta_1=0.9', '--opt_lamb_beta_2=0.999', '--warmup_proportion=0.0', '--warmup_steps=0.0', '--start_warmup_step=0', '--max_steps=7100', '--phase2', '--max_seq_length=512', '--max_predictions_per_seq=76', '--input_dir=/workspace/data_phase2', '--init_checkpoint=/workspace/phase1/model.ckpt-28252.pt', '--do_train', '--skip_checkpoint', '--train_mlm_accuracy_window_size=0', '--target_mlm_accuracy=0.720', '--weight_decay_rate=0.01', '--max_samples_termination=4500000', '--eval_iter_start_samples=150000', '--eval_iter_samples=150000', '--eval_batch_size=16', '--eval_dir=/workspace/evaldata', '--num_eval_examples', '10000', '--cache_eval_data', '--output_dir=/results', '--fp16', '--fused_bias_fc', '--fused_bias_mha', '--fused_dropout_add', '--distributed_lamb', '--dwu-num-rs-pg=1', '--dwu-num-ar-pg=1', '--dwu-num-ag-pg=1', '--dwu-num-blocks=1', '--gradient_accumulation_steps=1', '--log_freq=0', '--bert_config_path=/workspace/phase1/bert_config.json', '--allreduce_post_accumulation', '--allreduce_post_accumulation_fp16', '--dense_seq_output', '--unpad', '--unpad_fmha', '--exchange_padding', '--seed=7507']
:::MLLOG {"namespace": "", "time_ms": 1635375405969, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635375406211, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635375406294, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635375406369, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635375406475, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635375406581, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635375406649, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635375406681, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635375406704, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
:::MLLOG {"namespace": "", "time_ms": 1635375406725, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1072}}
device: cuda:0 n_gpu: 10, distributed training: True, 16-bits training: True
device: cuda:4 n_gpu: 10, distributed training: True, 16-bits training: True
:::MLLOG {"namespace": "", "time_ms": 1635375407917, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 66}}
:::MLLOG {"namespace": "", "time_ms": 1635375407917, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 71}}
:::MLLOG {"namespace": "", "time_ms": 1635375407917, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1635375407917, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 79}}
:::MLLOG {"namespace": "", "time_ms": 1635375407918, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xDSS8440x10A100-PCIE-80GB", "metadata": {"file": "/workspace/bert/mlperf_logger.py", "lineno": 83}}
:::MLLOG {"namespace": "", "time_ms": 1635375407918, "event_type": "POINT_IN_TIME", "key": "seed", "value": 7507, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1095}}
:::MLLOG {"namespace": "", "time_ms": 1635375407918, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 640, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1097}}
:::MLLOG {"namespace": "", "time_ms": 1635375407918, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 64, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1099}}
:::MLLOG {"namespace": "", "time_ms": 1635375407918, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1101}}
:::MLLOG {"namespace": "", "time_ms": 1635375407918, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1103}}
device: cuda:3 n_gpu: 10, distributed training: True, 16-bits training: True
:::MLLOG {"namespace": "", "time_ms": 1635375407918, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 7100.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1105}}
:::MLLOG {"namespace": "", "time_ms": 1635375407918, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1107}}
parsed args:
Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=150000, eval_iter_start_samples=150000, exchange_padding=True, fp16=True, fused_bias_fc=True, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_mha=False, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.00035, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=7100.0, min_samples_to_start_checkpoints=3000000, n_gpu=10, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.9, opt_lamb_beta_2=0.999, output_dir='/results', pad=False, pad_fmha=False, phase2=True, resume_from_checkpoint=False, seed=7507, skip_checkpoint=True, start_warmup_step=0.0, target_mlm_accuracy=0.72, train_batch_size=64, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=0.0, weight_decay_rate=0.01)
device: cuda:9 n_gpu: 10, distributed training: True, 16-bits training: True
device: cuda:5 n_gpu: 10, distributed training: True, 16-bits training: True
device: cuda:6 n_gpu: 10, distributed training: True, 16-bits training: True
device: cuda:1 n_gpu: 10, distributed training: True, 16-bits training: True
device: cuda:8 n_gpu: 10, distributed training: True, 16-bits training: True
device: cuda:7 n_gpu: 10, distributed training: True, 16-bits training: True
device: cuda:2 n_gpu: 10, distributed training: True, 16-bits training: True
:::MLLOG {"namespace": "", "time_ms": 1635375419299, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.00035, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 699}}
:::MLLOG {"namespace": "", "time_ms": 1635375424568, "event_type": "POINT_IN_TIME", "key": "opt_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 731}}
:::MLLOG {"namespace": "", "time_ms": 1635375424568, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.9, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 734}}
:::MLLOG {"namespace": "", "time_ms": 1635375424569, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.999, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 735}}
:::MLLOG {"namespace": "", "time_ms": 1635375424569, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 736}}
:::MLLOG {"namespace": "", "time_ms": 1635375424787, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
:::MLLOG {"namespace": "", "time_ms": 1635375424787, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 87}}
:::MLLOG {"namespace": "", "time_ms": 1635375424788, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 88}}
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
Torch distributed is available.
Torch distributed is initialized.
:::MLLOG {"namespace": "", "time_ms": 1635375437197, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1370}}
:::MLLOG {"namespace": "", "time_ms": 1635375437403, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1371}}
:::MLLOG {"namespace": "", "time_ms": 1635375437437, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1382, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1635375437439, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1384, "first_epoch_num": 1, "epoch_count": 1}}
parsed args:
Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=150000, eval_iter_start_samples=150000, exchange_padding=True, fp16=True, fused_bias_fc=True, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_mha=False, gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.00035, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=7100.0, min_samples_to_start_checkpoints=3000000, n_gpu=10, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.9, opt_lamb_beta_2=0.999, output_dir='/results', pad=False, pad_fmha=False, phase2=True, resume_from_checkpoint=False, resume_step=0, seed=7507, skip_checkpoint=True, start_warmup_step=0.0, target_mlm_accuracy=0.72, train_batch_size=64, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=0.0, weight_decay_rate=0.01)
epoch: 1
:::MLLOG {"namespace": "", "time_ms": 1635375547689, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3728023171424866, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 235, 'eval_loss': 4.10935640335083, 'eval_mlm_accuracy': 0.3728023171424866}
:::MLLOG {"namespace": "", "time_ms": 1635375653728, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3848120868206024, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 469, 'eval_loss': 4.001659393310547, 'eval_mlm_accuracy': 0.3848120868206024}
:::MLLOG {"namespace": "", "time_ms": 1635375757659, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.4058566093444824, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 704, 'eval_loss': 3.827632427215576, 'eval_mlm_accuracy': 0.4058566093444824}
:::MLLOG {"namespace": "", "time_ms": 1635375859535, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.43728792667388916, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 938, 'eval_loss': 3.53852915763855, 'eval_mlm_accuracy': 0.43728792667388916}
:::MLLOG {"namespace": "", "time_ms": 1635375961602, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5033894777297974, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 1172, 'eval_loss': 2.977912425994873, 'eval_mlm_accuracy': 0.5033894777297974}
:::MLLOG {"namespace": "", "time_ms": 1635376061442, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.566651463508606, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 1407, 'eval_loss': 2.4453012943267822, 'eval_mlm_accuracy': 0.566651463508606}
:::MLLOG {"namespace": "", "time_ms": 1635376160993, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6527467370033264, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 1641, 'eval_loss': 1.7803605794906616, 'eval_mlm_accuracy': 0.6527467370033264}
:::MLLOG {"namespace": "", "time_ms": 1635376264921, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.694691002368927, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 1875, 'eval_loss': 1.471199631690979, 'eval_mlm_accuracy': 0.694691002368927}
:::MLLOG {"namespace": "", "time_ms": 1635376369910, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7059021592140198, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 2110, 'eval_loss': 1.3949406147003174, 'eval_mlm_accuracy': 0.7059021592140198}
:::MLLOG {"namespace": "", "time_ms": 1635376472492, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7097761631011963, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 2344, 'eval_loss': 1.3739330768585205, 'eval_mlm_accuracy': 0.7097761631011963}
:::MLLOG {"namespace": "", "time_ms": 1635376570329, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7113313674926758, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 2579, 'eval_loss': 1.3595603704452515, 'eval_mlm_accuracy': 0.7113313674926758}
:::MLLOG {"namespace": "", "time_ms": 1635376667194, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7127511501312256, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 2813, 'eval_loss': 1.353773593902588, 'eval_mlm_accuracy': 0.7127511501312256}
:::MLLOG {"namespace": "", "time_ms": 1635376778000, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7146753668785095, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 3047, 'eval_loss': 1.3380379676818848, 'eval_mlm_accuracy': 0.7146753668785095}
:::MLLOG {"namespace": "", "time_ms": 1635376889323, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7153992652893066, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 3282, 'eval_loss': 1.3349815607070923, 'eval_mlm_accuracy': 0.7153992652893066}
:::MLLOG {"namespace": "", "time_ms": 1635376997019, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7162259221076965, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 3516, 'eval_loss': 1.3311561346054077, 'eval_mlm_accuracy': 0.7162259221076965}
:::MLLOG {"namespace": "", "time_ms": 1635377099727, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7168610692024231, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 3750, 'eval_loss': 1.3282908201217651, 'eval_mlm_accuracy': 0.7168610692024231}
:::MLLOG {"namespace": "", "time_ms": 1635377204302, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7175920009613037, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 3985, 'eval_loss': 1.3198970556259155, 'eval_mlm_accuracy': 0.7175920009613037}
:::MLLOG {"namespace": "", "time_ms": 1635377312158, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.718140721321106, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 4219, 'eval_loss': 1.3157438039779663, 'eval_mlm_accuracy': 0.718140721321106}
:::MLLOG {"namespace": "", "time_ms": 1635377420673, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7187315225601196, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 4454, 'eval_loss': 1.3139101266860962, 'eval_mlm_accuracy': 0.7187315225601196}
:::MLLOG {"namespace": "", "time_ms": 1635377527851, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7193877100944519, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 4688, 'eval_loss': 1.311193585395813, 'eval_mlm_accuracy': 0.7193877100944519}
:::MLLOG {"namespace": "", "time_ms": 1635377633709, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7196422815322876, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 4922, 'eval_loss': 1.307571530342102, 'eval_mlm_accuracy': 0.7196422815322876}
:::MLLOG {"namespace": "", "time_ms": 1635377740758, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.719889760017395, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 5157, 'eval_loss': 1.3052852153778076, 'eval_mlm_accuracy': 0.719889760017395}
:::MLLOG {"namespace": "", "time_ms": 1635377846283, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7205039262771606, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1579, "epoch_num": 1}}
{'global_steps': 5391, 'eval_loss': 1.3029875755310059, 'eval_mlm_accuracy': 0.7205039262771606}
0.720504 > 0.720000, Target MLM Accuracy reached at 5391
(1, 5398.0) {'final_loss': 0.0}
:::MLLOG {"namespace": "", "time_ms": 1635377846418, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1710, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1635377846418, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1713, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1635377846418, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 3450240, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1726}}
:::MLLOG {"namespace": "", "time_ms": 1635377846418, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1729}}
:::MLLOG {"namespace": "", "time_ms": 1635377846418, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1732, "status": "success"}}
{'e2e_time': 2439.8585782051086, 'training_sequences_per_second': 1878.7873834191714, 'final_loss': 0.0, 'raw_train_time': 2418.58128285408}
ENDING TIMING RUN AT 2021-10-27 11:37:29 PM
RESULT,bert,7507,2448,,2021-10-27 10:56:41 PM
