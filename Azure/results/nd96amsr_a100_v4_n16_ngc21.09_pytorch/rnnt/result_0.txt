+ : DGXA100_16x8x16x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/rnntv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019054039767056799
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets
+ : /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ : ./api_logs
+ : 7101
+ : 30
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized
+ LOGBASE=rnnt_16x8x16_211019054039767056799
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019054039767056799
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019054039767056799
+ readonly _cont_name=rnn_speech_recognition
+ _cont_name=rnn_speech_recognition
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets:/datasets/,/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743:/results
+ _cont_mounts+=,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized:/metadata
+ _cont_mounts+=,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets/sentencepieces:/sentencepieces
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07407/slurm_script: line 43: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ srun --ntasks=16 mkdir -p /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ srun --ntasks=16 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/rnntv11.sqsh --container-name=rnn_speech_recognition true
+ [[ DGXA100_16x8x16x1 == \D\G\X\A\1\0\0* ]]
+ echo 'using NCCL_TOPO_FILE /opt/microsoft/ndv4-topo.xml'
using NCCL_TOPO_FILE /opt/microsoft/ndv4-topo.xml
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019054039767056799_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ srun --nodes=1 --ntasks=1 --container-name=rnn_speech_recognition python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=16 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C04DD
Clearing cache on ip-0A0C04EB
Clearing cache on ip-0A0C04C1
Clearing cache on ip-0A0C04DE
Clearing cache on ip-0A0C04DF
Clearing cache on ip-0A0C04EE
Clearing cache on ip-0A0C04E5
Clearing cache on ip-0A0C04E9
Clearing cache on ip-0A0C04EA
Clearing cache on ip-0A0C04ED
Clearing cache on ip-0A0C04B8
Clearing cache on ip-0A0C04E4
Clearing cache on ip-0A0C04E8
Clearing cache on ip-0A0C04E1
Clearing cache on ip-0A0C04EF
Clearing cache on ip-0A0C04E7
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=16 --container-name=rnn_speech_recognition python -c '
from mlperf import logging
logging.log_event(key=logging.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1634622050472, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050473, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050483, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050492, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050502, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050508, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050511, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050520, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050522, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050526, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050532, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050533, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050538, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050538, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050540, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622050550, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ SEED=7102
+ srun --mpi=none --ntasks=128 --ntasks-per-node=8 --container-name=rnn_speech_recognition --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets:/datasets/,/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743:/results,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized:/metadata,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets/sentencepieces:/sentencepieces,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:51 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint==pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint==pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointpack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint==pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint==pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 7102 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
:::MLLOG {"namespace": "", "time_ms": 1634622055784, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055833, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055836, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055852, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055857, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055859, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055872, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055872, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055884, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055909, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055910, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055922, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055944, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055944, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055957, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055958, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055964, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055970, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055976, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055982, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055975, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055977, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055981, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055992, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055994, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622055999, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056007, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056011, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056017, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056018, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056020, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056026, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056026, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056032, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056033, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056031, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056037, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056038, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056042, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056045, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056045, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056054, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056057, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056054, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056066, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056070, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056070, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056075, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056071, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056079, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056084, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056088, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056088, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056088, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056091, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056094, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056096, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056101, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056103, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056102, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056102, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056103, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056107, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056107, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056108, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056111, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056115, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056116, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056126, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056122, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056124, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056127, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056134, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056134, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056134, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056135, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056137, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056139, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056140, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056145, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056150, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056149, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056150, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056152, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056152, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056151, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056152, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056154, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056160, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056160, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056165, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056168, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056173, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056170, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056174, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056187, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056190, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056187, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056191, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056193, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056197, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056199, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056213, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056212, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056216, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056217, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056220, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056219, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056228, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056228, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056228, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056230, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056231, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056232, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056241, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056240, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056242, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056243, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056251, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056254, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056259, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056259, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056260, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056263, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056284, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622056302, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
Distributed training with 128 GPUs

:::MLLOG {"namespace": "", "time_ms": 1634622057220, "event_type": "POINT_IN_TIME", "key": "seed", "value": 7102, "metadata": {"file": "train.py", "lineno": 421}}
DLL 2021-10-19 05:40:57.225251 - PARAMETER | epochs :  80
DLL 2021-10-19 05:40:57.225423 - PARAMETER | warmup_epochs :  6
DLL 2021-10-19 05:40:57.225498 - PARAMETER | hold_epochs :  33
DLL 2021-10-19 05:40:57.225532 - PARAMETER | epochs_this_job :  0
DLL 2021-10-19 05:40:57.225553 - PARAMETER | cudnn_benchmark :  True
DLL 2021-10-19 05:40:57.225576 - PARAMETER | amp_level :  2
DLL 2021-10-19 05:40:57.225597 - PARAMETER | seed :  7102
DLL 2021-10-19 05:40:57.225622 - PARAMETER | local_rank :  0
DLL 2021-10-19 05:40:57.225641 - PARAMETER | target :  0.058
DLL 2021-10-19 05:40:57.225662 - PARAMETER | apex_transducer_loss :  fp16
DLL 2021-10-19 05:40:57.225682 - PARAMETER | fuse_relu_dropout :  True
DLL 2021-10-19 05:40:57.225701 - PARAMETER | weights_init_scale :  0.5
DLL 2021-10-19 05:40:57.225730 - PARAMETER | hidden_hidden_bias_scale : 
DLL 2021-10-19 05:40:57.225752 - PARAMETER | batch_eval_mode :  cg_unroll_pipeline
DLL 2021-10-19 05:40:57.225773 - PARAMETER | cg_unroll_factor :  4
DLL 2021-10-19 05:40:57.225791 - PARAMETER | apex_transducer_joint :  pack_w_relu_dropout
DLL 2021-10-19 05:40:57.225813 - PARAMETER | buffer_pre_alloc :  True
DLL 2021-10-19 05:40:57.225832 - PARAMETER | multilayer_lstm :  False
DLL 2021-10-19 05:40:57.225854 - PARAMETER | batch_split_factor :  1
DLL 2021-10-19 05:40:57.225872 - PARAMETER | apex_mlp :  True
DLL 2021-10-19 05:40:57.225892 - PARAMETER | num_cg :  50
DLL 2021-10-19 05:40:57.225910 - PARAMETER | min_seq_split_len :  -1
DLL 2021-10-19 05:40:57.225935 - PARAMETER | pre_sort_for_seq_split :  False
DLL 2021-10-19 05:40:57.225958 - PARAMETER | batch_size :  16
DLL 2021-10-19 05:40:57.225978 - PARAMETER | val_batch_size :  22
DLL 2021-10-19 05:40:57.225995 - PARAMETER | lr :  0.007
DLL 2021-10-19 05:40:57.226015 - PARAMETER | min_lr :  1e-05
DLL 2021-10-19 05:40:57.226080 - PARAMETER | lr_exp_gamma :  0.935
DLL 2021-10-19 05:40:57.226102 - PARAMETER | weight_decay :  0.001
DLL 2021-10-19 05:40:57.226122 - PARAMETER | grad_accumulation_steps :  1
DLL 2021-10-19 05:40:57.226140 - PARAMETER | clip_norm :  1
DLL 2021-10-19 05:40:57.226158 - PARAMETER | beta1 :  0.905
DLL 2021-10-19 05:40:57.226182 - PARAMETER | beta2 :  0.999
DLL 2021-10-19 05:40:57.226202 - PARAMETER | ema :  0.995
DLL 2021-10-19 05:40:57.226221 - PARAMETER | multi_tensor_ema :  True
DLL 2021-10-19 05:40:57.226245 - PARAMETER | dist_lamb :  True
DLL 2021-10-19 05:40:57.226263 - PARAMETER | ema_update_type :  fp16
DLL 2021-10-19 05:40:57.226280 - PARAMETER | dwu_group_size :  8
DLL 2021-10-19 05:40:57.226300 - PARAMETER | dwu_overlap_reduction :  True
DLL 2021-10-19 05:40:57.226318 - PARAMETER | dali_device :  gpu
DLL 2021-10-19 05:40:57.226337 - PARAMETER | resume :  False
DLL 2021-10-19 05:40:57.226355 - PARAMETER | ckpt : 
DLL 2021-10-19 05:40:57.226374 - PARAMETER | save_at_the_end :  False
DLL 2021-10-19 05:40:57.226392 - PARAMETER | save_frequency : 
DLL 2021-10-19 05:40:57.226409 - PARAMETER | keep_milestones :  []
DLL 2021-10-19 05:40:57.226434 - PARAMETER | save_best_from :  200
DLL 2021-10-19 05:40:57.226452 - PARAMETER | val_frequency :  1
DLL 2021-10-19 05:40:57.226470 - PARAMETER | log_frequency :  1000
DLL 2021-10-19 05:40:57.226494 - PARAMETER | prediction_frequency :  1000000
DLL 2021-10-19 05:40:57.226513 - PARAMETER | model_config :  configs/baseline_v3-1023sp.yaml
DLL 2021-10-19 05:40:57.226530 - PARAMETER | num_buckets :  1
DLL 2021-10-19 05:40:57.226549 - PARAMETER | vectorized_sampler :  True
DLL 2021-10-19 05:40:57.226567 - PARAMETER | dist_sampler :  True
DLL 2021-10-19 05:40:57.226585 - PARAMETER | train_manifests :  ['/metadata/librispeech-train-clean-100-wav-tokenized.pkl', '/metadata/librispeech-train-clean-360-wav-tokenized.pkl', '/metadata/librispeech-train-other-500-wav-tokenized.pkl']
DLL 2021-10-19 05:40:57.226614 - PARAMETER | val_manifests :  ['/metadata/librispeech-dev-clean-wav-tokenized.pkl']
DLL 2021-10-19 05:40:57.226635 - PARAMETER | max_duration :  16.7
DLL 2021-10-19 05:40:57.226656 - PARAMETER | max_txt_len :  125
DLL 2021-10-19 05:40:57.226674 - PARAMETER | max_eval_sample_duration :  32.7
DLL 2021-10-19 05:40:57.226692 - PARAMETER | dataset_dir :  /datasets/LibriSpeech
DLL 2021-10-19 05:40:57.226711 - PARAMETER | output_dir :  /results
DLL 2021-10-19 05:40:57.226729 - PARAMETER | log_file : 
DLL 2021-10-19 05:40:57.226746 - PARAMETER | max_symbol_per_sample :  300
DLL 2021-10-19 05:40:57.226764 - PARAMETER | data_cpu_threads :  8
DLL 2021-10-19 05:40:57.226789 - PARAMETER | synthetic_audio_seq_len : 
DLL 2021-10-19 05:40:57.226807 - PARAMETER | synthetic_text_seq_len : 
DLL 2021-10-19 05:40:57.226825 - PARAMETER | enable_seq_len_stats :  False
DLL 2021-10-19 05:40:57.226843 - PARAMETER | vectorized_sa :  True
DLL 2021-10-19 05:40:57.226860 - PARAMETER | in_mem_file_list :  False
DLL 2021-10-19 05:40:57.226878 - PARAMETER | enable_prefetch :  True
DLL 2021-10-19 05:40:57.226901 - PARAMETER | tokenized_transcript :  True
DLL 2021-10-19 05:40:57.226925 - PARAMETER | dali_dont_use_mmap :  False
:::MLLOG {"namespace": "", "time_ms": 1634622057250, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "train.py", "lineno": 438}}
:::MLLOG {"namespace": "", "time_ms": 1634622057250, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "rnnt", "metadata": {"file": "train.py", "lineno": 445}}
:::MLLOG {"namespace": "", "time_ms": 1634622057250, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "train.py", "lineno": 446}}
:::MLLOG {"namespace": "", "time_ms": 1634622057250, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "train.py", "lineno": 447}}
:::MLLOG {"namespace": "", "time_ms": 1634622057250, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "train.py", "lineno": 448}}
:::MLLOG {"namespace": "", "time_ms": 1634622057251, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "16xND96amsr_A100_v4", "metadata": {"file": "train.py", "lineno": 449}}
:::MLLOG {"namespace": "", "time_ms": 1634622057253, "event_type": "POINT_IN_TIME", "key": "model_weights_initialization_scale", "value": 0.5, "metadata": {"file": "train.py", "lineno": 456}}
:::MLLOG {"namespace": "", "time_ms": 1634622057361, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "pre_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634622057611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "post_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634622057615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 201, "tensor": "pred_embed"}}
:::MLLOG {"namespace": "", "time_ms": 1634622057640, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "dec_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634622057642, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 221, "tensor": "joint_pred"}}
:::MLLOG {"namespace": "", "time_ms": 1634622057645, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 226, "tensor": "joint_enc"}}
:::MLLOG {"namespace": "", "time_ms": 1634622057669, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 243, "tensor": "joint_net"}}
:::MLLOG {"namespace": "", "time_ms": 1634622060894, "event_type": "POINT_IN_TIME", "key": "eval_max_prediction_symbols", "value": 300, "metadata": {"file": "train.py", "lineno": 483}}
Model size: 49.1M params

:::MLLOG {"namespace": "", "time_ms": 1634622060913, "event_type": "POINT_IN_TIME", "key": "model_eval_ema_factor", "value": 0.995, "metadata": {"file": "train.py", "lineno": 497}}
[ip-0A0C04DD:0:39790 - context.c:584] INFO job (ID: 867749480470930348) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:39790 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:39790 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:39764 - context.c:584] INFO job (ID: 867749712561005490) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:39764 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:39764 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:39769 - context.c:584] INFO job (ID: 867749269769633493) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:39769 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:39769 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:39765 - context.c:584] INFO job (ID: 867749096388022798) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:39765 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:39765 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:39762 - context.c:584] INFO job (ID: 867749691529726884) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:39762 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:39762 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:39763 - context.c:584] INFO job (ID: 867749038709510953) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:39763 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:39763 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:39768 - context.c:584] INFO job (ID: 867749953752831573) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:39768 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:39768 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:39766 - context.c:584] INFO job (ID: 867749075941618725) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:39766 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:39766 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
Starting with LRs: 0.007000000216066837
Setting up datasets...
:::MLLOG {"namespace": "", "time_ms": 1634622090500, "event_type": "POINT_IN_TIME", "key": "data_train_max_duration", "value": 16.7, "metadata": {"file": "train.py", "lineno": 568}}
:::MLLOG {"namespace": "", "time_ms": 1634622090500, "event_type": "POINT_IN_TIME", "key": "data_speed_perturbaton_max", "value": 1.15, "metadata": {"file": "train.py", "lineno": 570}}
:::MLLOG {"namespace": "", "time_ms": 1634622090500, "event_type": "POINT_IN_TIME", "key": "data_speed_perturbaton_min", "value": 0.85, "metadata": {"file": "train.py", "lineno": 572}}
:::MLLOG {"namespace": "", "time_ms": 1634622090500, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_n", "value": 2, "metadata": {"file": "train.py", "lineno": 574}}
:::MLLOG {"namespace": "", "time_ms": 1634622090501, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_min", "value": 0, "metadata": {"file": "train.py", "lineno": 576}}
:::MLLOG {"namespace": "", "time_ms": 1634622090501, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_max", "value": 20, "metadata": {"file": "train.py", "lineno": 578}}
:::MLLOG {"namespace": "", "time_ms": 1634622090501, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_n", "value": 10, "metadata": {"file": "train.py", "lineno": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634622090501, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_min", "value": 0, "metadata": {"file": "train.py", "lineno": 582}}
:::MLLOG {"namespace": "", "time_ms": 1634622090501, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_max", "value": 0.03, "metadata": {"file": "train.py", "lineno": 584}}
:::MLLOG {"namespace": "", "time_ms": 1634622090501, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 2048, "metadata": {"file": "train.py", "lineno": 586}}
Graph with max_seq_len of 641
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
:::MLLOG {"namespace": "", "time_ms": 1634622181284, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train.py", "lineno": 691}}
:::MLLOG {"namespace": "", "time_ms": 1634622181496, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "train.py", "lineno": 694}}
:::MLLOG {"namespace": "", "time_ms": 1634622181502, "event_type": "POINT_IN_TIME", "key": "data_train_num_buckets", "value": 1, "metadata": {"file": "train.py", "lineno": 700}}
Launching vectorized bucketing sampler
Launching simple sampler
Dataset read by DALI. Number of samples: 278528
Initializing DALI with parameters:
	           dither : 1e-05
	    dont_use_mmap : False
	        file_root : /datasets/LibriSpeech
	     gpu_pipeline : True
	 in_mem_file_list : False
	             nfft : 512
	          nfilter : 80
	   resample_range : [0.85, 1.15]
	      sample_rate : 16000
	          sampler : <common.data.dali.sampler.VectorizedBucketingSampler object at 0x14891405e310>
	   spect_wind_len : 320.0
	  spect_wind_step : 160.0
	synthetic_seq_len : None
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
Dataset read by DALI. Number of samples: 2703
Initializing DALI with parameters:
	           dither : 1e-05
	    dont_use_mmap : False
	        file_root : /datasets/LibriSpeech
	     gpu_pipeline : True
	 in_mem_file_list : False
	             nfft : 512
	          nfilter : 80
	   resample_range : None
	      sample_rate : 16000
	          sampler : <common.data.dali.sampler.SimpleSampler object at 0x148914037250>
	   spect_wind_len : 320.0
	  spect_wind_step : 160.0
	synthetic_seq_len : None
:::MLLOG {"namespace": "", "time_ms": 1634622186093, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 278528, "metadata": {"file": "train.py", "lineno": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634622186094, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 2703, "metadata": {"file": "train.py", "lineno": 781}}
:::MLLOG {"namespace": "", "time_ms": 1634622186094, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "lamb", "metadata": {"file": "train.py", "lineno": 783}}
:::MLLOG {"namespace": "", "time_ms": 1634622186094, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.007, "metadata": {"file": "train.py", "lineno": 784}}
:::MLLOG {"namespace": "", "time_ms": 1634622186094, "event_type": "POINT_IN_TIME", "key": "opt_lamb_epsilon", "value": 1e-09, "metadata": {"file": "train.py", "lineno": 785}}
:::MLLOG {"namespace": "", "time_ms": 1634622186094, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 0.935, "metadata": {"file": "train.py", "lineno": 786}}
:::MLLOG {"namespace": "", "time_ms": 1634622186094, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 6, "metadata": {"file": "train.py", "lineno": 787}}
:::MLLOG {"namespace": "", "time_ms": 1634622186094, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_hold_epochs", "value": 33, "metadata": {"file": "train.py", "lineno": 788}}
:::MLLOG {"namespace": "", "time_ms": 1634622186094, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.905, "metadata": {"file": "train.py", "lineno": 789}}
:::MLLOG {"namespace": "", "time_ms": 1634622186094, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.999, "metadata": {"file": "train.py", "lineno": 790}}
:::MLLOG {"namespace": "", "time_ms": 1634622186095, "event_type": "POINT_IN_TIME", "key": "opt_gradient_clip_norm", "value": 1, "metadata": {"file": "train.py", "lineno": 791}}
:::MLLOG {"namespace": "", "time_ms": 1634622186095, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_alt_decay_func", "value": true, "metadata": {"file": "train.py", "lineno": 792}}
:::MLLOG {"namespace": "", "time_ms": 1634622186095, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_alt_warmup_func", "value": true, "metadata": {"file": "train.py", "lineno": 793}}
:::MLLOG {"namespace": "", "time_ms": 1634622186095, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_min", "value": 1e-05, "metadata": {"file": "train.py", "lineno": 794}}
:::MLLOG {"namespace": "", "time_ms": 1634622186095, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.001, "metadata": {"file": "train.py", "lineno": 795}}
Pre-allocate buffer with max_seq_len of 1921 and max_txt_len of 125
:::MLLOG {"namespace": "", "time_ms": 1634622186243, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 1, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622186243, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622192276, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 1}}
DLL 2021-10-19 05:43:12.277281 - epoch    1 | avg train utts/s 46161 | took  6.03 s
:::MLLOG {"namespace": "", "time_ms": 1634622192277, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 46160.87638812337, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622192277, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622192454, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 11.385279952942906, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622192455, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 1}}
DLL 2021-10-19 05:43:12.455531 - epoch    1 |   dev ema wer 1138.53 | took  0.18 s
:::MLLOG {"namespace": "", "time_ms": 1634622192456, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622192456, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 2, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622192456, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634622197656, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 2}}
DLL 2021-10-19 05:43:17.656722 - epoch    2 | avg train utts/s 53560 | took  5.20 s
:::MLLOG {"namespace": "", "time_ms": 1634622197656, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 53559.999425627626, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622197656, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634622197766, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9959008859968383, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634622197766, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 2}}
DLL 2021-10-19 05:43:17.767021 - epoch    2 |   dev ema wer  99.59 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634622197767, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634622197767, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 3, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622197767, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622202835, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 3}}
DLL 2021-10-19 05:43:22.835509 - epoch    3 | avg train utts/s 54965 | took  5.07 s
:::MLLOG {"namespace": "", "time_ms": 1634622202835, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 54965.15740835973, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622202835, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622202962, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622202962, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 3}}
DLL 2021-10-19 05:43:22.963149 - epoch    3 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634622202963, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622202963, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 4, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622202963, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634622207830, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 4}}
DLL 2021-10-19 05:43:27.830436 - epoch    4 | avg train utts/s 57233 | took  4.87 s
:::MLLOG {"namespace": "", "time_ms": 1634622207830, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 57232.743847129444, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622207830, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634622207960, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9773905371126062, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634622207961, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 4}}
DLL 2021-10-19 05:43:27.961421 - epoch    4 |   dev ema wer  97.74 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634622207961, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634622207961, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 5, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622207962, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634622212758, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 5}}
DLL 2021-10-19 05:43:32.759196 - epoch    5 | avg train utts/s 58062 | took  4.80 s
:::MLLOG {"namespace": "", "time_ms": 1634622212759, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 58062.148826392535, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622212759, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634622212891, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9852578949303334, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634622212891, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 5}}
DLL 2021-10-19 05:43:32.892214 - epoch    5 |   dev ema wer  98.53 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634622212892, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634622212892, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 6, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622212893, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634622217673, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 6}}
DLL 2021-10-19 05:43:37.673805 - epoch    6 | avg train utts/s 58261 | took  4.78 s
:::MLLOG {"namespace": "", "time_ms": 1634622217673, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 58261.08432311868, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622217674, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634622217805, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634622217805, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 6}}
DLL 2021-10-19 05:43:37.806044 - epoch    6 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634622217806, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634622217806, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 7, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622217806, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634622222460, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 7}}
DLL 2021-10-19 05:43:42.461152 - epoch    7 | avg train utts/s 59842 | took  4.65 s
:::MLLOG {"namespace": "", "time_ms": 1634622222461, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59841.63567454127, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622222461, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634622222584, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634622222584, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 7}}
DLL 2021-10-19 05:43:42.585221 - epoch    7 |   dev ema wer 100.00 | took  0.12 s
:::MLLOG {"namespace": "", "time_ms": 1634622222585, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634622222585, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 8, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622222585, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 8}}
DLL 2021-10-19 05:43:44.263848 - epoch    8 | iter   48/136 | loss  210.38 | utts/s  1237 | took  1.66 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634622227276, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 8}}
DLL 2021-10-19 05:43:47.277098 - epoch    8 | avg train utts/s 59373 | took  4.69 s
:::MLLOG {"namespace": "", "time_ms": 1634622227277, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59373.09055247929, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622227277, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634622227384, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.985956398661814, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634622227385, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 8}}
DLL 2021-10-19 05:43:47.385515 - epoch    8 |   dev ema wer  98.60 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634622227385, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634622227385, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 9, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622227386, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634622232089, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 9}}
DLL 2021-10-19 05:43:52.089568 - epoch    9 | avg train utts/s 59221 | took  4.70 s
:::MLLOG {"namespace": "", "time_ms": 1634622232089, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59220.546382540655, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622232089, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634622232202, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.937410389323922, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634622232202, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 9}}
DLL 2021-10-19 05:43:52.203065 - epoch    9 |   dev ema wer  93.74 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634622232203, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634622232203, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 10, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622232203, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634622236859, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 10}}
DLL 2021-10-19 05:43:56.859533 - epoch   10 | avg train utts/s 59825 | took  4.66 s
:::MLLOG {"namespace": "", "time_ms": 1634622236859, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59824.854599413826, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622236859, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634622236981, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7708356310429764, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634622236981, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 10}}
DLL 2021-10-19 05:43:56.982213 - epoch   10 |   dev ema wer  77.08 | took  0.12 s
:::MLLOG {"namespace": "", "time_ms": 1634622236982, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634622236982, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 11, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622236982, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634622241566, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 11}}
DLL 2021-10-19 05:44:01.566683 - epoch   11 | avg train utts/s 60764 | took  4.58 s
:::MLLOG {"namespace": "", "time_ms": 1634622241566, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60763.72510061741, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622241566, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634622241701, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5064887320319106, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634622241702, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 11}}
DLL 2021-10-19 05:44:01.702517 - epoch   11 |   dev ema wer  50.65 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622241702, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634622241703, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 12, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622241703, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634622246319, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 12}}
DLL 2021-10-19 05:44:06.319488 - epoch   12 | avg train utts/s 60337 | took  4.62 s
:::MLLOG {"namespace": "", "time_ms": 1634622246319, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60336.81552047588, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622246319, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634622246467, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.33465681408771736, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634622246467, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 12}}
DLL 2021-10-19 05:44:06.467751 - epoch   12 |   dev ema wer  33.47 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622246468, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634622246468, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 13, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622246468, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634622251060, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 13}}
DLL 2021-10-19 05:44:11.060965 - epoch   13 | avg train utts/s 60651 | took  4.59 s
:::MLLOG {"namespace": "", "time_ms": 1634622251061, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60650.514454576536, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622251061, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634622251203, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2417925811551046, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634622251203, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 13}}
DLL 2021-10-19 05:44:11.204245 - epoch   13 |   dev ema wer  24.18 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622251204, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634622251204, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 14, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622251204, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634622255815, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 14}}
DLL 2021-10-19 05:44:15.815390 - epoch   14 | avg train utts/s 60414 | took  4.61 s
:::MLLOG {"namespace": "", "time_ms": 1634622255815, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60414.423247256535, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622255815, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634622255958, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.18988272489981986, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634622255959, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 14}}
DLL 2021-10-19 05:44:15.959620 - epoch   14 |   dev ema wer  18.99 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622255960, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634622255960, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 15, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622255960, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 15}}
DLL 2021-10-19 05:44:19.217612 - epoch   15 | iter   96/136 | loss   45.47 | utts/s   634 | took  3.23 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634622260541, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 15}}
DLL 2021-10-19 05:44:20.541969 - epoch   15 | avg train utts/s 60795 | took  4.58 s
:::MLLOG {"namespace": "", "time_ms": 1634622260542, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60795.432278621556, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622260542, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634622260688, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1583213852431896, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634622260688, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 15}}
DLL 2021-10-19 05:44:20.688913 - epoch   15 |   dev ema wer  15.83 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622260689, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634622260689, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 16, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622260689, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634622265297, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 16}}
DLL 2021-10-19 05:44:25.298064 - epoch   16 | avg train utts/s 60442 | took  4.61 s
:::MLLOG {"namespace": "", "time_ms": 1634622265298, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60442.14536440439, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622265298, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634622265443, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.13821183044741003, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634622265444, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 16}}
DLL 2021-10-19 05:44:25.444398 - epoch   16 |   dev ema wer  13.82 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622265444, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634622265444, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 17, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622265444, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634622270033, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 17}}
DLL 2021-10-19 05:44:30.033836 - epoch   17 | avg train utts/s 60699 | took  4.59 s
:::MLLOG {"namespace": "", "time_ms": 1634622270033, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60698.533319526454, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622270034, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634622270179, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.12471967942355061, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634622270179, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 17}}
DLL 2021-10-19 05:44:30.180001 - epoch   17 |   dev ema wer  12.47 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622270180, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634622270180, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 18, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622270180, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634622274769, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 18}}
DLL 2021-10-19 05:44:34.770034 - epoch   18 | avg train utts/s 60692 | took  4.59 s
:::MLLOG {"namespace": "", "time_ms": 1634622274770, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60691.61792791595, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622274770, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634622274915, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.11394801661703614, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634622274915, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 18}}
DLL 2021-10-19 05:44:34.916334 - epoch   18 |   dev ema wer  11.39 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622274916, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634622274916, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 19, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622274917, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634622279513, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 19}}
DLL 2021-10-19 05:44:39.513825 - epoch   19 | avg train utts/s 60595 | took  4.60 s
:::MLLOG {"namespace": "", "time_ms": 1634622279513, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60594.656479510995, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622279514, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634622279660, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.10624609389360685, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634622279660, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 19}}
DLL 2021-10-19 05:44:39.661187 - epoch   19 |   dev ema wer  10.62 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622279661, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634622279661, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 20, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622279661, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622284254, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 20}}
DLL 2021-10-19 05:44:44.255211 - epoch   20 | avg train utts/s 60640 | took  4.59 s
:::MLLOG {"namespace": "", "time_ms": 1634622284255, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60640.40860393996, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622284255, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622284401, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.10131980441895519, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622284402, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 20}}
DLL 2021-10-19 05:44:44.402485 - epoch   20 |   dev ema wer  10.13 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622284402, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622284402, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 21, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622284403, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634622288914, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 21}}
DLL 2021-10-19 05:44:48.914557 - epoch   21 | avg train utts/s 61742 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634622288914, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61742.18164656021, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622288914, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634622289059, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.09624646152714973, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634622289059, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 21}}
DLL 2021-10-19 05:44:49.060345 - epoch   21 |   dev ema wer   9.62 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622289060, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634622289060, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 22, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622289060, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634622293571, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 22}}
DLL 2021-10-19 05:44:53.571357 - epoch   22 | avg train utts/s 61755 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634622293571, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61755.19777640689, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622293571, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634622293717, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.09137531708393073, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634622293717, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 22}}
DLL 2021-10-19 05:44:53.718321 - epoch   22 |   dev ema wer   9.14 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622293718, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634622293718, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 23, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622293718, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 23}}
DLL 2021-10-19 05:44:53.993859 - epoch   23 | iter    8/136 | loss   43.22 | utts/s  8305 | took  0.25 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634622298236, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 23}}
DLL 2021-10-19 05:44:58.236769 - epoch   23 | avg train utts/s 61654 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634622298236, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61653.54850274581, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622298236, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634622298382, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08882026396088379, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634622298382, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 23}}
DLL 2021-10-19 05:44:58.383193 - epoch   23 |   dev ema wer   8.88 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622298383, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634622298384, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 24, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622298384, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634622302948, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 24}}
DLL 2021-10-19 05:45:02.948864 - epoch   24 | avg train utts/s 61020 | took  4.56 s
:::MLLOG {"namespace": "", "time_ms": 1634622302948, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61019.69885694792, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622302949, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634622303095, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08633873754641373, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634622303095, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 24}}
DLL 2021-10-19 05:45:03.096015 - epoch   24 |   dev ema wer   8.63 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622303096, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634622303096, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 25, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622303096, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634622307680, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 25}}
DLL 2021-10-19 05:45:07.681018 - epoch   25 | avg train utts/s 60758 | took  4.58 s
:::MLLOG {"namespace": "", "time_ms": 1634622307681, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60758.12831627337, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622307681, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634622307826, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08361824932906878, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634622307827, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 25}}
DLL 2021-10-19 05:45:07.827387 - epoch   25 |   dev ema wer   8.36 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622307827, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634622307827, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 26, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622307828, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634622312370, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 26}}
DLL 2021-10-19 05:45:12.371315 - epoch   26 | avg train utts/s 61307 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634622312371, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61307.39146944164, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622312371, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634622312516, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0807139443402816, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634622312516, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 26}}
DLL 2021-10-19 05:45:12.517312 - epoch   26 |   dev ema wer   8.07 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622312517, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634622312517, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 27, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622312517, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634622317044, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 27}}
DLL 2021-10-19 05:45:17.044542 - epoch   27 | avg train utts/s 61534 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634622317044, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61534.46631159314, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622317044, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634622317190, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08069556266313739, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634622317190, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 27}}
DLL 2021-10-19 05:45:17.190995 - epoch   27 |   dev ema wer   8.07 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622317191, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634622317191, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 28, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622317191, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634622321721, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 28}}
DLL 2021-10-19 05:45:21.722101 - epoch   28 | avg train utts/s 61482 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634622321722, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61482.291340727184, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622321722, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634622321874, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07931693687732069, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634622321875, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 28}}
DLL 2021-10-19 05:45:21.875472 - epoch   28 |   dev ema wer   7.93 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622321875, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634622321876, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 29, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622321876, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634622326454, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 29}}
DLL 2021-10-19 05:45:26.454901 - epoch   29 | avg train utts/s 60833 | took  4.58 s
:::MLLOG {"namespace": "", "time_ms": 1634622326454, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60832.77257334627, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622326455, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634622326601, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07775449432006176, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634622326601, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 29}}
DLL 2021-10-19 05:45:26.601975 - epoch   29 |   dev ema wer   7.78 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622326602, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634622326602, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 30, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622326602, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 30}}
DLL 2021-10-19 05:45:28.462497 - epoch   30 | iter   56/136 | loss   39.91 | utts/s  1115 | took  1.84 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634622331110, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 30}}
DLL 2021-10-19 05:45:31.111132 - epoch   30 | avg train utts/s 61780 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634622331111, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61780.4558385683, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622331111, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634622331256, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07595308995992794, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634622331257, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 30}}
DLL 2021-10-19 05:45:31.257610 - epoch   30 |   dev ema wer   7.60 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622331257, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634622331258, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 31, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622331258, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634622335825, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 31}}
DLL 2021-10-19 05:45:35.826363 - epoch   31 | avg train utts/s 60975 | took  4.57 s
:::MLLOG {"namespace": "", "time_ms": 1634622335826, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60975.0181590273, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622335826, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634622335972, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07503400610271681, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634622335972, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 31}}
DLL 2021-10-19 05:45:35.973048 - epoch   31 |   dev ema wer   7.50 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622335973, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634622335973, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 32, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622335973, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634622340511, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 32}}
DLL 2021-10-19 05:45:40.512126 - epoch   32 | avg train utts/s 61374 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634622340512, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61374.398159300414, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622340512, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634622340658, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0729936399397081, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634622340659, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 32}}
DLL 2021-10-19 05:45:40.659408 - epoch   32 |   dev ema wer   7.30 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622340659, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634622340659, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 33, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622340660, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634622345159, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 33}}
DLL 2021-10-19 05:45:45.159848 - epoch   33 | avg train utts/s 61903 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634622345159, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61903.071046693076, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622345160, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634622345305, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07398625050549612, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634622345305, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 33}}
DLL 2021-10-19 05:45:45.306144 - epoch   33 |   dev ema wer   7.40 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622345306, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634622345306, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 34, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622345306, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634622349823, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 34}}
DLL 2021-10-19 05:45:49.823571 - epoch   34 | avg train utts/s 61669 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634622349823, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61669.375667882356, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622349823, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634622349970, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07200102937392007, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634622349970, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 34}}
DLL 2021-10-19 05:45:49.970733 - epoch   34 |   dev ema wer   7.20 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622349970, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634622349971, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 35, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622349971, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634622354476, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 35}}
DLL 2021-10-19 05:45:54.476725 - epoch   35 | avg train utts/s 61825 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634622354476, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61825.40902208853, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622354476, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634622354622, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07115547222528583, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634622354622, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 35}}
DLL 2021-10-19 05:45:54.623246 - epoch   35 |   dev ema wer   7.12 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622354623, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634622354624, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 36, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622354624, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634622359175, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 36}}
DLL 2021-10-19 05:45:59.175441 - epoch   36 | avg train utts/s 61200 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634622359175, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61199.552876509326, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622359175, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634622359321, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07229513620822764, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634622359321, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 36}}
DLL 2021-10-19 05:45:59.321851 - epoch   36 |   dev ema wer   7.23 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622359322, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634622359322, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 37, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622359322, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 37}}
DLL 2021-10-19 05:46:02.798199 - epoch   37 | iter  104/136 | loss   37.25 | utts/s   593 | took  3.45 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634622363841, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 37}}
DLL 2021-10-19 05:46:03.841503 - epoch   37 | avg train utts/s 61637 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634622363841, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61636.69530756852, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622363841, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634622363988, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07207455608249697, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634622363988, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 37}}
DLL 2021-10-19 05:46:03.988743 - epoch   37 |   dev ema wer   7.21 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622363988, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634622363989, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 38, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622363989, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634622368544, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 38}}
DLL 2021-10-19 05:46:08.544714 - epoch   38 | avg train utts/s 61144 | took  4.56 s
:::MLLOG {"namespace": "", "time_ms": 1634622368544, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61144.07155455893, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622368544, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634622368690, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07027315172236315, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634622368690, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 38}}
DLL 2021-10-19 05:46:08.690778 - epoch   38 |   dev ema wer   7.03 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622368690, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634622368691, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 39, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622368691, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634622373194, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 39}}
DLL 2021-10-19 05:46:13.194937 - epoch   39 | avg train utts/s 61845 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634622373195, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61845.47906666741, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622373195, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634622373340, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07100841880813205, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634622373341, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 39}}
DLL 2021-10-19 05:46:13.341760 - epoch   39 |   dev ema wer   7.10 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622373342, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634622373342, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 40, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622373342, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634622377804, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 40}}
DLL 2021-10-19 05:46:17.805375 - epoch   40 | avg train utts/s 62414 | took  4.46 s
:::MLLOG {"namespace": "", "time_ms": 1634622377805, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62413.952940961506, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622377805, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634622377951, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07051211352523805, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634622377951, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 40}}
DLL 2021-10-19 05:46:17.951783 - epoch   40 |   dev ema wer   7.05 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622377952, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634622377952, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 41, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622377952, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634622382441, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 41}}
DLL 2021-10-19 05:46:22.441608 - epoch   41 | avg train utts/s 62047 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634622382441, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62047.35329365107, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622382441, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634622382587, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06893128929083489, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634622382587, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 41}}
DLL 2021-10-19 05:46:22.588339 - epoch   41 |   dev ema wer   6.89 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622382588, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634622382588, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 42, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622382588, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634622387054, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 42}}
DLL 2021-10-19 05:46:27.055383 - epoch   42 | avg train utts/s 62363 | took  4.47 s
:::MLLOG {"namespace": "", "time_ms": 1634622387055, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62362.50024753228, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622387055, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634622387200, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06769971692217198, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634622387201, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 42}}
DLL 2021-10-19 05:46:27.201414 - epoch   42 |   dev ema wer   6.77 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622387201, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634622387201, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 43, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622387202, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634622391686, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 43}}
DLL 2021-10-19 05:46:31.686456 - epoch   43 | avg train utts/s 62113 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634622391686, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62112.81765641425, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622391686, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634622391831, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06652328958494173, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634622391832, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 43}}
DLL 2021-10-19 05:46:31.832586 - epoch   43 |   dev ema wer   6.65 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622391832, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634622391833, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 44, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622391833, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634622396336, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 44}}
DLL 2021-10-19 05:46:36.336615 - epoch   44 | avg train utts/s 61851 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634622396336, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61851.415514285436, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622396336, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634622396481, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06628432778206683, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634622396481, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 44}}
DLL 2021-10-19 05:46:36.482128 - epoch   44 |   dev ema wer   6.63 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622396482, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634622396482, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 45, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622396482, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 45}}
DLL 2021-10-19 05:46:37.012312 - epoch   45 | iter   16/136 | loss   37.72 | utts/s  4043 | took  0.51 s | lrate 4.68e-03
:::MLLOG {"namespace": "", "time_ms": 1634622401029, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 45}}
DLL 2021-10-19 05:46:41.029750 - epoch   45 | avg train utts/s 61258 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634622401029, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61257.945479992406, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622401029, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634622401175, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06508951876769237, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634622401176, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 45}}
DLL 2021-10-19 05:46:41.176541 - epoch   45 |   dev ema wer   6.51 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622401176, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634622401177, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 46, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622401177, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634622405642, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 46}}
DLL 2021-10-19 05:46:45.642752 - epoch   46 | avg train utts/s 62376 | took  4.47 s
:::MLLOG {"namespace": "", "time_ms": 1634622405642, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62376.278835152676, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622405643, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634622405788, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06350869453328922, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634622405789, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 46}}
DLL 2021-10-19 05:46:45.789597 - epoch   46 |   dev ema wer   6.35 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622405789, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634622405790, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 47, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622405790, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634622410343, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 47}}
DLL 2021-10-19 05:46:50.343519 - epoch   47 | avg train utts/s 61174 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634622410343, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61173.81927183729, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622410343, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634622410489, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.062166832101760966, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634622410490, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 47}}
DLL 2021-10-19 05:46:50.490533 - epoch   47 |   dev ema wer   6.22 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622410490, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634622410491, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 48, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622410491, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634622414938, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 48}}
DLL 2021-10-19 05:46:54.939213 - epoch   48 | avg train utts/s 62625 | took  4.45 s
:::MLLOG {"namespace": "", "time_ms": 1634622414939, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62625.009716856934, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622414939, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634622415085, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.061358038307415166, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634622415086, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 48}}
DLL 2021-10-19 05:46:55.086405 - epoch   48 |   dev ema wer   6.14 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622415086, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634622415086, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 49, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622415087, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634622419569, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 49}}
DLL 2021-10-19 05:46:59.569663 - epoch   49 | avg train utts/s 62136 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634622419569, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62136.134961495714, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622419569, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634622419716, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06143156501599206, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634622419716, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 49}}
DLL 2021-10-19 05:46:59.717039 - epoch   49 |   dev ema wer   6.14 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622419717, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634622419717, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 50, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622419717, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634622424220, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 50}}
DLL 2021-10-19 05:47:04.221279 - epoch   50 | avg train utts/s 61850 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634622424221, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61850.08274316926, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622424221, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634622424366, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.060089702584463806, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634622424366, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 50}}
DLL 2021-10-19 05:47:04.367053 - epoch   50 |   dev ema wer   6.01 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622424367, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634622424367, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 51, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622424367, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634622428836, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 51}}
DLL 2021-10-19 05:47:08.837181 - epoch   51 | avg train utts/s 62323 | took  4.47 s
:::MLLOG {"namespace": "", "time_ms": 1634622428837, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62323.48508600087, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622428837, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634622428982, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.059317672144406454, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634622428982, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 51}}
DLL 2021-10-19 05:47:08.983222 - epoch   51 |   dev ema wer   5.93 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622428983, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634622428983, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 52, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622428983, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 52}}
DLL 2021-10-19 05:47:11.105780 - epoch   52 | iter   64/136 | loss   36.59 | utts/s   976 | took  2.10 s | lrate 2.92e-03
:::MLLOG {"namespace": "", "time_ms": 1634622433480, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 52}}
DLL 2021-10-19 05:47:13.480952 - epoch   52 | avg train utts/s 61938 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634622433481, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61938.070498195855, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622433481, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634622433626, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.058361824932906876, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634622433626, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 52}}
DLL 2021-10-19 05:47:13.627319 - epoch   52 |   dev ema wer   5.84 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622433627, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634622433627, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 53, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622433628, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634622438088, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 53}}
DLL 2021-10-19 05:47:18.088870 - epoch   53 | avg train utts/s 62441 | took  4.46 s
:::MLLOG {"namespace": "", "time_ms": 1634622438088, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62440.89756598158, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622438089, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634622438233, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.058784603507224, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634622438233, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 53}}
DLL 2021-10-19 05:47:18.234272 - epoch   53 |   dev ema wer   5.88 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622438234, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634622438234, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 54, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622438234, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634622442688, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 54}}
DLL 2021-10-19 05:47:22.688801 - epoch   54 | avg train utts/s 62535 | took  4.45 s
:::MLLOG {"namespace": "", "time_ms": 1634622442688, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62535.29518164515, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622442689, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634622442832, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.058894893570089334, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634622442833, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 54}}
DLL 2021-10-19 05:47:22.833668 - epoch   54 |   dev ema wer   5.89 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622442833, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634622442834, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 55, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622442834, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634622447309, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 55}}
DLL 2021-10-19 05:47:27.310252 - epoch   55 | avg train utts/s 62231 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634622447310, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62230.875649166555, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622447310, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634622447454, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05847211499577221, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634622447455, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 55}}
DLL 2021-10-19 05:47:27.455688 - epoch   55 |   dev ema wer   5.85 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622447455, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634622447456, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 56, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622447456, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634622451917, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 56}}
DLL 2021-10-19 05:47:31.917583 - epoch   56 | avg train utts/s 62434 | took  4.46 s
:::MLLOG {"namespace": "", "time_ms": 1634622451917, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62434.2067767796, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622451917, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634622452061, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.058012573067166645, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634622452062, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 56}}
DLL 2021-10-19 05:47:32.062532 - epoch   56 |   dev ema wer   5.80 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622452062, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634622452063, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 57, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622452063, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1634622456557, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 57}}
DLL 2021-10-19 05:47:36.557560 - epoch   57 | avg train utts/s 61975 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634622456557, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61974.690920572866, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622456557, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1634622456701, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05685452740708062, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1634622456701, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 57}}
DLL 2021-10-19 05:47:36.702137 - epoch   57 |   dev ema wer   5.69 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622456702, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1634622456702, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1028, "status": "success"}}
Finished after 0 epochs.
DLL 2021-10-19 05:47:36.702537 -  | avg train utts/s 58700
ENDING TIMING RUN AT 2021-10-19 05:47:53 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:53 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:53 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:53 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:54 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:54 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:47:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:40:51 AM
ENDING TIMING RUN AT 2021-10-19 05:48:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:40:51 AM
