+ : DGXA100_16x8x16x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/rnntv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019055542051709064
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets
+ : /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ : ./api_logs
+ : 22123
+ : 30
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized
+ LOGBASE=rnnt_16x8x16_211019055542051709064
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019055542051709064
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019055542051709064
+ readonly _cont_name=rnn_speech_recognition
+ _cont_name=rnn_speech_recognition
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets:/datasets/,/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743:/results
+ _cont_mounts+=,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized:/metadata
+ _cont_mounts+=,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets/sentencepieces:/sentencepieces
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07409/slurm_script: line 43: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ srun --ntasks=16 mkdir -p /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ srun --ntasks=16 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/rnntv11.sqsh --container-name=rnn_speech_recognition true
+ [[ DGXA100_16x8x16x1 == \D\G\X\A\1\0\0* ]]
+ echo 'using NCCL_TOPO_FILE /opt/microsoft/ndv4-topo.xml'
using NCCL_TOPO_FILE /opt/microsoft/ndv4-topo.xml
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019055542051709064_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ srun --nodes=1 --ntasks=1 --container-name=rnn_speech_recognition python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=16 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C04DD
Clearing cache on ip-0A0C04E1
Clearing cache on ip-0A0C04E9
Clearing cache on ip-0A0C04E4
Clearing cache on ip-0A0C04DF
Clearing cache on ip-0A0C04ED
Clearing cache on ip-0A0C04DE
Clearing cache on ip-0A0C04E7
Clearing cache on ip-0A0C04E8
Clearing cache on ip-0A0C04EB
Clearing cache on ip-0A0C04C1
Clearing cache on ip-0A0C04EE
Clearing cache on ip-0A0C04EA
Clearing cache on ip-0A0C04B8
Clearing cache on ip-0A0C04E5
Clearing cache on ip-0A0C04EF
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=16 --container-name=rnn_speech_recognition python -c '
from mlperf import logging
logging.log_event(key=logging.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1634622953108, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953123, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953130, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953131, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953178, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953190, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953184, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953191, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953199, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953214, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953218, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953220, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953223, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953235, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953249, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622953248, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ SEED=22124
+ srun --mpi=none --ntasks=128 --ntasks-per-node=8 --container-name=rnn_speech_recognition --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets:/datasets/,/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743:/results,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized:/metadata,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets/sentencepieces:/sentencepieces,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:55:54 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointt=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointt=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointt=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22124 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
:::MLLOG {"namespace": "", "time_ms": 1634622958488, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958511, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958535, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958544, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958562, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958574, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958568, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958591, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958593, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958596, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958607, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958617, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958639, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958648, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958649, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958659, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958658, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958663, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958680, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958680, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958680, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958679, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958684, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958696, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958706, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958705, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958705, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958723, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958717, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958721, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958723, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958726, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958725, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958731, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958733, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958745, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958745, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958746, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958752, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958755, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958754, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958758, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958755, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958760, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958762, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958770, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958779, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958776, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958779, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958783, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958786, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958793, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958789, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958789, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958797, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958795, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958805, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958814, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958810, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958813, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958811, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958813, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958815, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958820, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958820, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958828, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958831, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958832, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958835, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958841, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958840, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958844, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958845, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958847, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958848, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958855, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958855, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958865, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958864, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958874, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958876, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958880, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958883, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958888, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958892, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958891, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958897, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958902, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958901, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958905, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958909, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958910, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958912, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958915, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958913, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958918, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958921, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958924, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958922, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958928, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958931, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958936, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958937, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958939, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958940, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958944, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958953, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958956, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958957, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958956, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958962, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958961, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958965, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958964, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958968, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958971, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958968, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958974, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958975, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958979, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958986, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958984, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958991, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958995, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622958999, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622959008, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
Distributed training with 128 GPUs

:::MLLOG {"namespace": "", "time_ms": 1634622960043, "event_type": "POINT_IN_TIME", "key": "seed", "value": 22124, "metadata": {"file": "train.py", "lineno": 421}}
DLL 2021-10-19 05:56:00.048308 - PARAMETER | epochs :  80
DLL 2021-10-19 05:56:00.048449 - PARAMETER | warmup_epochs :  6
DLL 2021-10-19 05:56:00.048566 - PARAMETER | hold_epochs :  33
DLL 2021-10-19 05:56:00.048594 - PARAMETER | epochs_this_job :  0
DLL 2021-10-19 05:56:00.048615 - PARAMETER | cudnn_benchmark :  True
DLL 2021-10-19 05:56:00.048638 - PARAMETER | amp_level :  2
DLL 2021-10-19 05:56:00.048668 - PARAMETER | seed :  22124
DLL 2021-10-19 05:56:00.048689 - PARAMETER | local_rank :  0
DLL 2021-10-19 05:56:00.048707 - PARAMETER | target :  0.058
DLL 2021-10-19 05:56:00.048733 - PARAMETER | apex_transducer_loss :  fp16
DLL 2021-10-19 05:56:00.048754 - PARAMETER | fuse_relu_dropout :  True
DLL 2021-10-19 05:56:00.048773 - PARAMETER | weights_init_scale :  0.5
DLL 2021-10-19 05:56:00.048799 - PARAMETER | hidden_hidden_bias_scale : 
DLL 2021-10-19 05:56:00.048820 - PARAMETER | batch_eval_mode :  cg_unroll_pipeline
DLL 2021-10-19 05:56:00.048840 - PARAMETER | cg_unroll_factor :  4
DLL 2021-10-19 05:56:00.048857 - PARAMETER | apex_transducer_joint :  pack_w_relu_dropout
DLL 2021-10-19 05:56:00.048876 - PARAMETER | buffer_pre_alloc :  True
DLL 2021-10-19 05:56:00.048894 - PARAMETER | multilayer_lstm :  False
DLL 2021-10-19 05:56:00.048915 - PARAMETER | batch_split_factor :  1
DLL 2021-10-19 05:56:00.048933 - PARAMETER | apex_mlp :  True
DLL 2021-10-19 05:56:00.048952 - PARAMETER | num_cg :  50
DLL 2021-10-19 05:56:00.048976 - PARAMETER | min_seq_split_len :  -1
DLL 2021-10-19 05:56:00.048996 - PARAMETER | pre_sort_for_seq_split :  False
DLL 2021-10-19 05:56:00.049020 - PARAMETER | batch_size :  16
DLL 2021-10-19 05:56:00.049038 - PARAMETER | val_batch_size :  22
DLL 2021-10-19 05:56:00.049056 - PARAMETER | lr :  0.007
DLL 2021-10-19 05:56:00.049074 - PARAMETER | min_lr :  1e-05
DLL 2021-10-19 05:56:00.049124 - PARAMETER | lr_exp_gamma :  0.935
DLL 2021-10-19 05:56:00.049145 - PARAMETER | weight_decay :  0.001
DLL 2021-10-19 05:56:00.049164 - PARAMETER | grad_accumulation_steps :  1
DLL 2021-10-19 05:56:00.049183 - PARAMETER | clip_norm :  1
DLL 2021-10-19 05:56:00.049200 - PARAMETER | beta1 :  0.905
DLL 2021-10-19 05:56:00.049219 - PARAMETER | beta2 :  0.999
DLL 2021-10-19 05:56:00.049237 - PARAMETER | ema :  0.995
DLL 2021-10-19 05:56:00.049257 - PARAMETER | multi_tensor_ema :  True
DLL 2021-10-19 05:56:00.049281 - PARAMETER | dist_lamb :  True
DLL 2021-10-19 05:56:00.049301 - PARAMETER | ema_update_type :  fp16
DLL 2021-10-19 05:56:00.049318 - PARAMETER | dwu_group_size :  8
DLL 2021-10-19 05:56:00.049343 - PARAMETER | dwu_overlap_reduction :  True
DLL 2021-10-19 05:56:00.049363 - PARAMETER | dali_device :  gpu
DLL 2021-10-19 05:56:00.049380 - PARAMETER | resume :  False
DLL 2021-10-19 05:56:00.049404 - PARAMETER | ckpt : 
DLL 2021-10-19 05:56:00.049422 - PARAMETER | save_at_the_end :  False
DLL 2021-10-19 05:56:00.049440 - PARAMETER | save_frequency : 
DLL 2021-10-19 05:56:00.049458 - PARAMETER | keep_milestones :  []
DLL 2021-10-19 05:56:00.049485 - PARAMETER | save_best_from :  200
DLL 2021-10-19 05:56:00.049503 - PARAMETER | val_frequency :  1
DLL 2021-10-19 05:56:00.049520 - PARAMETER | log_frequency :  1000
DLL 2021-10-19 05:56:00.049544 - PARAMETER | prediction_frequency :  1000000
DLL 2021-10-19 05:56:00.049563 - PARAMETER | model_config :  configs/baseline_v3-1023sp.yaml
DLL 2021-10-19 05:56:00.049580 - PARAMETER | num_buckets :  1
DLL 2021-10-19 05:56:00.049600 - PARAMETER | vectorized_sampler :  True
DLL 2021-10-19 05:56:00.049617 - PARAMETER | dist_sampler :  True
DLL 2021-10-19 05:56:00.049634 - PARAMETER | train_manifests :  ['/metadata/librispeech-train-clean-100-wav-tokenized.pkl', '/metadata/librispeech-train-clean-360-wav-tokenized.pkl', '/metadata/librispeech-train-other-500-wav-tokenized.pkl']
DLL 2021-10-19 05:56:00.049664 - PARAMETER | val_manifests :  ['/metadata/librispeech-dev-clean-wav-tokenized.pkl']
DLL 2021-10-19 05:56:00.049684 - PARAMETER | max_duration :  16.7
DLL 2021-10-19 05:56:00.049704 - PARAMETER | max_txt_len :  125
DLL 2021-10-19 05:56:00.049729 - PARAMETER | max_eval_sample_duration :  32.7
DLL 2021-10-19 05:56:00.049748 - PARAMETER | dataset_dir :  /datasets/LibriSpeech
DLL 2021-10-19 05:56:00.049765 - PARAMETER | output_dir :  /results
DLL 2021-10-19 05:56:00.049782 - PARAMETER | log_file : 
DLL 2021-10-19 05:56:00.049802 - PARAMETER | max_symbol_per_sample :  300
DLL 2021-10-19 05:56:00.049819 - PARAMETER | data_cpu_threads :  8
DLL 2021-10-19 05:56:00.049838 - PARAMETER | synthetic_audio_seq_len : 
DLL 2021-10-19 05:56:00.049855 - PARAMETER | synthetic_text_seq_len : 
DLL 2021-10-19 05:56:00.049873 - PARAMETER | enable_seq_len_stats :  False
DLL 2021-10-19 05:56:00.049891 - PARAMETER | vectorized_sa :  True
DLL 2021-10-19 05:56:00.049908 - PARAMETER | in_mem_file_list :  False
DLL 2021-10-19 05:56:00.049926 - PARAMETER | enable_prefetch :  True
DLL 2021-10-19 05:56:00.049943 - PARAMETER | tokenized_transcript :  True
DLL 2021-10-19 05:56:00.049979 - PARAMETER | dali_dont_use_mmap :  False
:::MLLOG {"namespace": "", "time_ms": 1634622960072, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "train.py", "lineno": 438}}
:::MLLOG {"namespace": "", "time_ms": 1634622960072, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "rnnt", "metadata": {"file": "train.py", "lineno": 445}}
:::MLLOG {"namespace": "", "time_ms": 1634622960072, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "train.py", "lineno": 446}}
:::MLLOG {"namespace": "", "time_ms": 1634622960072, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "train.py", "lineno": 447}}
:::MLLOG {"namespace": "", "time_ms": 1634622960072, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "train.py", "lineno": 448}}
:::MLLOG {"namespace": "", "time_ms": 1634622960072, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "16xND96amsr_A100_v4", "metadata": {"file": "train.py", "lineno": 449}}
:::MLLOG {"namespace": "", "time_ms": 1634622960075, "event_type": "POINT_IN_TIME", "key": "model_weights_initialization_scale", "value": 0.5, "metadata": {"file": "train.py", "lineno": 456}}
:::MLLOG {"namespace": "", "time_ms": 1634622960201, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "pre_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634622960463, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "post_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634622960468, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 201, "tensor": "pred_embed"}}
:::MLLOG {"namespace": "", "time_ms": 1634622960492, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "dec_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634622960494, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 221, "tensor": "joint_pred"}}
:::MLLOG {"namespace": "", "time_ms": 1634622960497, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 226, "tensor": "joint_enc"}}
:::MLLOG {"namespace": "", "time_ms": 1634622960505, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 243, "tensor": "joint_net"}}
:::MLLOG {"namespace": "", "time_ms": 1634622963664, "event_type": "POINT_IN_TIME", "key": "eval_max_prediction_symbols", "value": 300, "metadata": {"file": "train.py", "lineno": 483}}
Model size: 49.1M params

:::MLLOG {"namespace": "", "time_ms": 1634622963682, "event_type": "POINT_IN_TIME", "key": "model_eval_ema_factor", "value": 0.995, "metadata": {"file": "train.py", "lineno": 497}}
[ip-0A0C04DD:0:47022 - context.c:584] INFO job (ID: 867749549670578931) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:47022 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:47022 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:47020 - context.c:584] INFO job (ID: 867749859229533914) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:47020 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:47020 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:47015 - context.c:584] INFO job (ID: 867748993244309763) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:47015 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:47015 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:47021 - context.c:584] INFO job (ID: 867749964854821528) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:47021 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:47021 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:47018 - context.c:584] INFO job (ID: 867749899528961579) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:47018 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:47018 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:47019 - context.c:584] INFO job (ID: 867749270485362428) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:47019 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:47019 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:47016 - context.c:584] INFO job (ID: 867749232981096463) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:47016 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:47016 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:47017 - context.c:584] INFO job (ID: 867749516666209747) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:47017 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:47017 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
Starting with LRs: 0.007000000216066837
Setting up datasets...
:::MLLOG {"namespace": "", "time_ms": 1634622993240, "event_type": "POINT_IN_TIME", "key": "data_train_max_duration", "value": 16.7, "metadata": {"file": "train.py", "lineno": 568}}
:::MLLOG {"namespace": "", "time_ms": 1634622993240, "event_type": "POINT_IN_TIME", "key": "data_speed_perturbaton_max", "value": 1.15, "metadata": {"file": "train.py", "lineno": 570}}
:::MLLOG {"namespace": "", "time_ms": 1634622993240, "event_type": "POINT_IN_TIME", "key": "data_speed_perturbaton_min", "value": 0.85, "metadata": {"file": "train.py", "lineno": 572}}
:::MLLOG {"namespace": "", "time_ms": 1634622993240, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_n", "value": 2, "metadata": {"file": "train.py", "lineno": 574}}
:::MLLOG {"namespace": "", "time_ms": 1634622993241, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_min", "value": 0, "metadata": {"file": "train.py", "lineno": 576}}
:::MLLOG {"namespace": "", "time_ms": 1634622993241, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_max", "value": 20, "metadata": {"file": "train.py", "lineno": 578}}
:::MLLOG {"namespace": "", "time_ms": 1634622993241, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_n", "value": 10, "metadata": {"file": "train.py", "lineno": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634622993241, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_min", "value": 0, "metadata": {"file": "train.py", "lineno": 582}}
:::MLLOG {"namespace": "", "time_ms": 1634622993241, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_max", "value": 0.03, "metadata": {"file": "train.py", "lineno": 584}}
:::MLLOG {"namespace": "", "time_ms": 1634622993241, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 2048, "metadata": {"file": "train.py", "lineno": 586}}
Graph with max_seq_len of 641
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
:::MLLOG {"namespace": "", "time_ms": 1634623083963, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train.py", "lineno": 691}}
:::MLLOG {"namespace": "", "time_ms": 1634623084170, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "train.py", "lineno": 694}}
:::MLLOG {"namespace": "", "time_ms": 1634623084176, "event_type": "POINT_IN_TIME", "key": "data_train_num_buckets", "value": 1, "metadata": {"file": "train.py", "lineno": 700}}
Launching vectorized bucketing sampler
Launching simple sampler
Dataset read by DALI. Number of samples: 278528
Initializing DALI with parameters:
	           dither : 1e-05
	    dont_use_mmap : False
	        file_root : /datasets/LibriSpeech
	     gpu_pipeline : True
	 in_mem_file_list : False
	             nfft : 512
	          nfilter : 80
	   resample_range : [0.85, 1.15]
	      sample_rate : 16000
	          sampler : <common.data.dali.sampler.VectorizedBucketingSampler object at 0x149928c1f310>
	   spect_wind_len : 320.0
	  spect_wind_step : 160.0
	synthetic_seq_len : None
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
Dataset read by DALI. Number of samples: 2703
Initializing DALI with parameters:
	           dither : 1e-05
	    dont_use_mmap : False
	        file_root : /datasets/LibriSpeech
	     gpu_pipeline : True
	 in_mem_file_list : False
	             nfft : 512
	          nfilter : 80
	   resample_range : None
	      sample_rate : 16000
	          sampler : <common.data.dali.sampler.SimpleSampler object at 0x149928bf8250>
	   spect_wind_len : 320.0
	  spect_wind_step : 160.0
	synthetic_seq_len : None
:::MLLOG {"namespace": "", "time_ms": 1634623088569, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 278528, "metadata": {"file": "train.py", "lineno": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634623088569, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 2703, "metadata": {"file": "train.py", "lineno": 781}}
:::MLLOG {"namespace": "", "time_ms": 1634623088570, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "lamb", "metadata": {"file": "train.py", "lineno": 783}}
:::MLLOG {"namespace": "", "time_ms": 1634623088570, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.007, "metadata": {"file": "train.py", "lineno": 784}}
:::MLLOG {"namespace": "", "time_ms": 1634623088570, "event_type": "POINT_IN_TIME", "key": "opt_lamb_epsilon", "value": 1e-09, "metadata": {"file": "train.py", "lineno": 785}}
:::MLLOG {"namespace": "", "time_ms": 1634623088570, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 0.935, "metadata": {"file": "train.py", "lineno": 786}}
:::MLLOG {"namespace": "", "time_ms": 1634623088570, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 6, "metadata": {"file": "train.py", "lineno": 787}}
:::MLLOG {"namespace": "", "time_ms": 1634623088570, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_hold_epochs", "value": 33, "metadata": {"file": "train.py", "lineno": 788}}
:::MLLOG {"namespace": "", "time_ms": 1634623088570, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.905, "metadata": {"file": "train.py", "lineno": 789}}
:::MLLOG {"namespace": "", "time_ms": 1634623088570, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.999, "metadata": {"file": "train.py", "lineno": 790}}
:::MLLOG {"namespace": "", "time_ms": 1634623088570, "event_type": "POINT_IN_TIME", "key": "opt_gradient_clip_norm", "value": 1, "metadata": {"file": "train.py", "lineno": 791}}
:::MLLOG {"namespace": "", "time_ms": 1634623088571, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_alt_decay_func", "value": true, "metadata": {"file": "train.py", "lineno": 792}}
:::MLLOG {"namespace": "", "time_ms": 1634623088571, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_alt_warmup_func", "value": true, "metadata": {"file": "train.py", "lineno": 793}}
:::MLLOG {"namespace": "", "time_ms": 1634623088571, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_min", "value": 1e-05, "metadata": {"file": "train.py", "lineno": 794}}
:::MLLOG {"namespace": "", "time_ms": 1634623088571, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.001, "metadata": {"file": "train.py", "lineno": 795}}
Pre-allocate buffer with max_seq_len of 1921 and max_txt_len of 125
:::MLLOG {"namespace": "", "time_ms": 1634623088664, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 1, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623088665, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623094967, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 1}}
DLL 2021-10-19 05:58:14.968112 - epoch    1 | avg train utts/s 44192 | took  6.30 s
:::MLLOG {"namespace": "", "time_ms": 1634623094968, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 44191.83058146079, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623094968, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623095137, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 11.156611889268778, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623095138, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 1}}
DLL 2021-10-19 05:58:15.138512 - epoch    1 |   dev ema wer 1115.66 | took  0.17 s
:::MLLOG {"namespace": "", "time_ms": 1634623095138, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623095138, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 2, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623095139, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634623100358, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 2}}
DLL 2021-10-19 05:58:20.359063 - epoch    2 | avg train utts/s 53361 | took  5.22 s
:::MLLOG {"namespace": "", "time_ms": 1634623100359, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 53360.888437968955, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623100359, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634623100490, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9944303518253006, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634623100491, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 2}}
DLL 2021-10-19 05:58:20.491478 - epoch    2 |   dev ema wer  99.44 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634623100491, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634623100492, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 3, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623100492, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634623105408, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 3}}
DLL 2021-10-19 05:58:25.409023 - epoch    3 | avg train utts/s 56649 | took  4.92 s
:::MLLOG {"namespace": "", "time_ms": 1634623105409, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 56649.38819911482, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623105409, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634623105536, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634623105536, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 3}}
DLL 2021-10-19 05:58:25.537279 - epoch    3 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634623105537, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634623105537, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 4, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623105538, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634623110445, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 4}}
DLL 2021-10-19 05:58:30.445971 - epoch    4 | avg train utts/s 56752 | took  4.91 s
:::MLLOG {"namespace": "", "time_ms": 1634623110446, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 56751.95221187298, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623110446, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634623110574, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9773905371126062, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634623110574, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 4}}
DLL 2021-10-19 05:58:30.575013 - epoch    4 |   dev ema wer  97.74 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634623110575, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634623110575, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 5, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623110575, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634623115320, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 5}}
DLL 2021-10-19 05:58:35.321230 - epoch    5 | avg train utts/s 58695 | took  4.75 s
:::MLLOG {"namespace": "", "time_ms": 1634623115321, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 58694.63947177236, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623115321, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634623115451, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9903312378221389, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634623115452, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 5}}
DLL 2021-10-19 05:58:35.452499 - epoch    5 |   dev ema wer  99.03 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634623115452, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634623115453, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 6, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623115453, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634623120198, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 6}}
DLL 2021-10-19 05:58:40.198803 - epoch    6 | avg train utts/s 58693 | took  4.75 s
:::MLLOG {"namespace": "", "time_ms": 1634623120198, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 58693.2800351045, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623120199, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634623120326, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634623120327, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 6}}
DLL 2021-10-19 05:58:40.327475 - epoch    6 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634623120327, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634623120328, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 7, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623120328, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634623124983, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 7}}
DLL 2021-10-19 05:58:44.983912 - epoch    7 | avg train utts/s 59828 | took  4.66 s
:::MLLOG {"namespace": "", "time_ms": 1634623124984, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59827.7529219538, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623124984, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634623125105, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634623125105, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 7}}
DLL 2021-10-19 05:58:45.106172 - epoch    7 |   dev ema wer 100.00 | took  0.12 s
:::MLLOG {"namespace": "", "time_ms": 1634623125106, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634623125106, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 8, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623125106, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 8}}
DLL 2021-10-19 05:58:46.757059 - epoch    8 | iter   48/136 | loss  238.00 | utts/s  1263 | took  1.62 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634623129765, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 8}}
DLL 2021-10-19 05:58:49.765756 - epoch    8 | avg train utts/s 59786 | took  4.66 s
:::MLLOG {"namespace": "", "time_ms": 1634623129765, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59785.98418390134, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623129765, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634623129873, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634623129873, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 8}}
DLL 2021-10-19 05:58:49.873788 - epoch    8 |   dev ema wer 100.00 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634623129874, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634623129874, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 9, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623129874, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634623134555, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 9}}
DLL 2021-10-19 05:58:54.555960 - epoch    9 | avg train utts/s 59497 | took  4.68 s
:::MLLOG {"namespace": "", "time_ms": 1634623134556, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59497.04610847375, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623134556, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634623134663, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9895224440277931, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634623134664, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 9}}
DLL 2021-10-19 05:58:54.664677 - epoch    9 |   dev ema wer  98.95 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634623134664, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634623134665, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 10, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623134665, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634623139273, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 10}}
DLL 2021-10-19 05:58:59.273788 - epoch   10 | avg train utts/s 60440 | took  4.61 s
:::MLLOG {"namespace": "", "time_ms": 1634623139273, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60439.5280395573, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623139274, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634623139381, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9803683688099702, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634623139381, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 10}}
DLL 2021-10-19 05:58:59.382315 - epoch   10 |   dev ema wer  98.04 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634623139382, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634623139382, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 11, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623139382, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634623144050, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 11}}
DLL 2021-10-19 05:59:04.050474 - epoch   11 | avg train utts/s 59674 | took  4.67 s
:::MLLOG {"namespace": "", "time_ms": 1634623144050, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59674.085826847186, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623144050, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634623144160, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9582552112054704, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634623144160, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 11}}
DLL 2021-10-19 05:59:04.161185 - epoch   11 |   dev ema wer  95.83 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634623144161, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634623144161, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 12, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623144161, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634623148799, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 12}}
DLL 2021-10-19 05:59:08.799545 - epoch   12 | avg train utts/s 60058 | took  4.64 s
:::MLLOG {"namespace": "", "time_ms": 1634623148799, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60057.852057523014, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623148799, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634623148917, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8272306165214515, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634623148918, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 12}}
DLL 2021-10-19 05:59:08.918585 - epoch   12 |   dev ema wer  82.72 | took  0.12 s
:::MLLOG {"namespace": "", "time_ms": 1634623148918, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634623148919, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 13, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623148919, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634623153521, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 13}}
DLL 2021-10-19 05:59:13.521660 - epoch   13 | avg train utts/s 60522 | took  4.60 s
:::MLLOG {"namespace": "", "time_ms": 1634623153521, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60521.73634590448, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623153521, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634623153654, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5386750487114444, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634623153655, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 13}}
DLL 2021-10-19 05:59:13.655498 - epoch   13 |   dev ema wer  53.87 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634623153655, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634623153656, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 14, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623153656, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634623158273, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 14}}
DLL 2021-10-19 05:59:18.273985 - epoch   14 | avg train utts/s 60319 | took  4.62 s
:::MLLOG {"namespace": "", "time_ms": 1634623158274, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60319.44727915006, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623158274, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634623158414, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.33713834050218744, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634623158414, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 14}}
DLL 2021-10-19 05:59:18.415049 - epoch   14 |   dev ema wer  33.71 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634623158415, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634623158415, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 15, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623158415, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 15}}
DLL 2021-10-19 05:59:21.653013 - epoch   15 | iter   96/136 | loss   46.75 | utts/s   638 | took  3.21 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634623162974, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 15}}
DLL 2021-10-19 05:59:22.974509 - epoch   15 | avg train utts/s 61102 | took  4.56 s
:::MLLOG {"namespace": "", "time_ms": 1634623162974, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61101.56379184891, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623162974, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634623163117, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2404139553692879, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634623163117, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 15}}
DLL 2021-10-19 05:59:23.118261 - epoch   15 |   dev ema wer  24.04 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634623163118, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634623163118, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 16, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623163118, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634623167740, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 16}}
DLL 2021-10-19 05:59:27.741341 - epoch   16 | avg train utts/s 60257 | took  4.62 s
:::MLLOG {"namespace": "", "time_ms": 1634623167741, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60256.985668689274, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623167741, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634623167885, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1883754273739936, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634623167885, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 16}}
DLL 2021-10-19 05:59:27.886291 - epoch   16 |   dev ema wer  18.84 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634623167886, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634623167886, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 17, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623167887, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634623172448, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 17}}
DLL 2021-10-19 05:59:32.449001 - epoch   17 | avg train utts/s 61056 | took  4.56 s
:::MLLOG {"namespace": "", "time_ms": 1634623172449, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61055.837767429024, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623172449, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634623172593, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.15813756847174737, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634623172593, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 17}}
DLL 2021-10-19 05:59:32.594270 - epoch   17 |   dev ema wer  15.81 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634623172594, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634623172594, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 18, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623172594, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634623177184, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 18}}
DLL 2021-10-19 05:59:37.184794 - epoch   18 | avg train utts/s 60687 | took  4.59 s
:::MLLOG {"namespace": "", "time_ms": 1634623177184, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60686.63969547567, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623177185, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634623177329, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.13848755560457335, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634623177330, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 18}}
DLL 2021-10-19 05:59:37.330619 - epoch   18 |   dev ema wer  13.85 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623177330, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634623177331, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 19, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623177331, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634623181924, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 19}}
DLL 2021-10-19 05:59:41.925068 - epoch   19 | avg train utts/s 60634 | took  4.59 s
:::MLLOG {"namespace": "", "time_ms": 1634623181925, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60634.45685813918, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623181925, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634623182070, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.12420499246351237, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634623182071, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 19}}
DLL 2021-10-19 05:59:42.071620 - epoch   19 |   dev ema wer  12.42 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623182072, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634623182072, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 20, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623182072, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623186661, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 20}}
DLL 2021-10-19 05:59:46.661966 - epoch   20 | avg train utts/s 60691 | took  4.59 s
:::MLLOG {"namespace": "", "time_ms": 1634623186662, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60690.58690328681, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623186662, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623186807, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.11437079519135326, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623186808, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 20}}
DLL 2021-10-19 05:59:46.808694 - epoch   20 |   dev ema wer  11.44 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623186808, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623186809, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 21, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623186809, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634623191370, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 21}}
DLL 2021-10-19 05:59:51.371079 - epoch   21 | avg train utts/s 61061 | took  4.56 s
:::MLLOG {"namespace": "", "time_ms": 1634623191371, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61060.54165101908, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623191371, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634623191516, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.10727546781368331, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634623191516, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 21}}
DLL 2021-10-19 05:59:51.516988 - epoch   21 |   dev ema wer  10.73 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623191517, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634623191517, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 22, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623191517, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634623196004, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 22}}
DLL 2021-10-19 05:59:56.005287 - epoch   22 | avg train utts/s 62065 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634623196005, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62064.65935245471, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623196005, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634623196151, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.10115436932465718, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634623196151, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 22}}
DLL 2021-10-19 05:59:56.151791 - epoch   22 |   dev ema wer  10.12 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623196152, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634623196152, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 23, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623196152, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 23}}
DLL 2021-10-19 05:59:56.433149 - epoch   23 | iter    8/136 | loss   36.75 | utts/s  8180 | took  0.25 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634623200699, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 23}}
DLL 2021-10-19 06:00:00.700327 - epoch   23 | avg train utts/s 61247 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634623200700, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61247.17702762498, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623200700, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634623200846, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.09541928605565972, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634623200846, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 23}}
DLL 2021-10-19 06:00:00.847114 - epoch   23 |   dev ema wer   9.54 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623200847, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634623200847, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 24, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623200847, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634623205350, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 24}}
DLL 2021-10-19 06:00:05.350536 - epoch   24 | avg train utts/s 61859 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634623205350, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61858.771348279864, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623205350, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634623205496, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.09122826366677696, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634623205497, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 24}}
DLL 2021-10-19 06:00:05.497444 - epoch   24 |   dev ema wer   9.12 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623205497, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634623205497, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 25, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623205498, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634623210063, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 25}}
DLL 2021-10-19 06:00:10.063782 - epoch   25 | avg train utts/s 61009 | took  4.57 s
:::MLLOG {"namespace": "", "time_ms": 1634623210063, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61008.58387618752, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623210064, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634623210209, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08753354656078821, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634623210209, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 25}}
DLL 2021-10-19 06:00:10.210217 - epoch   25 |   dev ema wer   8.75 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623210210, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634623210210, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 26, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623210210, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634623214756, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 26}}
DLL 2021-10-19 06:00:14.756680 - epoch   26 | avg train utts/s 61275 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634623214756, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61274.94890674964, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623214756, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634623214903, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0864674092864233, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634623214903, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 26}}
DLL 2021-10-19 06:00:14.904138 - epoch   26 |   dev ema wer   8.65 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623214904, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634623214904, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 27, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623214904, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634623219429, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 27}}
DLL 2021-10-19 06:00:19.430011 - epoch   27 | avg train utts/s 61553 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634623219430, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61552.833286624606, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623219430, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634623219574, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0844454248005588, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634623219575, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 27}}
DLL 2021-10-19 06:00:19.575415 - epoch   27 |   dev ema wer   8.44 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634623219575, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634623219576, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 28, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623219576, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634623224073, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 28}}
DLL 2021-10-19 06:00:24.073650 - epoch   28 | avg train utts/s 61933 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634623224073, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61932.711678352476, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623224073, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634623224218, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08293812727473254, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634623224219, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 28}}
DLL 2021-10-19 06:00:24.219559 - epoch   28 |   dev ema wer   8.29 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623224219, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634623224219, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 29, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623224220, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634623228762, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 29}}
DLL 2021-10-19 06:00:28.762863 - epoch   29 | avg train utts/s 61316 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634623228762, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61316.433527239686, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623228763, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634623228909, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08043821918311826, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634623228909, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 29}}
DLL 2021-10-19 06:00:28.910051 - epoch   29 |   dev ema wer   8.04 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623228910, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634623228910, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 30, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623228910, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 30}}
DLL 2021-10-19 06:00:30.793405 - epoch   30 | iter   56/136 | loss   39.59 | utts/s  1101 | took  1.86 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634623233453, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 30}}
DLL 2021-10-19 06:00:33.453899 - epoch   30 | avg train utts/s 61307 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634623233454, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61307.417208169616, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623233454, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634623233599, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07951913532590714, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634623233600, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 30}}
DLL 2021-10-19 06:00:33.600554 - epoch   30 |   dev ema wer   7.95 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623233600, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634623233601, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 31, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623233601, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634623238158, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 31}}
DLL 2021-10-19 06:00:38.158936 - epoch   31 | avg train utts/s 61115 | took  4.56 s
:::MLLOG {"namespace": "", "time_ms": 1634623238159, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61115.03054974389, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623238159, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634623238305, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07865519650012867, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634623238305, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 31}}
DLL 2021-10-19 06:00:38.305839 - epoch   31 |   dev ema wer   7.87 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623238306, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634623238306, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 32, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623238306, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634623242819, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 32}}
DLL 2021-10-19 06:00:42.820316 - epoch   32 | avg train utts/s 61708 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634623242820, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61708.37124039662, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623242820, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634623242968, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07690893717142752, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634623242969, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 32}}
DLL 2021-10-19 06:00:42.969666 - epoch   32 |   dev ema wer   7.69 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623242969, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634623242969, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 33, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623242970, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634623247452, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 33}}
DLL 2021-10-19 06:00:47.452583 - epoch   33 | avg train utts/s 62142 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634623247452, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62141.572015015285, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623247452, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634623247598, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07637586853424506, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634623247598, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 33}}
DLL 2021-10-19 06:00:47.599330 - epoch   33 |   dev ema wer   7.64 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623247599, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634623247599, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 34, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623247600, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634623252121, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 34}}
DLL 2021-10-19 06:00:52.122213 - epoch   34 | avg train utts/s 61594 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634623252122, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61594.2340069362, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623252122, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634623252268, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07411492224550568, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634623252268, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 34}}
DLL 2021-10-19 06:00:52.268900 - epoch   34 |   dev ema wer   7.41 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623252269, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634623252269, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 35, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623252269, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634623256774, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 35}}
DLL 2021-10-19 06:00:56.774639 - epoch   35 | avg train utts/s 61827 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634623256774, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61826.6949209574, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623256774, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634623256920, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07402301385978456, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634623256921, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 35}}
DLL 2021-10-19 06:00:56.921423 - epoch   35 |   dev ema wer   7.40 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623256921, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634623256921, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 36, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623256922, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634623261460, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 36}}
DLL 2021-10-19 06:01:01.461090 - epoch   36 | avg train utts/s 61366 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634623261461, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61366.23190071353, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623261461, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634623261606, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07407815889121723, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634623261606, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 36}}
DLL 2021-10-19 06:01:01.607255 - epoch   36 |   dev ema wer   7.41 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623261607, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634623261607, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 37, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623261607, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 37}}
DLL 2021-10-19 06:01:05.103162 - epoch   37 | iter  104/136 | loss   38.91 | utts/s   591 | took  3.47 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634623266146, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 37}}
DLL 2021-10-19 06:01:06.146452 - epoch   37 | avg train utts/s 61371 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634623266146, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61370.63554278024, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623266146, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634623266293, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0727546781368332, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634623266294, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 37}}
DLL 2021-10-19 06:01:06.294486 - epoch   37 |   dev ema wer   7.28 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623266294, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634623266294, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 38, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623266295, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634623270813, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 38}}
DLL 2021-10-19 06:01:10.813859 - epoch   38 | avg train utts/s 61639 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634623270813, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61639.46938451394, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623270814, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634623270959, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07159663247674718, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634623270959, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 38}}
DLL 2021-10-19 06:01:10.960120 - epoch   38 |   dev ema wer   7.16 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623270960, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634623270960, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 39, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623270960, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634623275520, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 39}}
DLL 2021-10-19 06:01:15.521270 - epoch   39 | avg train utts/s 61076 | took  4.56 s
:::MLLOG {"namespace": "", "time_ms": 1634623275521, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61076.13922040334, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623275521, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634623275667, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07124738061100695, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634623275667, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 39}}
DLL 2021-10-19 06:01:15.668170 - epoch   39 |   dev ema wer   7.12 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623275668, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634623275668, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 40, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623275668, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634623280157, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 40}}
DLL 2021-10-19 06:01:20.157584 - epoch   40 | avg train utts/s 62054 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634623280157, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62054.01086335908, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623280157, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634623280303, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07157825079960295, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634623280303, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 40}}
DLL 2021-10-19 06:01:20.303879 - epoch   40 |   dev ema wer   7.16 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623280304, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634623280304, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 41, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623280304, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634623284789, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 41}}
DLL 2021-10-19 06:01:24.790139 - epoch   41 | avg train utts/s 62097 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634623284790, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62097.18788406729, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623284790, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634623284936, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07027315172236315, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634623284936, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 41}}
DLL 2021-10-19 06:01:24.936705 - epoch   41 |   dev ema wer   7.03 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623284936, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634623284937, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 42, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623284937, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634623289468, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 42}}
DLL 2021-10-19 06:01:29.468785 - epoch   42 | avg train utts/s 61467 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634623289468, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61467.31035913906, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623289469, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634623289614, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06961141134517114, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634623289614, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 42}}
DLL 2021-10-19 06:01:29.615046 - epoch   42 |   dev ema wer   6.96 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623289615, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634623289615, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 43, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623289615, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634623294181, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 43}}
DLL 2021-10-19 06:01:34.182264 - epoch   43 | avg train utts/s 60995 | took  4.57 s
:::MLLOG {"namespace": "", "time_ms": 1634623294182, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60995.03022844072, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623294182, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634623294328, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0681224954964891, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634623294328, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 43}}
DLL 2021-10-19 06:01:34.329341 - epoch   43 |   dev ema wer   6.81 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623294329, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634623294329, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 44, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623294329, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634623298818, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 44}}
DLL 2021-10-19 06:01:38.819017 - epoch   44 | avg train utts/s 62048 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634623298819, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62048.157399481286, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623298819, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634623298964, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06744237344215286, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634623298964, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 44}}
DLL 2021-10-19 06:01:38.965289 - epoch   44 |   dev ema wer   6.74 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623298965, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634623298965, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 45, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623298966, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 45}}
DLL 2021-10-19 06:01:39.517509 - epoch   45 | iter   16/136 | loss   37.50 | utts/s  3890 | took  0.53 s | lrate 4.68e-03
:::MLLOG {"namespace": "", "time_ms": 1634623303453, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 45}}
DLL 2021-10-19 06:01:43.454404 - epoch   45 | avg train utts/s 62059 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634623303454, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62059.370915350286, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623303454, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634623303600, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06494246535053859, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634623303600, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 45}}
DLL 2021-10-19 06:01:43.600837 - epoch   45 |   dev ema wer   6.49 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623303601, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634623303601, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 46, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623303601, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634623308112, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 46}}
DLL 2021-10-19 06:01:48.112524 - epoch   46 | avg train utts/s 61749 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634623308112, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61749.452769797805, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623308112, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634623308257, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06424396161905813, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634623308258, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 46}}
DLL 2021-10-19 06:01:48.258715 - epoch   46 |   dev ema wer   6.42 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623308259, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634623308259, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 47, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623308259, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634623312739, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 47}}
DLL 2021-10-19 06:01:52.740168 - epoch   47 | avg train utts/s 62164 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634623312740, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62164.31548875113, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623312740, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634623312885, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06326973273041432, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634623312886, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 47}}
DLL 2021-10-19 06:01:52.886506 - epoch   47 |   dev ema wer   6.33 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623312886, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634623312887, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 48, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623312887, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634623317419, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 48}}
DLL 2021-10-19 06:01:57.420059 - epoch   48 | avg train utts/s 61449 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634623317420, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61449.013773375525, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623317420, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634623317565, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06299400757325098, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634623317565, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 48}}
DLL 2021-10-19 06:01:57.566303 - epoch   48 |   dev ema wer   6.30 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623317566, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634623317566, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 49, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623317567, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634623322096, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 49}}
DLL 2021-10-19 06:02:02.096965 - epoch   49 | avg train utts/s 61490 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634623322097, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61489.990089437604, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623322097, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634623322242, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06334325943899122, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634623322243, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 49}}
DLL 2021-10-19 06:02:02.243458 - epoch   49 |   dev ema wer   6.33 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623322243, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634623322244, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 50, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623322244, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634623326776, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 50}}
DLL 2021-10-19 06:02:06.777379 - epoch   50 | avg train utts/s 61447 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634623326777, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61447.378312998255, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623326777, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634623326921, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06251608396750119, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634623326922, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 50}}
DLL 2021-10-19 06:02:06.922559 - epoch   50 |   dev ema wer   6.25 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634623326923, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634623326923, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 51, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623326923, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634623331424, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 51}}
DLL 2021-10-19 06:02:11.425318 - epoch   51 | avg train utts/s 61872 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634623331425, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61871.78098078621, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623331425, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634623331569, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.060898496378809605, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634623331570, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 51}}
DLL 2021-10-19 06:02:11.570641 - epoch   51 |   dev ema wer   6.09 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634623331570, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634623331571, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 52, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623331571, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 52}}
DLL 2021-10-19 06:02:13.727430 - epoch   52 | iter   64/136 | loss   41.44 | utts/s   961 | took  2.13 s | lrate 2.92e-03
:::MLLOG {"namespace": "", "time_ms": 1634623336093, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 52}}
DLL 2021-10-19 06:02:16.093476 - epoch   52 | avg train utts/s 61593 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634623336093, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61592.91554350373, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623336093, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634623336237, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05906032866438734, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634623336237, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 52}}
DLL 2021-10-19 06:02:16.238352 - epoch   52 |   dev ema wer   5.91 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634623336238, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634623336238, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 53, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623336238, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634623340786, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 53}}
DLL 2021-10-19 06:02:20.786436 - epoch   53 | avg train utts/s 61251 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634623340786, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61250.85065802278, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623340786, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634623340932, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05893165692437778, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634623340932, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 53}}
DLL 2021-10-19 06:02:20.933049 - epoch   53 |   dev ema wer   5.89 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623340933, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634623340933, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 54, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623340933, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634623345432, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 54}}
DLL 2021-10-19 06:02:25.433023 - epoch   54 | avg train utts/s 61910 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634623345433, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61910.366992361356, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623345433, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634623345577, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.059189000404396896, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634623345577, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 54}}
DLL 2021-10-19 06:02:25.578312 - epoch   54 |   dev ema wer   5.92 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634623345578, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634623345578, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 55, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623345578, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634623350049, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 55}}
DLL 2021-10-19 06:02:30.050081 - epoch   55 | avg train utts/s 62296 | took  4.47 s
:::MLLOG {"namespace": "", "time_ms": 1634623350050, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62295.52882371288, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623350050, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634623350194, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.058839748538656665, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634623350195, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 55}}
DLL 2021-10-19 06:02:30.195399 - epoch   55 |   dev ema wer   5.88 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634623350195, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634623350195, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 56, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623350196, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634623354678, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 56}}
DLL 2021-10-19 06:02:34.678729 - epoch   56 | avg train utts/s 62138 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634623354678, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62137.645342316544, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623354678, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634623354824, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.058766221830079776, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634623354824, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 56}}
DLL 2021-10-19 06:02:34.824983 - epoch   56 |   dev ema wer   5.88 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634623354825, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634623354825, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 57, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623354825, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1634623359325, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 57}}
DLL 2021-10-19 06:02:39.326246 - epoch   57 | avg train utts/s 61889 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634623359326, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61888.50726330925, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634623359326, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1634623359470, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05733245101283041, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1634623359470, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 57}}
DLL 2021-10-19 06:02:39.471203 - epoch   57 |   dev ema wer   5.73 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634623359471, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1634623359471, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1028, "status": "success"}}
Finished after 0 epochs.
DLL 2021-10-19 06:02:39.471955 -  | avg train utts/s 58625
ENDING TIMING RUN AT 2021-10-19 06:02:55 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:56 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:57 AM
ENDING TIMING RUN AT 2021-10-19 06:02:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:55:54 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:57 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:58 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:02:59 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:00 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:01 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:02 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:03 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:04 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:04 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:55:54 AM
ENDING TIMING RUN AT 2021-10-19 06:03:04 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 05:55:54 AM
