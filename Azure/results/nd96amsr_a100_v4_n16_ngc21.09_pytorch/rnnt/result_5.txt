+ : DGXA100_16x8x16x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/rnntv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019061814619216766
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets
+ : /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ : ./api_logs
+ : 18511
+ : 30
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized
+ LOGBASE=rnnt_16x8x16_211019061814619216766
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019061814619216766
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019061814619216766
+ readonly _cont_name=rnn_speech_recognition
+ _cont_name=rnn_speech_recognition
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets:/datasets/,/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743:/results
+ _cont_mounts+=,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized:/metadata
+ _cont_mounts+=,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets/sentencepieces:/sentencepieces
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07412/slurm_script: line 43: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ srun --ntasks=16 mkdir -p /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ srun --ntasks=16 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/rnntv11.sqsh --container-name=rnn_speech_recognition true
+ [[ DGXA100_16x8x16x1 == \D\G\X\A\1\0\0* ]]
+ echo 'using NCCL_TOPO_FILE /opt/microsoft/ndv4-topo.xml'
using NCCL_TOPO_FILE /opt/microsoft/ndv4-topo.xml
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019061814619216766_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ srun --nodes=1 --ntasks=1 --container-name=rnn_speech_recognition python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=16 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C04DD
Clearing cache on ip-0A0C04E9
Clearing cache on ip-0A0C04EA
Clearing cache on ip-0A0C04E4
Clearing cache on ip-0A0C04C1
Clearing cache on ip-0A0C04E5
Clearing cache on ip-0A0C04ED
Clearing cache on ip-0A0C04DE
Clearing cache on ip-0A0C04DF
Clearing cache on ip-0A0C04EB
Clearing cache on ip-0A0C04B8
Clearing cache on ip-0A0C04E1
Clearing cache on ip-0A0C04E7
Clearing cache on ip-0A0C04EF
Clearing cache on ip-0A0C04EE
Clearing cache on ip-0A0C04E8
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=16 --container-name=rnn_speech_recognition python -c '
from mlperf import logging
logging.log_event(key=logging.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1634624305338, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305389, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305397, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305413, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305401, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305432, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305429, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305445, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305447, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305453, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305454, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305471, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305489, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305501, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305501, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624305521, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ SEED=18512
+ srun --mpi=none --ntasks=128 --ntasks-per-node=8 --container-name=rnn_speech_recognition --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets:/datasets/,/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743:/results,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized:/metadata,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets/sentencepieces:/sentencepieces,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
running benchmark
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 06:18:26 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointt=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointt=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 18512 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
:::MLLOG {"namespace": "", "time_ms": 1634624310809, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310815, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310838, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310847, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310868, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310861, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310880, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310886, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310924, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310933, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310931, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310932, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310933, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310935, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310941, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310941, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310963, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310977, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310969, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310969, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310976, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310978, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310984, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310986, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310997, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624310996, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311001, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311005, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311003, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311008, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311025, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311030, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311032, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311033, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311037, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311036, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311039, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311042, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311043, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311048, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311052, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311056, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311063, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311063, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311079, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311065, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311072, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311074, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311075, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311081, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311088, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311088, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311093, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311094, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311092, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311095, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311094, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311103, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311101, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311102, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311102, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311109, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311109, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311121, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311113, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311125, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311125, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311125, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311125, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311129, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311132, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311135, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311136, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311139, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311140, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311151, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311144, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311147, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311146, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311150, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311150, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311152, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311163, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311167, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311167, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311168, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311181, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311173, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311179, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311184, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311187, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311198, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311197, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311199, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311201, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311206, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311216, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311215, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311216, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311216, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311220, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311223, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311223, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311224, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311225, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311229, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311229, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311233, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311229, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311239, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311239, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311239, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311241, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311242, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311249, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311247, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311252, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311257, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311258, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311264, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311268, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311267, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311270, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311276, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311277, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311284, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634624311294, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
Distributed training with 128 GPUs

:::MLLOG {"namespace": "", "time_ms": 1634624312337, "event_type": "POINT_IN_TIME", "key": "seed", "value": 18512, "metadata": {"file": "train.py", "lineno": 421}}
DLL 2021-10-19 06:18:32.341858 - PARAMETER | epochs :  80
DLL 2021-10-19 06:18:32.341980 - PARAMETER | warmup_epochs :  6
DLL 2021-10-19 06:18:32.342026 - PARAMETER | hold_epochs :  33
DLL 2021-10-19 06:18:32.342059 - PARAMETER | epochs_this_job :  0
DLL 2021-10-19 06:18:32.342088 - PARAMETER | cudnn_benchmark :  True
DLL 2021-10-19 06:18:32.342116 - PARAMETER | amp_level :  2
DLL 2021-10-19 06:18:32.342145 - PARAMETER | seed :  18512
DLL 2021-10-19 06:18:32.342171 - PARAMETER | local_rank :  0
DLL 2021-10-19 06:18:32.342210 - PARAMETER | target :  0.058
DLL 2021-10-19 06:18:32.342284 - PARAMETER | apex_transducer_loss :  fp16
DLL 2021-10-19 06:18:32.342315 - PARAMETER | fuse_relu_dropout :  True
DLL 2021-10-19 06:18:32.342376 - PARAMETER | weights_init_scale :  0.5
DLL 2021-10-19 06:18:32.342402 - PARAMETER | hidden_hidden_bias_scale : 
DLL 2021-10-19 06:18:32.342423 - PARAMETER | batch_eval_mode :  cg_unroll_pipeline
DLL 2021-10-19 06:18:32.342444 - PARAMETER | cg_unroll_factor :  4
DLL 2021-10-19 06:18:32.342463 - PARAMETER | apex_transducer_joint :  pack_w_relu_dropout
DLL 2021-10-19 06:18:32.342482 - PARAMETER | buffer_pre_alloc :  True
DLL 2021-10-19 06:18:32.342501 - PARAMETER | multilayer_lstm :  False
DLL 2021-10-19 06:18:32.342521 - PARAMETER | batch_split_factor :  1
DLL 2021-10-19 06:18:32.342540 - PARAMETER | apex_mlp :  True
DLL 2021-10-19 06:18:32.342560 - PARAMETER | num_cg :  50
DLL 2021-10-19 06:18:32.342578 - PARAMETER | min_seq_split_len :  -1
DLL 2021-10-19 06:18:32.342600 - PARAMETER | pre_sort_for_seq_split :  False
DLL 2021-10-19 06:18:32.342622 - PARAMETER | batch_size :  16
DLL 2021-10-19 06:18:32.342640 - PARAMETER | val_batch_size :  22
DLL 2021-10-19 06:18:32.342658 - PARAMETER | lr :  0.007
DLL 2021-10-19 06:18:32.342678 - PARAMETER | min_lr :  1e-05
DLL 2021-10-19 06:18:32.342725 - PARAMETER | lr_exp_gamma :  0.935
DLL 2021-10-19 06:18:32.342747 - PARAMETER | weight_decay :  0.001
DLL 2021-10-19 06:18:32.342767 - PARAMETER | grad_accumulation_steps :  1
DLL 2021-10-19 06:18:32.342787 - PARAMETER | clip_norm :  1
DLL 2021-10-19 06:18:32.342806 - PARAMETER | beta1 :  0.905
DLL 2021-10-19 06:18:32.342825 - PARAMETER | beta2 :  0.999
DLL 2021-10-19 06:18:32.342846 - PARAMETER | ema :  0.995
DLL 2021-10-19 06:18:32.342865 - PARAMETER | multi_tensor_ema :  True
DLL 2021-10-19 06:18:32.342883 - PARAMETER | dist_lamb :  True
DLL 2021-10-19 06:18:32.342901 - PARAMETER | ema_update_type :  fp16
DLL 2021-10-19 06:18:32.342921 - PARAMETER | dwu_group_size :  8
DLL 2021-10-19 06:18:32.342941 - PARAMETER | dwu_overlap_reduction :  True
DLL 2021-10-19 06:18:32.342960 - PARAMETER | dali_device :  gpu
DLL 2021-10-19 06:18:32.342978 - PARAMETER | resume :  False
DLL 2021-10-19 06:18:32.342997 - PARAMETER | ckpt : 
DLL 2021-10-19 06:18:32.343017 - PARAMETER | save_at_the_end :  False
DLL 2021-10-19 06:18:32.343035 - PARAMETER | save_frequency : 
DLL 2021-10-19 06:18:32.343053 - PARAMETER | keep_milestones :  []
DLL 2021-10-19 06:18:32.343080 - PARAMETER | save_best_from :  200
DLL 2021-10-19 06:18:32.343100 - PARAMETER | val_frequency :  1
DLL 2021-10-19 06:18:32.343119 - PARAMETER | log_frequency :  1000
DLL 2021-10-19 06:18:32.343137 - PARAMETER | prediction_frequency :  1000000
DLL 2021-10-19 06:18:32.343161 - PARAMETER | model_config :  configs/baseline_v3-1023sp.yaml
DLL 2021-10-19 06:18:32.343180 - PARAMETER | num_buckets :  1
DLL 2021-10-19 06:18:32.343198 - PARAMETER | vectorized_sampler :  True
DLL 2021-10-19 06:18:32.343221 - PARAMETER | dist_sampler :  True
DLL 2021-10-19 06:18:32.343240 - PARAMETER | train_manifests :  ['/metadata/librispeech-train-clean-100-wav-tokenized.pkl', '/metadata/librispeech-train-clean-360-wav-tokenized.pkl', '/metadata/librispeech-train-other-500-wav-tokenized.pkl']
DLL 2021-10-19 06:18:32.343267 - PARAMETER | val_manifests :  ['/metadata/librispeech-dev-clean-wav-tokenized.pkl']
DLL 2021-10-19 06:18:32.343292 - PARAMETER | max_duration :  16.7
DLL 2021-10-19 06:18:32.343316 - PARAMETER | max_txt_len :  125
DLL 2021-10-19 06:18:32.343335 - PARAMETER | max_eval_sample_duration :  32.7
DLL 2021-10-19 06:18:32.343355 - PARAMETER | dataset_dir :  /datasets/LibriSpeech
DLL 2021-10-19 06:18:32.343373 - PARAMETER | output_dir :  /results
DLL 2021-10-19 06:18:32.343397 - PARAMETER | log_file : 
DLL 2021-10-19 06:18:32.343415 - PARAMETER | max_symbol_per_sample :  300
DLL 2021-10-19 06:18:32.343433 - PARAMETER | data_cpu_threads :  8
DLL 2021-10-19 06:18:32.343456 - PARAMETER | synthetic_audio_seq_len : 
DLL 2021-10-19 06:18:32.343475 - PARAMETER | synthetic_text_seq_len : 
DLL 2021-10-19 06:18:32.343495 - PARAMETER | enable_seq_len_stats :  False
DLL 2021-10-19 06:18:32.343513 - PARAMETER | vectorized_sa :  True
DLL 2021-10-19 06:18:32.343536 - PARAMETER | in_mem_file_list :  False
DLL 2021-10-19 06:18:32.343555 - PARAMETER | enable_prefetch :  True
DLL 2021-10-19 06:18:32.343576 - PARAMETER | tokenized_transcript :  True
DLL 2021-10-19 06:18:32.343597 - PARAMETER | dali_dont_use_mmap :  False
:::MLLOG {"namespace": "", "time_ms": 1634624312366, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "train.py", "lineno": 438}}
:::MLLOG {"namespace": "", "time_ms": 1634624312367, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "rnnt", "metadata": {"file": "train.py", "lineno": 445}}
:::MLLOG {"namespace": "", "time_ms": 1634624312367, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "train.py", "lineno": 446}}
:::MLLOG {"namespace": "", "time_ms": 1634624312367, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "train.py", "lineno": 447}}
:::MLLOG {"namespace": "", "time_ms": 1634624312367, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "train.py", "lineno": 448}}
:::MLLOG {"namespace": "", "time_ms": 1634624312367, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "16xND96amsr_A100_v4", "metadata": {"file": "train.py", "lineno": 449}}
:::MLLOG {"namespace": "", "time_ms": 1634624312369, "event_type": "POINT_IN_TIME", "key": "model_weights_initialization_scale", "value": 0.5, "metadata": {"file": "train.py", "lineno": 456}}
:::MLLOG {"namespace": "", "time_ms": 1634624312472, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "pre_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634624312623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "post_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634624312628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 201, "tensor": "pred_embed"}}
:::MLLOG {"namespace": "", "time_ms": 1634624312652, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "dec_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634624312654, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 221, "tensor": "joint_pred"}}
:::MLLOG {"namespace": "", "time_ms": 1634624312657, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 226, "tensor": "joint_enc"}}
:::MLLOG {"namespace": "", "time_ms": 1634624312664, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 243, "tensor": "joint_net"}}
:::MLLOG {"namespace": "", "time_ms": 1634624315807, "event_type": "POINT_IN_TIME", "key": "eval_max_prediction_symbols", "value": 300, "metadata": {"file": "train.py", "lineno": 483}}
Model size: 49.1M params

:::MLLOG {"namespace": "", "time_ms": 1634624315825, "event_type": "POINT_IN_TIME", "key": "model_eval_ema_factor", "value": 0.995, "metadata": {"file": "train.py", "lineno": 497}}
[ip-0A0C04DD:0:57180 - context.c:584] INFO job (ID: 867749451395359601) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:57180 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:57180 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:57178 - context.c:584] INFO job (ID: 867749279918102672) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:57178 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:57178 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:57177 - context.c:584] INFO job (ID: 867749300804095012) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:57177 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:57177 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:57176 - context.c:584] INFO job (ID: 867749072454381482) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:57176 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:57176 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:57181 - context.c:584] INFO job (ID: 867749207930733678) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:57181 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:57181 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:57179 - context.c:584] INFO job (ID: 867748964399114323) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:57179 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:57179 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:57183 - context.c:584] INFO job (ID: 867749924362578723) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:57183 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:57183 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:57182 - context.c:584] INFO job (ID: 867749680427231877) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:57182 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:57182 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
Starting with LRs: 0.007000000216066837
Setting up datasets...
:::MLLOG {"namespace": "", "time_ms": 1634624345738, "event_type": "POINT_IN_TIME", "key": "data_train_max_duration", "value": 16.7, "metadata": {"file": "train.py", "lineno": 568}}
:::MLLOG {"namespace": "", "time_ms": 1634624345738, "event_type": "POINT_IN_TIME", "key": "data_speed_perturbaton_max", "value": 1.15, "metadata": {"file": "train.py", "lineno": 570}}
:::MLLOG {"namespace": "", "time_ms": 1634624345738, "event_type": "POINT_IN_TIME", "key": "data_speed_perturbaton_min", "value": 0.85, "metadata": {"file": "train.py", "lineno": 572}}
:::MLLOG {"namespace": "", "time_ms": 1634624345738, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_n", "value": 2, "metadata": {"file": "train.py", "lineno": 574}}
:::MLLOG {"namespace": "", "time_ms": 1634624345738, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_min", "value": 0, "metadata": {"file": "train.py", "lineno": 576}}
:::MLLOG {"namespace": "", "time_ms": 1634624345738, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_max", "value": 20, "metadata": {"file": "train.py", "lineno": 578}}
:::MLLOG {"namespace": "", "time_ms": 1634624345738, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_n", "value": 10, "metadata": {"file": "train.py", "lineno": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634624345738, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_min", "value": 0, "metadata": {"file": "train.py", "lineno": 582}}
:::MLLOG {"namespace": "", "time_ms": 1634624345738, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_max", "value": 0.03, "metadata": {"file": "train.py", "lineno": 584}}
:::MLLOG {"namespace": "", "time_ms": 1634624345739, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 2048, "metadata": {"file": "train.py", "lineno": 586}}
Graph with max_seq_len of 641
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
:::MLLOG {"namespace": "", "time_ms": 1634624436590, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train.py", "lineno": 691}}
:::MLLOG {"namespace": "", "time_ms": 1634624436844, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "train.py", "lineno": 694}}
:::MLLOG {"namespace": "", "time_ms": 1634624436851, "event_type": "POINT_IN_TIME", "key": "data_train_num_buckets", "value": 1, "metadata": {"file": "train.py", "lineno": 700}}
Launching vectorized bucketing sampler
Launching simple sampler
Dataset read by DALI. Number of samples: 278528
Initializing DALI with parameters:
	           dither : 1e-05
	    dont_use_mmap : False
	        file_root : /datasets/LibriSpeech
	     gpu_pipeline : True
	 in_mem_file_list : False
	             nfft : 512
	          nfilter : 80
	   resample_range : [0.85, 1.15]
	      sample_rate : 16000
	          sampler : <common.data.dali.sampler.VectorizedBucketingSampler object at 0x148220b1b2e0>
	   spect_wind_len : 320.0
	  spect_wind_step : 160.0
	synthetic_seq_len : None
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
Dataset read by DALI. Number of samples: 2703
Initializing DALI with parameters:
	           dither : 1e-05
	    dont_use_mmap : False
	        file_root : /datasets/LibriSpeech
	     gpu_pipeline : True
	 in_mem_file_list : False
	             nfft : 512
	          nfilter : 80
	   resample_range : None
	      sample_rate : 16000
	          sampler : <common.data.dali.sampler.SimpleSampler object at 0x148220af4220>
	   spect_wind_len : 320.0
	  spect_wind_step : 160.0
	synthetic_seq_len : None
:::MLLOG {"namespace": "", "time_ms": 1634624441277, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 278528, "metadata": {"file": "train.py", "lineno": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634624441277, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 2703, "metadata": {"file": "train.py", "lineno": 781}}
:::MLLOG {"namespace": "", "time_ms": 1634624441278, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "lamb", "metadata": {"file": "train.py", "lineno": 783}}
:::MLLOG {"namespace": "", "time_ms": 1634624441278, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.007, "metadata": {"file": "train.py", "lineno": 784}}
:::MLLOG {"namespace": "", "time_ms": 1634624441278, "event_type": "POINT_IN_TIME", "key": "opt_lamb_epsilon", "value": 1e-09, "metadata": {"file": "train.py", "lineno": 785}}
:::MLLOG {"namespace": "", "time_ms": 1634624441278, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 0.935, "metadata": {"file": "train.py", "lineno": 786}}
:::MLLOG {"namespace": "", "time_ms": 1634624441278, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 6, "metadata": {"file": "train.py", "lineno": 787}}
:::MLLOG {"namespace": "", "time_ms": 1634624441278, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_hold_epochs", "value": 33, "metadata": {"file": "train.py", "lineno": 788}}
:::MLLOG {"namespace": "", "time_ms": 1634624441278, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.905, "metadata": {"file": "train.py", "lineno": 789}}
:::MLLOG {"namespace": "", "time_ms": 1634624441278, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.999, "metadata": {"file": "train.py", "lineno": 790}}
:::MLLOG {"namespace": "", "time_ms": 1634624441278, "event_type": "POINT_IN_TIME", "key": "opt_gradient_clip_norm", "value": 1, "metadata": {"file": "train.py", "lineno": 791}}
:::MLLOG {"namespace": "", "time_ms": 1634624441278, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_alt_decay_func", "value": true, "metadata": {"file": "train.py", "lineno": 792}}
:::MLLOG {"namespace": "", "time_ms": 1634624441279, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_alt_warmup_func", "value": true, "metadata": {"file": "train.py", "lineno": 793}}
:::MLLOG {"namespace": "", "time_ms": 1634624441279, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_min", "value": 1e-05, "metadata": {"file": "train.py", "lineno": 794}}
:::MLLOG {"namespace": "", "time_ms": 1634624441279, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.001, "metadata": {"file": "train.py", "lineno": 795}}
Pre-allocate buffer with max_seq_len of 1921 and max_txt_len of 125
:::MLLOG {"namespace": "", "time_ms": 1634624441361, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 1, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624441361, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624447685, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 1}}
DLL 2021-10-19 06:20:47.685459 - epoch    1 | avg train utts/s 44046 | took  6.32 s
:::MLLOG {"namespace": "", "time_ms": 1634624447685, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 44046.116832739455, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624447685, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624447856, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 8.490533436270725, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624447856, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 1}}
DLL 2021-10-19 06:20:47.857357 - epoch    1 |   dev ema wer 849.05 | took  0.17 s
:::MLLOG {"namespace": "", "time_ms": 1634624447857, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624447857, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 2, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624447857, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634624453034, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 2}}
DLL 2021-10-19 06:20:53.035245 - epoch    2 | avg train utts/s 53800 | took  5.18 s
:::MLLOG {"namespace": "", "time_ms": 1634624453035, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 53799.59317095856, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624453035, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634624453148, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9886952685563031, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634624453148, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 2}}
DLL 2021-10-19 06:20:53.149215 - epoch    2 |   dev ema wer  98.87 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634624453149, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634624453149, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 3, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624453149, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624458125, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 3}}
DLL 2021-10-19 06:20:58.125477 - epoch    3 | avg train utts/s 55980 | took  4.98 s
:::MLLOG {"namespace": "", "time_ms": 1634624458125, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 55980.257086966, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624458125, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624458251, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624458251, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 3}}
DLL 2021-10-19 06:20:58.252375 - epoch    3 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634624458252, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634624458252, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 4, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624458253, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634624463084, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 4}}
DLL 2021-10-19 06:21:03.085031 - epoch    4 | avg train utts/s 57644 | took  4.83 s
:::MLLOG {"namespace": "", "time_ms": 1634624463085, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 57643.77188812472, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624463085, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634624463218, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9773905371126062, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634624463218, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 4}}
DLL 2021-10-19 06:21:03.218980 - epoch    4 |   dev ema wer  97.74 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634624463219, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634624463219, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 5, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624463219, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634624467945, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 5}}
DLL 2021-10-19 06:21:07.945499 - epoch    5 | avg train utts/s 58939 | took  4.73 s
:::MLLOG {"namespace": "", "time_ms": 1634624467945, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 58938.51862679027, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624467945, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634624468075, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9773905371126062, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634624468075, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 5}}
DLL 2021-10-19 06:21:08.076144 - epoch    5 |   dev ema wer  97.74 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634624468076, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634624468076, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 6, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624468076, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634624472831, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 6}}
DLL 2021-10-19 06:21:12.831566 - epoch    6 | avg train utts/s 58582 | took  4.75 s
:::MLLOG {"namespace": "", "time_ms": 1634624472831, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 58581.97017684444, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624472831, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634624472961, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634624472961, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 6}}
DLL 2021-10-19 06:21:12.961886 - epoch    6 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634624472962, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634624472962, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 7, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624472962, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634624477751, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 7}}
DLL 2021-10-19 06:21:17.751400 - epoch    7 | avg train utts/s 58164 | took  4.79 s
:::MLLOG {"namespace": "", "time_ms": 1634624477751, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 58163.86440901421, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624477751, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634624477874, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634624477874, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 7}}
DLL 2021-10-19 06:21:17.874777 - epoch    7 |   dev ema wer 100.00 | took  0.12 s
:::MLLOG {"namespace": "", "time_ms": 1634624477874, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634624477875, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 8, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624477875, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 8}}
DLL 2021-10-19 06:21:19.526647 - epoch    8 | iter   48/136 | loss  244.50 | utts/s  1263 | took  1.62 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634624482545, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 8}}
DLL 2021-10-19 06:21:22.546214 - epoch    8 | avg train utts/s 59633 | took  4.67 s
:::MLLOG {"namespace": "", "time_ms": 1634624482546, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59633.012252261855, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624482546, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634624482653, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634624482653, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 8}}
DLL 2021-10-19 06:21:22.653956 - epoch    8 |   dev ema wer 100.00 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634624482654, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634624482654, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 9, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624482654, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634624487233, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 9}}
DLL 2021-10-19 06:21:27.233523 - epoch    9 | avg train utts/s 60833 | took  4.58 s
:::MLLOG {"namespace": "", "time_ms": 1634624487233, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60832.75356704667, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624487233, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634624487342, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9867651924561597, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634624487342, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 9}}
DLL 2021-10-19 06:21:27.342668 - epoch    9 |   dev ema wer  98.68 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634624487342, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634624487343, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 10, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624487343, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634624491967, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 10}}
DLL 2021-10-19 06:21:31.967566 - epoch   10 | avg train utts/s 60233 | took  4.62 s
:::MLLOG {"namespace": "", "time_ms": 1634624491967, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60233.28068322376, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624491967, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634624492078, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9487886474761957, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634624492078, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 10}}
DLL 2021-10-19 06:21:32.078830 - epoch   10 |   dev ema wer  94.88 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634624492078, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634624492079, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 11, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624492079, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634624496688, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 11}}
DLL 2021-10-19 06:21:36.689320 - epoch   11 | avg train utts/s 60422 | took  4.61 s
:::MLLOG {"namespace": "", "time_ms": 1634624496689, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60422.20375208688, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624496689, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634624496811, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8050990772398073, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634624496811, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 11}}
DLL 2021-10-19 06:21:36.812146 - epoch   11 |   dev ema wer  80.51 | took  0.12 s
:::MLLOG {"namespace": "", "time_ms": 1634624496812, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634624496812, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 12, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624496812, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634624501498, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 12}}
DLL 2021-10-19 06:21:41.499153 - epoch   12 | avg train utts/s 59436 | took  4.69 s
:::MLLOG {"namespace": "", "time_ms": 1634624501499, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59435.57369659736, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624501499, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634624501634, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5293555383993236, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634624501634, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 12}}
DLL 2021-10-19 06:21:41.635229 - epoch   12 |   dev ema wer  52.94 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634624501635, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634624501635, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 13, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624501636, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634624506158, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 13}}
DLL 2021-10-19 06:21:46.158670 - epoch   13 | avg train utts/s 61589 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634624506158, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61588.97347969911, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624506158, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634624506301, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.34151317966251243, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634624506301, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 13}}
DLL 2021-10-19 06:21:46.302101 - epoch   13 |   dev ema wer  34.15 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634624506302, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634624506302, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 14, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624506302, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634624510860, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 14}}
DLL 2021-10-19 06:21:50.861182 - epoch   14 | avg train utts/s 61107 | took  4.56 s
:::MLLOG {"namespace": "", "time_ms": 1634624510861, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61107.39024106124, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624510861, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634624511005, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.24256461159516193, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634624511006, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 14}}
DLL 2021-10-19 06:21:51.006655 - epoch   14 |   dev ema wer  24.26 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634624511006, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634624511007, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 15, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624511007, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 15}}
DLL 2021-10-19 06:21:54.215932 - epoch   15 | iter   96/136 | loss   52.88 | utts/s   643 | took  3.18 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634624515589, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 15}}
DLL 2021-10-19 06:21:55.590174 - epoch   15 | avg train utts/s 60776 | took  4.58 s
:::MLLOG {"namespace": "", "time_ms": 1634624515590, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60775.728006257, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624515590, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634624515743, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1905628469541561, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634624515744, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 15}}
DLL 2021-10-19 06:21:55.744522 - epoch   15 |   dev ema wer  19.06 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624515744, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634624515744, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 16, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624515745, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634624520330, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 16}}
DLL 2021-10-19 06:22:00.330380 - epoch   16 | avg train utts/s 60745 | took  4.59 s
:::MLLOG {"namespace": "", "time_ms": 1634624520330, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60745.276364773315, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624520330, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634624520475, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1584132936289107, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634624520476, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 16}}
DLL 2021-10-19 06:22:00.476574 - epoch   16 |   dev ema wer  15.84 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624520477, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634624520477, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 17, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624520477, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634624525028, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 17}}
DLL 2021-10-19 06:22:05.028733 - epoch   17 | avg train utts/s 61202 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634624525028, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61201.56312404863, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624525028, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634624525173, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.13804639535311203, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634624525173, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 17}}
DLL 2021-10-19 06:22:05.174140 - epoch   17 |   dev ema wer  13.80 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634624525174, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634624525174, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 18, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624525174, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634624529741, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 18}}
DLL 2021-10-19 06:22:09.742198 - epoch   18 | avg train utts/s 60985 | took  4.57 s
:::MLLOG {"namespace": "", "time_ms": 1634624529742, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60984.77423272396, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624529742, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634624529887, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.122440351457667, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634624529888, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 18}}
DLL 2021-10-19 06:22:09.888739 - epoch   18 |   dev ema wer  12.24 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624529889, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634624529889, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 19, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624529889, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634624534434, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 19}}
DLL 2021-10-19 06:22:14.435043 - epoch   19 | avg train utts/s 61276 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634624534435, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61276.25379233107, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624534435, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634624534581, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.11334142127127679, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634624534582, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 19}}
DLL 2021-10-19 06:22:14.582462 - epoch   19 |   dev ema wer  11.33 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624534582, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634624534582, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 20, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624534583, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624539104, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 20}}
DLL 2021-10-19 06:22:19.104681 - epoch   20 | avg train utts/s 61601 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634624539104, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61601.048050069214, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624539104, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624539250, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1044998345649057, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624539250, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 20}}
DLL 2021-10-19 06:22:19.250969 - epoch   20 |   dev ema wer  10.45 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624539251, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624539251, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 21, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624539251, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634624543767, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 21}}
DLL 2021-10-19 06:22:23.767711 - epoch   21 | avg train utts/s 61677 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634624543767, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61676.73385101976, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624543767, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634624543915, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.09769861402154333, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634624543915, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 21}}
DLL 2021-10-19 06:22:23.916010 - epoch   21 |   dev ema wer   9.77 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624543916, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634624543916, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 22, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624543916, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634624548481, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 22}}
DLL 2021-10-19 06:22:28.481745 - epoch   22 | avg train utts/s 61014 | took  4.56 s
:::MLLOG {"namespace": "", "time_ms": 1634624548481, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61014.367112241096, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624548481, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634624548626, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.093048049704055, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634624548626, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 22}}
DLL 2021-10-19 06:22:28.627099 - epoch   22 |   dev ema wer   9.30 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634624548627, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634624548627, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 23, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624548627, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 23}}
DLL 2021-10-19 06:22:28.907127 - epoch   23 | iter    8/136 | loss   48.97 | utts/s  8001 | took  0.26 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634624553146, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 23}}
DLL 2021-10-19 06:22:33.146990 - epoch   23 | avg train utts/s 61637 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634624553147, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61636.6692916161, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624553147, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634624553292, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0906951950295945, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634624553293, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 23}}
DLL 2021-10-19 06:22:33.293537 - epoch   23 |   dev ema wer   9.07 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624553293, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634624553294, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 24, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624553294, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634624557802, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 24}}
DLL 2021-10-19 06:22:37.802955 - epoch   24 | avg train utts/s 61778 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634624557803, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61777.7245943889, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624557803, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634624557949, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08900408073232602, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634624557950, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 24}}
DLL 2021-10-19 06:22:37.950420 - epoch   24 |   dev ema wer   8.90 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624557950, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634624557950, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 25, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624557950, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634624562523, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 25}}
DLL 2021-10-19 06:22:42.523867 - epoch   25 | avg train utts/s 60908 | took  4.57 s
:::MLLOG {"namespace": "", "time_ms": 1634624562523, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60908.36259729659, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624562524, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634624562669, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08681666115216352, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634624562669, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 25}}
DLL 2021-10-19 06:22:42.670340 - epoch   25 |   dev ema wer   8.68 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624562670, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634624562670, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 26, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624562670, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634624567206, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 26}}
DLL 2021-10-19 06:22:47.207158 - epoch   26 | avg train utts/s 61402 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634624567207, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61402.30814980671, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624567207, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634624567352, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0843535164148377, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634624567352, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 26}}
DLL 2021-10-19 06:22:47.353242 - epoch   26 |   dev ema wer   8.44 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624567353, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634624567353, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 27, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624567353, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634624571915, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 27}}
DLL 2021-10-19 06:22:51.915742 - epoch   27 | avg train utts/s 61058 | took  4.56 s
:::MLLOG {"namespace": "", "time_ms": 1634624571915, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61057.506701512735, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624571916, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634624572061, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0828278372118672, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634624572061, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 27}}
DLL 2021-10-19 06:22:52.062148 - epoch   27 |   dev ema wer   8.28 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624572062, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634624572062, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 28, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624572062, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634624576627, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 28}}
DLL 2021-10-19 06:22:56.627421 - epoch   28 | avg train utts/s 61021 | took  4.56 s
:::MLLOG {"namespace": "", "time_ms": 1634624576627, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61020.50204568894, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624576627, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634624576774, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08170655490606964, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634624576775, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 28}}
DLL 2021-10-19 06:22:56.775401 - epoch   28 |   dev ema wer   8.17 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624576775, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634624576775, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 29, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624576776, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634624581265, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 29}}
DLL 2021-10-19 06:23:01.266176 - epoch   29 | avg train utts/s 62033 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634624581266, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62032.846718485, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624581266, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634624581413, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07825079960295578, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634624581413, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 29}}
DLL 2021-10-19 06:23:01.413793 - epoch   29 |   dev ema wer   7.83 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624581414, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634624581414, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 30, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624581414, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 30}}
DLL 2021-10-19 06:23:03.334808 - epoch   30 | iter   56/136 | loss   41.31 | utts/s  1086 | took  1.89 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634624585944, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 30}}
DLL 2021-10-19 06:23:05.944608 - epoch   30 | avg train utts/s 61485 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634624585944, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61484.9706360504, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624585944, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634624586090, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0776258225800522, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634624586090, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 30}}
DLL 2021-10-19 06:23:06.090848 - epoch   30 |   dev ema wer   7.76 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624586091, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634624586091, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 31, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624586091, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634624590629, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 31}}
DLL 2021-10-19 06:23:10.630345 - epoch   31 | avg train utts/s 61367 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634624590630, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61367.29890384386, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624590630, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634624590775, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07652292195139884, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634624590776, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 31}}
DLL 2021-10-19 06:23:10.776470 - epoch   31 |   dev ema wer   7.65 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624590776, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634624590776, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 32, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624590777, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634624595293, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 32}}
DLL 2021-10-19 06:23:15.294045 - epoch   32 | avg train utts/s 61668 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634624595294, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61668.11258116357, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624595294, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634624595440, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07560383809418772, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634624595440, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 32}}
DLL 2021-10-19 06:23:15.440832 - epoch   32 |   dev ema wer   7.56 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624595440, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634624595441, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 33, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624595441, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634624599938, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 33}}
DLL 2021-10-19 06:23:19.939232 - epoch   33 | avg train utts/s 61925 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634624599939, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61925.15114656543, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624599939, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634624600083, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0741333039226499, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634624600084, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 33}}
DLL 2021-10-19 06:23:20.084641 - epoch   33 |   dev ema wer   7.41 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634624600084, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634624600085, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 34, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624600085, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634624604634, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 34}}
DLL 2021-10-19 06:23:24.635383 - epoch   34 | avg train utts/s 61216 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634624604635, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61215.57119345911, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624604635, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634624604781, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07415168559979413, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634624604782, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 34}}
DLL 2021-10-19 06:23:24.782482 - epoch   34 |   dev ema wer   7.42 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624604782, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634624604782, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 35, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624604782, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634624609296, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 35}}
DLL 2021-10-19 06:23:29.296867 - epoch   35 | avg train utts/s 61705 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634624609296, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61704.812002718914, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624609297, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634624609442, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0729201132311312, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634624609443, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 35}}
DLL 2021-10-19 06:23:29.443621 - epoch   35 |   dev ema wer   7.29 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624609443, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634624609444, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 36, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624609444, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634624613947, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 36}}
DLL 2021-10-19 06:23:33.947826 - epoch   36 | avg train utts/s 61849 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634624613947, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61848.59613259092, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624613948, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634624614094, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07293849490827543, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634624614095, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 36}}
DLL 2021-10-19 06:23:34.095673 - epoch   36 |   dev ema wer   7.29 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624614095, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634624614096, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 37, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624614096, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 37}}
DLL 2021-10-19 06:23:37.587158 - epoch   37 | iter  104/136 | loss   40.59 | utts/s   592 | took  3.46 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634624618636, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 37}}
DLL 2021-10-19 06:23:38.636910 - epoch   37 | avg train utts/s 61344 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634624618636, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61344.17484840274, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624618637, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634624618783, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07238704459394875, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634624618783, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 37}}
DLL 2021-10-19 06:23:38.783917 - epoch   37 |   dev ema wer   7.24 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624618784, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634624618784, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 38, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624618784, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634624623295, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 38}}
DLL 2021-10-19 06:23:43.295913 - epoch   38 | avg train utts/s 61743 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634624623296, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61743.18018233044, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624623296, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634624623441, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07207455608249697, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634624623441, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 38}}
DLL 2021-10-19 06:23:43.442138 - epoch   38 |   dev ema wer   7.21 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624623442, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634624623442, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 39, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624623442, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634624627947, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 39}}
DLL 2021-10-19 06:23:47.947673 - epoch   39 | avg train utts/s 61831 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634624627947, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61830.87691611337, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624627947, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634624628093, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07043858681666115, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634624628093, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 39}}
DLL 2021-10-19 06:23:48.093908 - epoch   39 |   dev ema wer   7.04 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624628094, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634624628094, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 40, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624628094, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634624632576, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 40}}
DLL 2021-10-19 06:23:52.577003 - epoch   40 | avg train utts/s 62140 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634624632577, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62140.081275274984, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624632577, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634624632721, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07056725855667072, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634624632722, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 40}}
DLL 2021-10-19 06:23:52.722456 - epoch   40 |   dev ema wer   7.06 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634624632722, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634624632723, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 41, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624632723, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634624637252, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 41}}
DLL 2021-10-19 06:23:57.253201 - epoch   41 | avg train utts/s 61490 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634624637253, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61489.51108623945, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624637253, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634624637399, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06981360979375759, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634624637399, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 41}}
DLL 2021-10-19 06:23:57.399756 - epoch   41 |   dev ema wer   6.98 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624637400, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634624637400, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 42, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624637400, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634624641954, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 42}}
DLL 2021-10-19 06:24:01.954880 - epoch   42 | avg train utts/s 61157 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634624641954, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61157.24009843949, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624641955, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634624642099, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06882099922796955, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634624642099, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 42}}
DLL 2021-10-19 06:24:02.100373 - epoch   42 |   dev ema wer   6.88 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634624642100, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634624642100, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 43, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624642101, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634624646572, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 43}}
DLL 2021-10-19 06:24:06.572844 - epoch   43 | avg train utts/s 62288 | took  4.47 s
:::MLLOG {"namespace": "", "time_ms": 1634624646572, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62288.06211450557, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624646573, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634624646718, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06744237344215286, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634624646719, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 43}}
DLL 2021-10-19 06:24:06.719665 - epoch   43 |   dev ema wer   6.74 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624646720, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634624646720, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 44, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624646720, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634624651225, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 44}}
DLL 2021-10-19 06:24:11.226366 - epoch   44 | avg train utts/s 61813 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634624651226, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61813.347735533964, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624651226, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634624651372, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06624756442777839, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634624651373, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 44}}
DLL 2021-10-19 06:24:11.373699 - epoch   44 |   dev ema wer   6.62 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624651373, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634624651374, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 45, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624651374, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 45}}
DLL 2021-10-19 06:24:11.899523 - epoch   45 | iter   16/136 | loss   27.61 | utts/s  4087 | took  0.50 s | lrate 4.68e-03
:::MLLOG {"namespace": "", "time_ms": 1634624655873, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 45}}
DLL 2021-10-19 06:24:15.874301 - epoch   45 | avg train utts/s 61898 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634624655874, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61898.288936296, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624655874, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634624656020, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06497922870482703, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634624656020, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 45}}
DLL 2021-10-19 06:24:16.020822 - epoch   45 |   dev ema wer   6.50 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624656021, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634624656021, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 46, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624656021, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634624660441, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 46}}
DLL 2021-10-19 06:24:20.442137 - epoch   46 | avg train utts/s 63009 | took  4.42 s
:::MLLOG {"namespace": "", "time_ms": 1634624660442, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 63009.241946080474, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624660442, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634624660588, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06450130509907724, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634624660588, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 46}}
DLL 2021-10-19 06:24:20.588751 - epoch   46 |   dev ema wer   6.45 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624660589, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634624660589, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 47, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624660589, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634624665063, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 47}}
DLL 2021-10-19 06:24:25.064210 - epoch   47 | avg train utts/s 62244 | took  4.47 s
:::MLLOG {"namespace": "", "time_ms": 1634624665064, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62244.37392666346, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624665064, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634624665209, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06315944266754898, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634624665209, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 47}}
DLL 2021-10-19 06:24:25.210306 - epoch   47 |   dev ema wer   6.32 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624665210, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634624665210, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 48, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624665211, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634624669700, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 48}}
DLL 2021-10-19 06:24:29.700451 - epoch   48 | avg train utts/s 62044 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634624669700, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62043.65928836617, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624669700, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634624669846, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06209330539318408, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634624669846, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 48}}
DLL 2021-10-19 06:24:29.847116 - epoch   48 |   dev ema wer   6.21 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624669847, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634624669847, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 49, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624669847, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634624674320, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 49}}
DLL 2021-10-19 06:24:34.321073 - epoch   49 | avg train utts/s 62267 | took  4.47 s
:::MLLOG {"namespace": "", "time_ms": 1634624674321, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62267.16949426994, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624674321, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634624674466, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06192787029888607, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634624674467, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 49}}
DLL 2021-10-19 06:24:34.467547 - epoch   49 |   dev ema wer   6.19 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624674467, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634624674468, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 50, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624674468, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634624678905, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 50}}
DLL 2021-10-19 06:24:38.905828 - epoch   50 | avg train utts/s 62771 | took  4.44 s
:::MLLOG {"namespace": "", "time_ms": 1634624678905, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62770.60327660058, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624678906, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634624679050, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06075144296165582, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634624679051, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 50}}
DLL 2021-10-19 06:24:39.051710 - epoch   50 |   dev ema wer   6.08 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624679052, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634624679052, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 51, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624679052, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634624683512, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 51}}
DLL 2021-10-19 06:24:43.512759 - epoch   51 | avg train utts/s 62449 | took  4.46 s
:::MLLOG {"namespace": "", "time_ms": 1634624683512, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62449.085305199886, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624683512, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634624683658, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05985074078158891, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634624683659, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 51}}
DLL 2021-10-19 06:24:43.659575 - epoch   51 |   dev ema wer   5.99 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624683659, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634624683660, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 52, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624683660, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 52}}
DLL 2021-10-19 06:24:45.786315 - epoch   52 | iter   64/136 | loss   33.12 | utts/s   975 | took  2.10 s | lrate 2.92e-03
:::MLLOG {"namespace": "", "time_ms": 1634624688150, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 52}}
DLL 2021-10-19 06:24:48.150650 - epoch   52 | avg train utts/s 62029 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634624688150, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62028.51879352487, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624688150, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634624688296, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06080658799308849, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634624688297, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 52}}
DLL 2021-10-19 06:24:48.297667 - epoch   52 |   dev ema wer   6.08 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624688298, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634624688298, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 53, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624688298, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634624692845, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 53}}
DLL 2021-10-19 06:24:52.845553 - epoch   53 | avg train utts/s 61257 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634624692845, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61256.89191225533, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624692845, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634624692990, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06001617587588692, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634624692991, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 53}}
DLL 2021-10-19 06:24:52.991483 - epoch   53 |   dev ema wer   6.00 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634624692991, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634624692992, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 54, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624692992, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634624697479, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 54}}
DLL 2021-10-19 06:24:57.479721 - epoch   54 | avg train utts/s 62071 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634624697479, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62071.03700832581, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624697480, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634624697623, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05900518363295467, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634624697624, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 54}}
DLL 2021-10-19 06:24:57.624633 - epoch   54 |   dev ema wer   5.90 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634624697624, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634624697625, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 55, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624697625, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634624702150, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 55}}
DLL 2021-10-19 06:25:02.151266 - epoch   55 | avg train utts/s 61542 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634624702151, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61542.19758544178, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624702151, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634624702295, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.058821366861512445, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634624702295, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 55}}
DLL 2021-10-19 06:25:02.296184 - epoch   55 |   dev ema wer   5.88 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634624702296, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634624702296, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 56, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624702296, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634624706780, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 56}}
DLL 2021-10-19 06:25:06.780563 - epoch   56 | avg train utts/s 62122 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634624706780, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62121.8511176371, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624706780, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634624706924, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05825153487004154, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634624706924, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 56}}
DLL 2021-10-19 06:25:06.925379 - epoch   56 |   dev ema wer   5.83 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634624706925, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634624706925, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 57, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624706926, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1634624711409, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 57}}
DLL 2021-10-19 06:25:11.409868 - epoch   57 | avg train utts/s 62124 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634624711409, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62123.555714284346, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634624711410, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1634624711553, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05736921436711886, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1634624711553, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 57}}
DLL 2021-10-19 06:25:11.553707 - epoch   57 |   dev ema wer   5.74 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634624711553, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 57}}
:::MLLOG {"namespace": "", "time_ms": 1634624711554, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1028, "status": "success"}}
Finished after 0 epochs.
DLL 2021-10-19 06:25:11.554293 -  | avg train utts/s 58758
ENDING TIMING RUN AT 2021-10-19 06:25:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:28 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:28 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:28 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:28 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:29 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:29 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:29 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:29 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:29 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:30 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:31 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:31 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:31 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:31 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:31 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:31 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:31 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:31 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:31 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:31 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:32 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:33 AM
RESULT,RNN_SPEECH_RECOGNITION,,427,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:34 AM
RESULT,RNN_SPEECH_RECOGNITION,,428,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:35 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:35 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:35 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:35 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:35 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:35 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:35 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:35 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:35 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:35 AM
RESULT,RNN_SPEECH_RECOGNITION,,429,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:36 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:36 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:36 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:36 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:36 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:36 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:36 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:36 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 06:18:26 AM
ENDING TIMING RUN AT 2021-10-19 06:25:36 AM
RESULT,RNN_SPEECH_RECOGNITION,,430,nvidia,2021-10-19 06:18:26 AM
