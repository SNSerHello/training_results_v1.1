+ : DGXA100_16x8x16x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/rnntv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019054810924134961
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets
+ : /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ : ./api_logs
+ : 22748
+ : 30
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized
+ LOGBASE=rnnt_16x8x16_211019054810924134961
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019054810924134961
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019054810924134961
+ readonly _cont_name=rnn_speech_recognition
+ _cont_name=rnn_speech_recognition
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets:/datasets/,/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743:/results
+ _cont_mounts+=,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized:/metadata
+ _cont_mounts+=,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets/sentencepieces:/sentencepieces
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07408/slurm_script: line 43: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ srun --ntasks=16 mkdir -p /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ srun --ntasks=16 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/rnntv11.sqsh --container-name=rnn_speech_recognition true
+ [[ DGXA100_16x8x16x1 == \D\G\X\A\1\0\0* ]]
+ echo 'using NCCL_TOPO_FILE /opt/microsoft/ndv4-topo.xml'
using NCCL_TOPO_FILE /opt/microsoft/ndv4-topo.xml
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019054810924134961_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ srun --nodes=1 --ntasks=1 --container-name=rnn_speech_recognition python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=16 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C04DD
Clearing cache on ip-0A0C04E7
Clearing cache on ip-0A0C04E8
Clearing cache on ip-0A0C04E1
Clearing cache on ip-0A0C04EB
Clearing cache on ip-0A0C04EF
Clearing cache on ip-0A0C04C1
Clearing cache on ip-0A0C04ED
Clearing cache on ip-0A0C04EE
Clearing cache on ip-0A0C04E4
Clearing cache on ip-0A0C04B8
Clearing cache on ip-0A0C04DE
Clearing cache on ip-0A0C04E9
Clearing cache on ip-0A0C04E5
Clearing cache on ip-0A0C04DF
Clearing cache on ip-0A0C04EA
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=16 --container-name=rnn_speech_recognition python -c '
from mlperf import logging
logging.log_event(key=logging.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1634622501681, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501682, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501703, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501704, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501712, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501717, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501732, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501734, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501739, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501746, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501742, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501753, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501756, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501756, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501759, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622501766, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ SEED=22749
+ srun --mpi=none --ntasks=128 --ntasks-per-node=8 --container-name=rnn_speech_recognition --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets:/datasets/,/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743:/results,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized:/metadata,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets/sentencepieces:/sentencepieces,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 05:48:22 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointt=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joinnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointt=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_join+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
t=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 22749 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
:::MLLOG {"namespace": "", "time_ms": 1634622507003, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507049, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507052, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507099, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507119, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507133, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507162, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507163, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507162, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507178, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507181, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507181, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507185, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507194, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507188, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507186, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507190, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507193, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507207, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507213, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507218, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507226, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507226, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507230, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507228, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507227, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507229, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507230, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507244, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507247, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507257, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507253, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507258, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507261, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507261, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507264, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507268, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507264, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507267, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507275, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507275, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507278, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507282, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507285, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507291, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507291, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507293, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507305, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507311, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507306, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507309, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507309, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507317, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507319, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507321, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507327, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507330, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507334, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507337, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507347, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507343, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507352, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507355, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507355, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507358, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507363, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507366, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507364, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507368, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507369, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507371, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507375, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507380, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507383, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507388, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507390, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507389, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507394, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507394, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507401, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507403, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507405, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507411, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507414, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507419, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507420, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507422, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507430, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507432, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507437, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507437, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507443, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507446, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507445, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507447, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507446, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507453, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507453, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507458, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507465, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507463, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507469, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507467, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507471, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507476, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507477, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507478, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507481, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507487, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507486, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507488, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507488, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507488, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507492, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507490, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507497, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507497, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507498, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507512, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507513, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507513, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507519, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507521, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507526, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507531, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507534, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507546, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634622507555, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
Distributed training with 128 GPUs

:::MLLOG {"namespace": "", "time_ms": 1634622508609, "event_type": "POINT_IN_TIME", "key": "seed", "value": 22749, "metadata": {"file": "train.py", "lineno": 421}}
DLL 2021-10-19 05:48:28.613671 - PARAMETER | epochs :  80
DLL 2021-10-19 05:48:28.613869 - PARAMETER | warmup_epochs :  6
DLL 2021-10-19 05:48:28.613913 - PARAMETER | hold_epochs :  33
DLL 2021-10-19 05:48:28.613937 - PARAMETER | epochs_this_job :  0
DLL 2021-10-19 05:48:28.613961 - PARAMETER | cudnn_benchmark :  True
DLL 2021-10-19 05:48:28.613984 - PARAMETER | amp_level :  2
DLL 2021-10-19 05:48:28.614005 - PARAMETER | seed :  22749
DLL 2021-10-19 05:48:28.614025 - PARAMETER | local_rank :  0
DLL 2021-10-19 05:48:28.614045 - PARAMETER | target :  0.058
DLL 2021-10-19 05:48:28.614065 - PARAMETER | apex_transducer_loss :  fp16
DLL 2021-10-19 05:48:28.614095 - PARAMETER | fuse_relu_dropout :  True
DLL 2021-10-19 05:48:28.614116 - PARAMETER | weights_init_scale :  0.5
DLL 2021-10-19 05:48:28.614140 - PARAMETER | hidden_hidden_bias_scale : 
DLL 2021-10-19 05:48:28.614163 - PARAMETER | batch_eval_mode :  cg_unroll_pipeline
DLL 2021-10-19 05:48:28.614190 - PARAMETER | cg_unroll_factor :  4
DLL 2021-10-19 05:48:28.614210 - PARAMETER | apex_transducer_joint :  pack_w_relu_dropout
DLL 2021-10-19 05:48:28.614231 - PARAMETER | buffer_pre_alloc :  True
DLL 2021-10-19 05:48:28.614257 - PARAMETER | multilayer_lstm :  False
DLL 2021-10-19 05:48:28.614277 - PARAMETER | batch_split_factor :  1
DLL 2021-10-19 05:48:28.614296 - PARAMETER | apex_mlp :  True
DLL 2021-10-19 05:48:28.614321 - PARAMETER | num_cg :  50
DLL 2021-10-19 05:48:28.614340 - PARAMETER | min_seq_split_len :  -1
DLL 2021-10-19 05:48:28.614359 - PARAMETER | pre_sort_for_seq_split :  False
DLL 2021-10-19 05:48:28.614391 - PARAMETER | batch_size :  16
DLL 2021-10-19 05:48:28.614411 - PARAMETER | val_batch_size :  22
DLL 2021-10-19 05:48:28.614429 - PARAMETER | lr :  0.007
DLL 2021-10-19 05:48:28.614449 - PARAMETER | min_lr :  1e-05
DLL 2021-10-19 05:48:28.614496 - PARAMETER | lr_exp_gamma :  0.935
DLL 2021-10-19 05:48:28.614518 - PARAMETER | weight_decay :  0.001
DLL 2021-10-19 05:48:28.614539 - PARAMETER | grad_accumulation_steps :  1
DLL 2021-10-19 05:48:28.614559 - PARAMETER | clip_norm :  1
DLL 2021-10-19 05:48:28.614578 - PARAMETER | beta1 :  0.905
DLL 2021-10-19 05:48:28.614604 - PARAMETER | beta2 :  0.999
DLL 2021-10-19 05:48:28.614625 - PARAMETER | ema :  0.995
DLL 2021-10-19 05:48:28.614644 - PARAMETER | multi_tensor_ema :  True
DLL 2021-10-19 05:48:28.614664 - PARAMETER | dist_lamb :  True
DLL 2021-10-19 05:48:28.614682 - PARAMETER | ema_update_type :  fp16
DLL 2021-10-19 05:48:28.614701 - PARAMETER | dwu_group_size :  8
DLL 2021-10-19 05:48:28.614721 - PARAMETER | dwu_overlap_reduction :  True
DLL 2021-10-19 05:48:28.614747 - PARAMETER | dali_device :  gpu
DLL 2021-10-19 05:48:28.614767 - PARAMETER | resume :  False
DLL 2021-10-19 05:48:28.614786 - PARAMETER | ckpt : 
DLL 2021-10-19 05:48:28.614806 - PARAMETER | save_at_the_end :  False
DLL 2021-10-19 05:48:28.614824 - PARAMETER | save_frequency : 
DLL 2021-10-19 05:48:28.614843 - PARAMETER | keep_milestones :  []
DLL 2021-10-19 05:48:28.614864 - PARAMETER | save_best_from :  200
DLL 2021-10-19 05:48:28.614885 - PARAMETER | val_frequency :  1
DLL 2021-10-19 05:48:28.614904 - PARAMETER | log_frequency :  1000
DLL 2021-10-19 05:48:28.614925 - PARAMETER | prediction_frequency :  1000000
DLL 2021-10-19 05:48:28.614943 - PARAMETER | model_config :  configs/baseline_v3-1023sp.yaml
DLL 2021-10-19 05:48:28.614962 - PARAMETER | num_buckets :  1
DLL 2021-10-19 05:48:28.614980 - PARAMETER | vectorized_sampler :  True
DLL 2021-10-19 05:48:28.614998 - PARAMETER | dist_sampler :  True
DLL 2021-10-19 05:48:28.615025 - PARAMETER | train_manifests :  ['/metadata/librispeech-train-clean-100-wav-tokenized.pkl', '/metadata/librispeech-train-clean-360-wav-tokenized.pkl', '/metadata/librispeech-train-other-500-wav-tokenized.pkl']
DLL 2021-10-19 05:48:28.615049 - PARAMETER | val_manifests :  ['/metadata/librispeech-dev-clean-wav-tokenized.pkl']
DLL 2021-10-19 05:48:28.615073 - PARAMETER | max_duration :  16.7
DLL 2021-10-19 05:48:28.615093 - PARAMETER | max_txt_len :  125
DLL 2021-10-19 05:48:28.615112 - PARAMETER | max_eval_sample_duration :  32.7
DLL 2021-10-19 05:48:28.615131 - PARAMETER | dataset_dir :  /datasets/LibriSpeech
DLL 2021-10-19 05:48:28.615157 - PARAMETER | output_dir :  /results
DLL 2021-10-19 05:48:28.615176 - PARAMETER | log_file : 
DLL 2021-10-19 05:48:28.615194 - PARAMETER | max_symbol_per_sample :  300
DLL 2021-10-19 05:48:28.615213 - PARAMETER | data_cpu_threads :  8
DLL 2021-10-19 05:48:28.615239 - PARAMETER | synthetic_audio_seq_len : 
DLL 2021-10-19 05:48:28.615258 - PARAMETER | synthetic_text_seq_len : 
DLL 2021-10-19 05:48:28.615276 - PARAMETER | enable_seq_len_stats :  False
DLL 2021-10-19 05:48:28.615295 - PARAMETER | vectorized_sa :  True
DLL 2021-10-19 05:48:28.615315 - PARAMETER | in_mem_file_list :  False
DLL 2021-10-19 05:48:28.615336 - PARAMETER | enable_prefetch :  True
DLL 2021-10-19 05:48:28.615354 - PARAMETER | tokenized_transcript :  True
DLL 2021-10-19 05:48:28.615378 - PARAMETER | dali_dont_use_mmap :  False
:::MLLOG {"namespace": "", "time_ms": 1634622508638, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "train.py", "lineno": 438}}
:::MLLOG {"namespace": "", "time_ms": 1634622508639, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "rnnt", "metadata": {"file": "train.py", "lineno": 445}}
:::MLLOG {"namespace": "", "time_ms": 1634622508639, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "train.py", "lineno": 446}}
:::MLLOG {"namespace": "", "time_ms": 1634622508639, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "train.py", "lineno": 447}}
:::MLLOG {"namespace": "", "time_ms": 1634622508639, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "train.py", "lineno": 448}}
:::MLLOG {"namespace": "", "time_ms": 1634622508639, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "16xND96amsr_A100_v4", "metadata": {"file": "train.py", "lineno": 449}}
:::MLLOG {"namespace": "", "time_ms": 1634622508641, "event_type": "POINT_IN_TIME", "key": "model_weights_initialization_scale", "value": 0.5, "metadata": {"file": "train.py", "lineno": 456}}
:::MLLOG {"namespace": "", "time_ms": 1634622508802, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "pre_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634622508961, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "post_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634622508965, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 201, "tensor": "pred_embed"}}
:::MLLOG {"namespace": "", "time_ms": 1634622508991, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "dec_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634622508993, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 221, "tensor": "joint_pred"}}
:::MLLOG {"namespace": "", "time_ms": 1634622508996, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 226, "tensor": "joint_enc"}}
:::MLLOG {"namespace": "", "time_ms": 1634622509003, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 243, "tensor": "joint_net"}}
:::MLLOG {"namespace": "", "time_ms": 1634622512222, "event_type": "POINT_IN_TIME", "key": "eval_max_prediction_symbols", "value": 300, "metadata": {"file": "train.py", "lineno": 483}}
Model size: 49.1M params

:::MLLOG {"namespace": "", "time_ms": 1634622512251, "event_type": "POINT_IN_TIME", "key": "model_eval_ema_factor", "value": 0.995, "metadata": {"file": "train.py", "lineno": 497}}
[ip-0A0C04DD:0:43277 - context.c:584] INFO job (ID: 867749370200700044) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:43277 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:43277 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:43279 - context.c:584] INFO job (ID: 867749758174673526) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:43279 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:43279 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:43280 - context.c:584] INFO job (ID: 867749747663799682) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:43280 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:43280 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:43275 - context.c:584] INFO job (ID: 867749616339048794) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:43275 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:43275 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:43276 - context.c:584] INFO job (ID: 867749749694589450) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:43276 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:43276 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:43278 - context.c:584] INFO job (ID: 867749135744650607) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:43278 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:43278 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:43274 - context.c:584] INFO job (ID: 867749342457093254) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:43274 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:43274 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:43273 - context.c:584] INFO job (ID: 867749788658155882) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:43273 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:43273 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
Starting with LRs: 0.007000000216066837
Setting up datasets...
:::MLLOG {"namespace": "", "time_ms": 1634622542083, "event_type": "POINT_IN_TIME", "key": "data_train_max_duration", "value": 16.7, "metadata": {"file": "train.py", "lineno": 568}}
:::MLLOG {"namespace": "", "time_ms": 1634622542083, "event_type": "POINT_IN_TIME", "key": "data_speed_perturbaton_max", "value": 1.15, "metadata": {"file": "train.py", "lineno": 570}}
:::MLLOG {"namespace": "", "time_ms": 1634622542083, "event_type": "POINT_IN_TIME", "key": "data_speed_perturbaton_min", "value": 0.85, "metadata": {"file": "train.py", "lineno": 572}}
:::MLLOG {"namespace": "", "time_ms": 1634622542083, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_n", "value": 2, "metadata": {"file": "train.py", "lineno": 574}}
:::MLLOG {"namespace": "", "time_ms": 1634622542083, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_min", "value": 0, "metadata": {"file": "train.py", "lineno": 576}}
:::MLLOG {"namespace": "", "time_ms": 1634622542083, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_max", "value": 20, "metadata": {"file": "train.py", "lineno": 578}}
:::MLLOG {"namespace": "", "time_ms": 1634622542083, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_n", "value": 10, "metadata": {"file": "train.py", "lineno": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634622542083, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_min", "value": 0, "metadata": {"file": "train.py", "lineno": 582}}
:::MLLOG {"namespace": "", "time_ms": 1634622542084, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_max", "value": 0.03, "metadata": {"file": "train.py", "lineno": 584}}
:::MLLOG {"namespace": "", "time_ms": 1634622542084, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 2048, "metadata": {"file": "train.py", "lineno": 586}}
Graph with max_seq_len of 641
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
:::MLLOG {"namespace": "", "time_ms": 1634622632430, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train.py", "lineno": 691}}
:::MLLOG {"namespace": "", "time_ms": 1634622632848, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "train.py", "lineno": 694}}
:::MLLOG {"namespace": "", "time_ms": 1634622632854, "event_type": "POINT_IN_TIME", "key": "data_train_num_buckets", "value": 1, "metadata": {"file": "train.py", "lineno": 700}}
Launching vectorized bucketing sampler
Launching simple sampler
Dataset read by DALI. Number of samples: 278528
Initializing DALI with parameters:
	           dither : 1e-05
	    dont_use_mmap : False
	        file_root : /datasets/LibriSpeech
	     gpu_pipeline : True
	 in_mem_file_list : False
	             nfft : 512
	          nfilter : 80
	   resample_range : [0.85, 1.15]
	      sample_rate : 16000
	          sampler : <common.data.dali.sampler.VectorizedBucketingSampler object at 0x1473080ce310>
	   spect_wind_len : 320.0
	  spect_wind_step : 160.0
	synthetic_seq_len : None
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
Dataset read by DALI. Number of samples: 2703
Initializing DALI with parameters:
	           dither : 1e-05
	    dont_use_mmap : False
	        file_root : /datasets/LibriSpeech
	     gpu_pipeline : True
	 in_mem_file_list : False
	             nfft : 512
	          nfilter : 80
	   resample_range : None
	      sample_rate : 16000
	          sampler : <common.data.dali.sampler.SimpleSampler object at 0x1473080a7250>
	   spect_wind_len : 320.0
	  spect_wind_step : 160.0
	synthetic_seq_len : None
:::MLLOG {"namespace": "", "time_ms": 1634622637143, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 278528, "metadata": {"file": "train.py", "lineno": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634622637143, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 2703, "metadata": {"file": "train.py", "lineno": 781}}
:::MLLOG {"namespace": "", "time_ms": 1634622637143, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "lamb", "metadata": {"file": "train.py", "lineno": 783}}
:::MLLOG {"namespace": "", "time_ms": 1634622637143, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.007, "metadata": {"file": "train.py", "lineno": 784}}
:::MLLOG {"namespace": "", "time_ms": 1634622637143, "event_type": "POINT_IN_TIME", "key": "opt_lamb_epsilon", "value": 1e-09, "metadata": {"file": "train.py", "lineno": 785}}
:::MLLOG {"namespace": "", "time_ms": 1634622637144, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 0.935, "metadata": {"file": "train.py", "lineno": 786}}
:::MLLOG {"namespace": "", "time_ms": 1634622637144, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 6, "metadata": {"file": "train.py", "lineno": 787}}
:::MLLOG {"namespace": "", "time_ms": 1634622637144, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_hold_epochs", "value": 33, "metadata": {"file": "train.py", "lineno": 788}}
:::MLLOG {"namespace": "", "time_ms": 1634622637144, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.905, "metadata": {"file": "train.py", "lineno": 789}}
:::MLLOG {"namespace": "", "time_ms": 1634622637144, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.999, "metadata": {"file": "train.py", "lineno": 790}}
:::MLLOG {"namespace": "", "time_ms": 1634622637144, "event_type": "POINT_IN_TIME", "key": "opt_gradient_clip_norm", "value": 1, "metadata": {"file": "train.py", "lineno": 791}}
:::MLLOG {"namespace": "", "time_ms": 1634622637144, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_alt_decay_func", "value": true, "metadata": {"file": "train.py", "lineno": 792}}
:::MLLOG {"namespace": "", "time_ms": 1634622637144, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_alt_warmup_func", "value": true, "metadata": {"file": "train.py", "lineno": 793}}
:::MLLOG {"namespace": "", "time_ms": 1634622637144, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_min", "value": 1e-05, "metadata": {"file": "train.py", "lineno": 794}}
:::MLLOG {"namespace": "", "time_ms": 1634622637144, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.001, "metadata": {"file": "train.py", "lineno": 795}}
Pre-allocate buffer with max_seq_len of 1921 and max_txt_len of 125
:::MLLOG {"namespace": "", "time_ms": 1634622637276, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 1, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622637276, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622643754, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 1}}
DLL 2021-10-19 05:50:43.754905 - epoch    1 | avg train utts/s 42995 | took  6.48 s
:::MLLOG {"namespace": "", "time_ms": 1634622643754, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 42995.073861155885, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622643755, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622643936, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 11.39526120363222, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622643936, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 1}}
DLL 2021-10-19 05:50:43.937195 - epoch    1 |   dev ema wer 1139.53 | took  0.18 s
:::MLLOG {"namespace": "", "time_ms": 1634622643937, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622643937, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 2, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622643938, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634622649165, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 2}}
DLL 2021-10-19 05:50:49.166324 - epoch    2 | avg train utts/s 53275 | took  5.23 s
:::MLLOG {"namespace": "", "time_ms": 1634622649166, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 53274.50998911509, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622649166, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634622649294, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634622649294, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 2}}
DLL 2021-10-19 05:50:49.295011 - epoch    2 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634622649295, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634622649295, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 3, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622649295, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622654318, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 3}}
DLL 2021-10-19 05:50:54.318789 - epoch    3 | avg train utts/s 55451 | took  5.02 s
:::MLLOG {"namespace": "", "time_ms": 1634622654318, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 55451.00131257123, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622654319, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622654443, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622654444, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 3}}
DLL 2021-10-19 05:50:54.444671 - epoch    3 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634622654444, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634622654445, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 4, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622654445, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634622659239, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 4}}
DLL 2021-10-19 05:50:59.239912 - epoch    4 | avg train utts/s 58094 | took  4.79 s
:::MLLOG {"namespace": "", "time_ms": 1634622659240, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 58093.55979332531, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622659240, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634622659369, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634622659369, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 4}}
DLL 2021-10-19 05:50:59.370035 - epoch    4 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634622659370, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634622659370, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 5, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622659370, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634622664148, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 5}}
DLL 2021-10-19 05:51:04.148843 - epoch    5 | avg train utts/s 58293 | took  4.78 s
:::MLLOG {"namespace": "", "time_ms": 1634622664148, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 58293.23744156486, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622664149, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634622664279, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634622664280, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 5}}
DLL 2021-10-19 05:51:04.280582 - epoch    5 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634622664280, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634622664281, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 6, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622664281, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634622669007, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 6}}
DLL 2021-10-19 05:51:09.007392 - epoch    6 | avg train utts/s 58935 | took  4.73 s
:::MLLOG {"namespace": "", "time_ms": 1634622669007, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 58935.08739393783, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622669007, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634622669136, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634622669136, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 6}}
DLL 2021-10-19 05:51:09.136914 - epoch    6 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634622669137, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634622669137, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 7, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622669137, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634622673839, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 7}}
DLL 2021-10-19 05:51:13.839493 - epoch    7 | avg train utts/s 59239 | took  4.70 s
:::MLLOG {"namespace": "", "time_ms": 1634622673839, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59238.87348491563, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622673839, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634622673963, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634622673963, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 7}}
DLL 2021-10-19 05:51:13.964608 - epoch    7 |   dev ema wer 100.00 | took  0.12 s
:::MLLOG {"namespace": "", "time_ms": 1634622673964, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634622673965, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 8, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622673965, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 8}}
DLL 2021-10-19 05:51:15.652833 - epoch    8 | iter   48/136 | loss  275.25 | utts/s  1230 | took  1.67 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634622678663, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 8}}
DLL 2021-10-19 05:51:18.663963 - epoch    8 | avg train utts/s 59280 | took  4.70 s
:::MLLOG {"namespace": "", "time_ms": 1634622678664, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59280.2178985768, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622678664, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634622678773, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9926840924965994, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634622678773, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 8}}
DLL 2021-10-19 05:51:18.773690 - epoch    8 |   dev ema wer  99.27 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634622678773, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634622678774, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 9, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622678774, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634622683423, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 9}}
DLL 2021-10-19 05:51:23.423667 - epoch    9 | avg train utts/s 59908 | took  4.65 s
:::MLLOG {"namespace": "", "time_ms": 1634622683423, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59907.82197338044, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622683423, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634622683533, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9588985699055181, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634622683533, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 9}}
DLL 2021-10-19 05:51:23.533941 - epoch    9 |   dev ema wer  95.89 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634622683534, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634622683534, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 10, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622683534, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634622688181, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 10}}
DLL 2021-10-19 05:51:28.181656 - epoch   10 | avg train utts/s 59940 | took  4.65 s
:::MLLOG {"namespace": "", "time_ms": 1634622688181, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59939.616857001434, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622688181, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634622688299, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.831826035807507, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634622688300, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 10}}
DLL 2021-10-19 05:51:28.300615 - epoch   10 |   dev ema wer  83.18 | took  0.12 s
:::MLLOG {"namespace": "", "time_ms": 1634622688300, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634622688301, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 11, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622688301, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634622692911, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 11}}
DLL 2021-10-19 05:51:32.911689 - epoch   11 | avg train utts/s 60416 | took  4.61 s
:::MLLOG {"namespace": "", "time_ms": 1634622692911, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60415.82296535533, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622692911, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634622693044, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5713209073195838, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634622693044, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 11}}
DLL 2021-10-19 05:51:33.045302 - epoch   11 |   dev ema wer  57.13 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634622693045, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634622693045, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 12, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622693046, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634622697704, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 12}}
DLL 2021-10-19 05:51:37.704972 - epoch   12 | avg train utts/s 59786 | took  4.66 s
:::MLLOG {"namespace": "", "time_ms": 1634622697705, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59785.95358754021, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622697705, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634622697854, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.36825851990735636, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634622697854, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 12}}
DLL 2021-10-19 05:51:37.855171 - epoch   12 |   dev ema wer  36.83 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622697855, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634622697855, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 13, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622697855, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634622702499, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 13}}
DLL 2021-10-19 05:51:42.499581 - epoch   13 | avg train utts/s 59981 | took  4.64 s
:::MLLOG {"namespace": "", "time_ms": 1634622702499, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59981.37271700631, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622702499, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634622702643, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.25565236572184846, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634622702644, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 13}}
DLL 2021-10-19 05:51:42.644728 - epoch   13 |   dev ema wer  25.57 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622702644, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634622702645, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 14, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622702645, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634622707219, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 14}}
DLL 2021-10-19 05:51:47.219383 - epoch   14 | avg train utts/s 60895 | took  4.57 s
:::MLLOG {"namespace": "", "time_ms": 1634622707219, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60894.61854941851, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622707219, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634622707363, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.19806257122899892, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634622707363, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 14}}
DLL 2021-10-19 05:51:47.364246 - epoch   14 |   dev ema wer  19.81 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622707364, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634622707364, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 15, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622707364, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 15}}
DLL 2021-10-19 05:51:50.644052 - epoch   15 | iter   96/136 | loss   62.41 | utts/s   630 | took  3.25 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634622711986, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 15}}
DLL 2021-10-19 05:51:51.986994 - epoch   15 | avg train utts/s 60263 | took  4.62 s
:::MLLOG {"namespace": "", "time_ms": 1634622711987, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60263.30496851582, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622711987, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634622712130, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1665379949266571, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634622712131, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 15}}
DLL 2021-10-19 05:51:52.131420 - epoch   15 |   dev ema wer  16.65 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622712131, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634622712131, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 16, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622712132, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634622716673, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 16}}
DLL 2021-10-19 05:51:56.674202 - epoch   16 | avg train utts/s 61324 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634622716674, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61323.537113373975, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622716674, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634622716819, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.14260505128487924, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634622716819, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 16}}
DLL 2021-10-19 05:51:56.819873 - epoch   16 |   dev ema wer  14.26 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622716820, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634622716820, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 17, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622716820, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634622721402, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 17}}
DLL 2021-10-19 05:52:01.402715 - epoch   17 | avg train utts/s 60789 | took  4.58 s
:::MLLOG {"namespace": "", "time_ms": 1634622721402, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60788.96293481007, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622721402, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634622721548, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.12780780118378002, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634622721548, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 17}}
DLL 2021-10-19 05:52:01.549172 - epoch   17 |   dev ema wer  12.78 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622721549, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634622721549, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 18, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622721550, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634622726083, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 18}}
DLL 2021-10-19 05:52:06.083643 - epoch   18 | avg train utts/s 61440 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634622726083, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61439.89056775006, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622726083, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634622726229, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.11674203154295798, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634622726229, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 18}}
DLL 2021-10-19 05:52:06.230265 - epoch   18 |   dev ema wer  11.67 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622726230, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634622726230, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 19, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622726230, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634622730777, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 19}}
DLL 2021-10-19 05:52:10.777843 - epoch   19 | avg train utts/s 61255 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634622730777, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61254.64677752613, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622730778, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634622730922, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.10834160508804823, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634622730923, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 19}}
DLL 2021-10-19 05:52:10.923572 - epoch   19 |   dev ema wer  10.83 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622730923, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634622730924, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 20, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622730924, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622735437, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 20}}
DLL 2021-10-19 05:52:15.438387 - epoch   20 | avg train utts/s 61704 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634622735438, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61703.95484840098, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622735438, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622735584, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1019815447961472, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622735585, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 20}}
DLL 2021-10-19 05:52:15.585590 - epoch   20 |   dev ema wer  10.20 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622735585, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622735586, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 21, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622735586, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634622740237, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 21}}
DLL 2021-10-19 05:52:20.237663 - epoch   21 | avg train utts/s 59883 | took  4.65 s
:::MLLOG {"namespace": "", "time_ms": 1634622740237, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59883.29192030229, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622740237, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634622740383, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.09821330098158156, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634622740383, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 21}}
DLL 2021-10-19 05:52:20.384373 - epoch   21 |   dev ema wer   9.82 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622740384, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634622740384, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 22, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622740385, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634622744923, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 22}}
DLL 2021-10-19 05:52:24.924165 - epoch   22 | avg train utts/s 61365 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634622744924, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61364.81680878461, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622744924, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634622745071, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.09323186647549722, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634622745072, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 22}}
DLL 2021-10-19 05:52:25.072697 - epoch   22 |   dev ema wer   9.32 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622745073, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634622745073, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 23, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622745073, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 23}}
DLL 2021-10-19 05:52:25.357753 - epoch   23 | iter    8/136 | loss   43.50 | utts/s  7792 | took  0.26 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634622749643, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 23}}
DLL 2021-10-19 05:52:29.643915 - epoch   23 | avg train utts/s 60944 | took  4.57 s
:::MLLOG {"namespace": "", "time_ms": 1634622749644, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60944.255254997865, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622749644, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634622749788, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.09016212639241204, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634622749789, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 23}}
DLL 2021-10-19 05:52:29.789648 - epoch   23 |   dev ema wer   9.02 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622749789, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634622749790, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 24, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622749790, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634622754329, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 24}}
DLL 2021-10-19 05:52:34.330115 - epoch   24 | avg train utts/s 61353 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634622754330, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61352.70577618087, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622754330, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634622754475, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08714753134075953, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634622754475, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 24}}
DLL 2021-10-19 05:52:34.476164 - epoch   24 |   dev ema wer   8.71 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622754476, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634622754477, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 25, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622754477, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634622759004, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 25}}
DLL 2021-10-19 05:52:39.005026 - epoch   25 | avg train utts/s 61517 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634622759005, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61517.19223421155, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622759005, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634622759151, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08426160802911657, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634622759151, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 25}}
DLL 2021-10-19 05:52:39.152222 - epoch   25 |   dev ema wer   8.43 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622759152, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634622759152, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 26, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622759152, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634622763668, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 26}}
DLL 2021-10-19 05:52:43.669226 - epoch   26 | avg train utts/s 61674 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634622763669, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61673.65036321392, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622763669, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634622763817, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08172493658321385, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634622763817, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 26}}
DLL 2021-10-19 05:52:43.817950 - epoch   26 |   dev ema wer   8.17 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622763818, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634622763818, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 27, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622763818, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634622768296, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 27}}
DLL 2021-10-19 05:52:48.297144 - epoch   27 | avg train utts/s 62194 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634622768297, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62193.76982763596, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622768297, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634622768441, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0800522039630896, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634622768442, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 27}}
DLL 2021-10-19 05:52:48.442394 - epoch   27 |   dev ema wer   8.01 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622768442, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634622768442, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 28, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622768443, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634622773030, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 28}}
DLL 2021-10-19 05:52:53.030979 - epoch   28 | avg train utts/s 60711 | took  4.59 s
:::MLLOG {"namespace": "", "time_ms": 1634622773031, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60711.43806465279, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622773031, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634622773178, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07874710488584978, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634622773179, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 28}}
DLL 2021-10-19 05:52:53.179504 - epoch   28 |   dev ema wer   7.87 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622773179, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634622773180, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 29, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622773180, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634622777689, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 29}}
DLL 2021-10-19 05:52:57.689780 - epoch   29 | avg train utts/s 61766 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634622777689, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61765.9954051595, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622777690, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634622777834, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07703760891143709, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634622777835, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 29}}
DLL 2021-10-19 05:52:57.835569 - epoch   29 |   dev ema wer   7.70 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622777835, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634622777836, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 30, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622777836, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 30}}
DLL 2021-10-19 05:52:59.699683 - epoch   30 | iter   56/136 | loss   40.56 | utts/s  1115 | took  1.84 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634622782348, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 30}}
DLL 2021-10-19 05:53:02.349204 - epoch   30 | avg train utts/s 61723 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634622782349, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61722.922101110256, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622782349, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634622782494, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07604499834564905, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634622782495, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 30}}
DLL 2021-10-19 05:53:02.495592 - epoch   30 |   dev ema wer   7.60 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622782495, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634622782496, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 31, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622782496, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634622787067, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 31}}
DLL 2021-10-19 05:53:07.068331 - epoch   31 | avg train utts/s 60920 | took  4.57 s
:::MLLOG {"namespace": "", "time_ms": 1634622787068, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60920.33376654002, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622787068, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634622787214, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07556707473989926, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634622787214, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 31}}
DLL 2021-10-19 05:53:07.215075 - epoch   31 |   dev ema wer   7.56 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622787215, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634622787215, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 32, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622787215, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634622791723, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 32}}
DLL 2021-10-19 05:53:11.723523 - epoch   32 | avg train utts/s 61790 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634622791723, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61789.81773610399, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622791723, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634622791870, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07481342597698613, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634622791870, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 32}}
DLL 2021-10-19 05:53:11.870866 - epoch   32 |   dev ema wer   7.48 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622791871, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634622791871, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 33, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622791871, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634622796362, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 33}}
DLL 2021-10-19 05:53:16.362679 - epoch   33 | avg train utts/s 62020 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634622796362, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62019.97670209034, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622796362, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634622796507, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07499724274842837, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634622796508, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 33}}
DLL 2021-10-19 05:53:16.508622 - epoch   33 |   dev ema wer   7.50 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622796509, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634622796509, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 34, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622796509, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634622801016, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 34}}
DLL 2021-10-19 05:53:21.016622 - epoch   34 | avg train utts/s 61798 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634622801016, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61798.18539247653, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622801016, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634622801161, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07288334987684277, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634622801161, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 34}}
DLL 2021-10-19 05:53:21.162113 - epoch   34 |   dev ema wer   7.29 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622801162, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634622801162, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 35, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622801162, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634622805649, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 35}}
DLL 2021-10-19 05:53:25.649486 - epoch   35 | avg train utts/s 62082 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634622805649, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62082.01795685983, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622805649, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634622805795, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07314069335686188, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634622805795, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 35}}
DLL 2021-10-19 05:53:25.796300 - epoch   35 |   dev ema wer   7.31 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622805796, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634622805796, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 36, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622805796, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634622810277, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 36}}
DLL 2021-10-19 05:53:30.277483 - epoch   36 | avg train utts/s 62167 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634622810277, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62166.50209347386, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622810277, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634622810422, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07223999117679497, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634622810423, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 36}}
DLL 2021-10-19 05:53:30.423615 - epoch   36 |   dev ema wer   7.22 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622810423, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634622810424, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 37, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622810424, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 37}}
DLL 2021-10-19 05:53:33.889331 - epoch   37 | iter  104/136 | loss   32.28 | utts/s   595 | took  3.44 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634622814923, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 37}}
DLL 2021-10-19 05:53:34.923614 - epoch   37 | avg train utts/s 61906 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634622814923, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61906.37434861465, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622814923, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634622815069, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07185397595676629, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634622815069, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 37}}
DLL 2021-10-19 05:53:35.070174 - epoch   37 |   dev ema wer   7.19 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622815070, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634622815070, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 38, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622815070, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634622819622, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 38}}
DLL 2021-10-19 05:53:39.623127 - epoch   38 | avg train utts/s 61187 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634622819623, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61187.23778360606, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622819623, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634622819770, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07194588434248742, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634622819771, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 38}}
DLL 2021-10-19 05:53:39.771576 - epoch   38 |   dev ema wer   7.19 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622819771, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634622819772, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 39, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622819772, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634622824314, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 39}}
DLL 2021-10-19 05:53:44.314755 - epoch   39 | avg train utts/s 61319 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634622824314, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61318.580200987526, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622824314, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634622824460, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07170692253961251, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634622824461, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 39}}
DLL 2021-10-19 05:53:44.461633 - epoch   39 |   dev ema wer   7.17 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622824462, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634622824462, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 40, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622824462, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634622828956, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 40}}
DLL 2021-10-19 05:53:48.956726 - epoch   40 | avg train utts/s 61975 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634622828956, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61974.74681252608, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622828956, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634622829103, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07176206757104518, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634622829104, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 40}}
DLL 2021-10-19 05:53:49.104590 - epoch   40 |   dev ema wer   7.18 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622829104, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634622829105, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 41, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622829105, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634622833617, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 41}}
DLL 2021-10-19 05:53:53.618220 - epoch   41 | avg train utts/s 61720 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634622833618, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61719.59595778581, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622833618, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634622833764, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06970331973089225, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634622833764, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 41}}
DLL 2021-10-19 05:53:53.765191 - epoch   41 |   dev ema wer   6.97 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622833765, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634622833765, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 42, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622833765, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634622838287, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 42}}
DLL 2021-10-19 05:53:58.287463 - epoch   42 | avg train utts/s 61602 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634622838287, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61602.207691781594, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622838287, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634622838436, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06885776258225801, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634622838436, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 42}}
DLL 2021-10-19 05:53:58.436740 - epoch   42 |   dev ema wer   6.89 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622838436, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634622838437, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 43, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622838437, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634622842927, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 43}}
DLL 2021-10-19 05:54:02.927479 - epoch   43 | avg train utts/s 62033 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634622842927, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62033.48904191822, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622842927, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634622843072, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06830631226793132, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634622843073, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 43}}
DLL 2021-10-19 05:54:03.073674 - epoch   43 |   dev ema wer   6.83 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622843073, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634622843073, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 44, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622843074, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634622847558, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 44}}
DLL 2021-10-19 05:54:07.558492 - epoch   44 | avg train utts/s 62114 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634622847558, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62113.7720735154, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622847558, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634622847704, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06692768648211463, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634622847704, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 44}}
DLL 2021-10-19 05:54:07.704970 - epoch   44 |   dev ema wer   6.69 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622847705, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634622847705, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 45, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622847705, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 45}}
DLL 2021-10-19 05:54:08.233567 - epoch   45 | iter   16/136 | loss   32.25 | utts/s  4055 | took  0.51 s | lrate 4.68e-03
:::MLLOG {"namespace": "", "time_ms": 1634622852239, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 45}}
DLL 2021-10-19 05:54:12.239622 - epoch   45 | avg train utts/s 61432 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634622852239, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61432.475717648886, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622852239, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634622852387, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06565935075916327, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634622852387, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 45}}
DLL 2021-10-19 05:54:12.387855 - epoch   45 |   dev ema wer   6.57 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622852388, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634622852388, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 46, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622852388, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634622856848, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 46}}
DLL 2021-10-19 05:54:16.849264 - epoch   46 | avg train utts/s 62441 | took  4.46 s
:::MLLOG {"namespace": "", "time_ms": 1634622856849, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62441.40151889663, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622856849, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634622856996, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0642255799419139, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634622856996, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 46}}
DLL 2021-10-19 05:54:16.996994 - epoch   46 |   dev ema wer   6.42 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622856997, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634622856997, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 47, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622856997, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634622861503, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 47}}
DLL 2021-10-19 05:54:21.503554 - epoch   47 | avg train utts/s 61812 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634622861503, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61812.01660446035, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622861503, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634622861649, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06360060291901033, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634622861649, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 47}}
DLL 2021-10-19 05:54:21.650233 - epoch   47 |   dev ema wer   6.36 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622861650, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634622861650, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 48, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622861650, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634622866128, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 48}}
DLL 2021-10-19 05:54:26.129313 - epoch   48 | avg train utts/s 62195 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634622866129, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62195.21347648464, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622866129, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634622866274, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06233226719605897, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634622866274, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 48}}
DLL 2021-10-19 05:54:26.275327 - epoch   48 |   dev ema wer   6.23 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622866275, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634622866275, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 49, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622866275, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634622870799, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 49}}
DLL 2021-10-19 05:54:30.799606 - epoch   49 | avg train utts/s 61575 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634622870799, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61574.5927979568, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622870799, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634622870945, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.062258740487482075, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634622870946, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 49}}
DLL 2021-10-19 05:54:30.946574 - epoch   49 |   dev ema wer   6.23 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622870946, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634622870947, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 50, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622870947, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634622875492, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 50}}
DLL 2021-10-19 05:54:35.493107 - epoch   50 | avg train utts/s 61275 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634622875493, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61275.22530644533, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622875493, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634622875637, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.060420572773059816, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634622875637, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 50}}
DLL 2021-10-19 05:54:35.638327 - epoch   50 |   dev ema wer   6.04 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622875638, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634622875639, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 51, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622875639, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634622880081, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 51}}
DLL 2021-10-19 05:54:40.082265 - epoch   51 | avg train utts/s 62690 | took  4.44 s
:::MLLOG {"namespace": "", "time_ms": 1634622880082, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62689.768312255204, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622880082, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634622880227, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05929929046726223, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634622880228, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 51}}
DLL 2021-10-19 05:54:40.228706 - epoch   51 |   dev ema wer   5.93 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622880229, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634622880229, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 52, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622880229, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 52}}
DLL 2021-10-19 05:54:42.409758 - epoch   52 | iter   64/136 | loss   35.00 | utts/s   949 | took  2.16 s | lrate 2.92e-03
:::MLLOG {"namespace": "", "time_ms": 1634622884777, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 52}}
DLL 2021-10-19 05:54:44.777975 - epoch   52 | avg train utts/s 61237 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634622884778, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61237.169904928705, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622884778, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634622884921, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05955663394728135, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634622884921, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 52}}
DLL 2021-10-19 05:54:44.922244 - epoch   52 |   dev ema wer   5.96 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622884922, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634622884922, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 53, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622884923, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634622889438, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 53}}
DLL 2021-10-19 05:54:49.439019 - epoch   53 | avg train utts/s 61678 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634622889439, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61677.925651199024, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622889439, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634622889583, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05887651189294511, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634622889584, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 53}}
DLL 2021-10-19 05:54:49.584501 - epoch   53 |   dev ema wer   5.89 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622889584, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634622889584, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 54, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622889585, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634622894053, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 54}}
DLL 2021-10-19 05:54:54.054109 - epoch   54 | avg train utts/s 62326 | took  4.47 s
:::MLLOG {"namespace": "", "time_ms": 1634622894054, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62326.48758843889, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622894054, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634622894198, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.058416969964339545, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634622894198, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 54}}
DLL 2021-10-19 05:54:54.199276 - epoch   54 |   dev ema wer   5.84 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622894199, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634622894199, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 55, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622894199, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634622898694, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 55}}
DLL 2021-10-19 05:54:58.695092 - epoch   55 | avg train utts/s 61964 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634622898695, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61964.490683535216, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622898695, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634622898840, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.058380206610051104, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634622898840, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 55}}
DLL 2021-10-19 05:54:58.840837 - epoch   55 |   dev ema wer   5.84 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634622898841, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634622898841, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 56, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622898841, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634622903300, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 56}}
DLL 2021-10-19 05:55:03.300956 - epoch   56 | avg train utts/s 62459 | took  4.46 s
:::MLLOG {"namespace": "", "time_ms": 1634622903301, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62459.34220076974, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634622903301, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634622903445, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.057957428035733984, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634622903446, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 56}}
DLL 2021-10-19 05:55:03.446490 - epoch   56 |   dev ema wer   5.80 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634622903446, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634622903447, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1028, "status": "success"}}
Finished after 0 epochs.
DLL 2021-10-19 05:55:03.447202 -  | avg train utts/s 58600
ENDING TIMING RUN AT 2021-10-19 05:55:19 AM
RESULT,RNN_SPEECH_RECOGNITION,,417,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:19 AM
RESULT,RNN_SPEECH_RECOGNITION,,417,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:20 AM
RESULT,RNN_SPEECH_RECOGNITION,,418,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:20 AM
RESULT,RNN_SPEECH_RECOGNITION,,418,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:21 AM
ENDING TIMING RUN AT 2021-10-19 05:55:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 05:48:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:27 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:28 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:28 AM
ENDING TIMING RUN AT 2021-10-19 05:55:28 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:48:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:28 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:28 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:48:22 AM
ENDING TIMING RUN AT 2021-10-19 05:55:28 AM
RESULT,RNN_SPEECH_RECOGNITION,,426,nvidia,2021-10-19 05:48:22 AM
