+ : DGXA100_16x8x16x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/rnntv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019070309753706529
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets
+ : /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ : ./api_logs
+ : 4329
+ : 30
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized
+ LOGBASE=rnnt_16x8x16_211019070309753706529
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019070309753706529
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019070309753706529
+ readonly _cont_name=rnn_speech_recognition
+ _cont_name=rnn_speech_recognition
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets:/datasets/,/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743:/results
+ _cont_mounts+=,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized:/metadata
+ _cont_mounts+=,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets/sentencepieces:/sentencepieces
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07418/slurm_script: line 43: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ srun --ntasks=16 mkdir -p /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743
+ srun --ntasks=16 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/rnntv11.sqsh --container-name=rnn_speech_recognition true
+ [[ DGXA100_16x8x16x1 == \D\G\X\A\1\0\0* ]]
+ echo 'using NCCL_TOPO_FILE /opt/microsoft/ndv4-topo.xml'
using NCCL_TOPO_FILE /opt/microsoft/ndv4-topo.xml
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743/rnnt_16x8x16_211019070309753706529_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ srun --nodes=1 --ntasks=1 --container-name=rnn_speech_recognition python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=16 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C04DD
Clearing cache on ip-0A0C04E5
Clearing cache on ip-0A0C04DF
Clearing cache on ip-0A0C04E7
Clearing cache on ip-0A0C04C1
Clearing cache on ip-0A0C04E1
Clearing cache on ip-0A0C04ED
Clearing cache on ip-0A0C04B8
Clearing cache on ip-0A0C04EF
Clearing cache on ip-0A0C04E9
Clearing cache on ip-0A0C04EB
Clearing cache on ip-0A0C04E8
Clearing cache on ip-0A0C04EE
Clearing cache on ip-0A0C04EA
Clearing cache on ip-0A0C04DE
Clearing cache on ip-0A0C04E4
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=16 --container-name=rnn_speech_recognition python -c '
from mlperf import logging
logging.log_event(key=logging.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1634627000550, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000565, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000572, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000579, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000582, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000594, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000621, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000632, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000635, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000634, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000638, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000639, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000675, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000679, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000681, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627000683, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ SEED=4330
+ srun --mpi=none --ntasks=128 --ntasks-per-node=8 --container-name=rnn_speech_recognition --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets:/datasets/,/mnt/resource_nvme/mlcommons/logs/rnnt/16N-m19.051743:/results,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/tokenized:/metadata,/mnt/resource_nvme/mlcommons/v1.1/bm_data/rnnt_data/datasets/sentencepieces:/sentencepieces,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/rnnt/implementations/pytorch/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 07:03:21 AM
running benchmark
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
/bm_utils/bind.sh --cpu=/bm_utils/azure.sh --mem=/bm_utils/azure.sh --cluster=azure -- python -u
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=num_sockets = 2 num_nodes=4 cores_per_socket=48
pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointpack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=num_sockets = 2 num_nodes=4 cores_per_socket=48
pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=num_sockets = 2 num_nodes=4 cores_per_socket=48
pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointpack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_jointnum_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u train.py --batch_size=16 --beta1=0.905 --beta2=0.999 --max_duration=16.7 --val_batch_size=22 --target=0.058 --lr=0.007 --min_lr=1e-5 --lr_exp_gamma=0.935 --epochs=80 --warmup_epochs=6 --hold_epochs=33 --epochs_this_job=0 --ema=0.995 --output_dir /results --model_config=configs/baseline_v3-1023sp.yaml --seed 4330 --dataset_dir=/datasets/LibriSpeech --cudnn_benchmark --dali_device gpu --weight_decay=1e-3 --log_frequency=1000 --val_frequency=1 --grad_accumulation_steps=1 --prediction_frequency=1000000 --weights_init_scale=0.5 --val_manifests=/metadata/librispeech-dev-clean-wav-tokenized.pkl --train_manifests /metadata/librispeech-train-clean-100-wav-tokenized.pkl /metadata/librispeech-train-clean-360-wav-tokenized.pkl /metadata/librispeech-train-other-500-wav-tokenized.pkl --num_buckets=1 --max_symbol_per_sample=300 --apex_transducer_loss=fp16 --fuse_relu_dropout --multi_tensor_ema --batch_eval_mode cg_unroll_pipeline --dist_lamb --apex_transducer_joint=pack_w_relu_dropout --buffer_pre_alloc --ema_update_type=fp16 --amp_level 2 --data_cpu_threads 8 --num_cg 50 --vectorized_sa --enable_prefetch --tokenized_transcript --vectorized_sampler --dist_sampler --apex_mlp --dwu_overlap_reduction
:::MLLOG {"namespace": "", "time_ms": 1634627005937, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627005947, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627005951, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627005964, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627005964, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627005968, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627005970, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627005987, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627005998, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627005997, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006000, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006051, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006056, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006059, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006065, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006066, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006080, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006088, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006091, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006098, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006097, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006104, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006105, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006110, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006111, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006112, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006114, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006116, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006119, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006119, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006125, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006132, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006136, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006146, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006147, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006146, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006155, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006160, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006160, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006163, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006177, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006177, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006180, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006179, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006180, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006182, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006184, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006189, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006190, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006192, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006192, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006196, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006198, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006198, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006200, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006201, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006209, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006208, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006212, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006215, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006212, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006214, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006221, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006227, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006228, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006228, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006232, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006229, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006236, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006240, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006245, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006248, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006250, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006251, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006256, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006252, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006254, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006259, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006258, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006259, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006260, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006261, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006264, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006265, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006265, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006265, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006266, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006269, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006275, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006280, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006286, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006288, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006295, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006297, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006314, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006313, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006318, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006320, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006321, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006326, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006327, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006331, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006339, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006343, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006346, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006346, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006350, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006354, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006355, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006353, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006358, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006363, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006367, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006371, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006375, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006377, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006378, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006381, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006383, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006387, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006392, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006394, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006396, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006397, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006404, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006408, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
:::MLLOG {"namespace": "", "time_ms": 1634627006413, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 403}}
Distributed training with 128 GPUs

:::MLLOG {"namespace": "", "time_ms": 1634627007436, "event_type": "POINT_IN_TIME", "key": "seed", "value": 4330, "metadata": {"file": "train.py", "lineno": 421}}
DLL 2021-10-19 07:03:27.441693 - PARAMETER | epochs :  80
DLL 2021-10-19 07:03:27.441893 - PARAMETER | warmup_epochs :  6
DLL 2021-10-19 07:03:27.441938 - PARAMETER | hold_epochs :  33
DLL 2021-10-19 07:03:27.441961 - PARAMETER | epochs_this_job :  0
DLL 2021-10-19 07:03:27.441987 - PARAMETER | cudnn_benchmark :  True
DLL 2021-10-19 07:03:27.442009 - PARAMETER | amp_level :  2
DLL 2021-10-19 07:03:27.442031 - PARAMETER | seed :  4330
DLL 2021-10-19 07:03:27.442049 - PARAMETER | local_rank :  0
DLL 2021-10-19 07:03:27.442068 - PARAMETER | target :  0.058
DLL 2021-10-19 07:03:27.442094 - PARAMETER | apex_transducer_loss :  fp16
DLL 2021-10-19 07:03:27.442116 - PARAMETER | fuse_relu_dropout :  True
DLL 2021-10-19 07:03:27.442136 - PARAMETER | weights_init_scale :  0.5
DLL 2021-10-19 07:03:27.442154 - PARAMETER | hidden_hidden_bias_scale : 
DLL 2021-10-19 07:03:27.442182 - PARAMETER | batch_eval_mode :  cg_unroll_pipeline
DLL 2021-10-19 07:03:27.442201 - PARAMETER | cg_unroll_factor :  4
DLL 2021-10-19 07:03:27.442221 - PARAMETER | apex_transducer_joint :  pack_w_relu_dropout
DLL 2021-10-19 07:03:27.442239 - PARAMETER | buffer_pre_alloc :  True
DLL 2021-10-19 07:03:27.442259 - PARAMETER | multilayer_lstm :  False
DLL 2021-10-19 07:03:27.442277 - PARAMETER | batch_split_factor :  1
DLL 2021-10-19 07:03:27.442295 - PARAMETER | apex_mlp :  True
DLL 2021-10-19 07:03:27.442313 - PARAMETER | num_cg :  50
DLL 2021-10-19 07:03:27.442330 - PARAMETER | min_seq_split_len :  -1
DLL 2021-10-19 07:03:27.442351 - PARAMETER | pre_sort_for_seq_split :  False
DLL 2021-10-19 07:03:27.442371 - PARAMETER | batch_size :  16
DLL 2021-10-19 07:03:27.442390 - PARAMETER | val_batch_size :  22
DLL 2021-10-19 07:03:27.442408 - PARAMETER | lr :  0.007
DLL 2021-10-19 07:03:27.442426 - PARAMETER | min_lr :  1e-05
DLL 2021-10-19 07:03:27.442487 - PARAMETER | lr_exp_gamma :  0.935
DLL 2021-10-19 07:03:27.442509 - PARAMETER | weight_decay :  0.001
DLL 2021-10-19 07:03:27.442530 - PARAMETER | grad_accumulation_steps :  1
DLL 2021-10-19 07:03:27.442548 - PARAMETER | clip_norm :  1
DLL 2021-10-19 07:03:27.442566 - PARAMETER | beta1 :  0.905
DLL 2021-10-19 07:03:27.442585 - PARAMETER | beta2 :  0.999
DLL 2021-10-19 07:03:27.442603 - PARAMETER | ema :  0.995
DLL 2021-10-19 07:03:27.442622 - PARAMETER | multi_tensor_ema :  True
DLL 2021-10-19 07:03:27.442639 - PARAMETER | dist_lamb :  True
DLL 2021-10-19 07:03:27.442657 - PARAMETER | ema_update_type :  fp16
DLL 2021-10-19 07:03:27.442674 - PARAMETER | dwu_group_size :  8
DLL 2021-10-19 07:03:27.442693 - PARAMETER | dwu_overlap_reduction :  True
DLL 2021-10-19 07:03:27.442718 - PARAMETER | dali_device :  gpu
DLL 2021-10-19 07:03:27.442737 - PARAMETER | resume :  False
DLL 2021-10-19 07:03:27.442755 - PARAMETER | ckpt : 
DLL 2021-10-19 07:03:27.442773 - PARAMETER | save_at_the_end :  False
DLL 2021-10-19 07:03:27.442790 - PARAMETER | save_frequency : 
DLL 2021-10-19 07:03:27.442807 - PARAMETER | keep_milestones :  []
DLL 2021-10-19 07:03:27.442836 - PARAMETER | save_best_from :  200
DLL 2021-10-19 07:03:27.442855 - PARAMETER | val_frequency :  1
DLL 2021-10-19 07:03:27.442872 - PARAMETER | log_frequency :  1000
DLL 2021-10-19 07:03:27.442896 - PARAMETER | prediction_frequency :  1000000
DLL 2021-10-19 07:03:27.442914 - PARAMETER | model_config :  configs/baseline_v3-1023sp.yaml
DLL 2021-10-19 07:03:27.442932 - PARAMETER | num_buckets :  1
DLL 2021-10-19 07:03:27.442952 - PARAMETER | vectorized_sampler :  True
DLL 2021-10-19 07:03:27.442969 - PARAMETER | dist_sampler :  True
DLL 2021-10-19 07:03:27.442987 - PARAMETER | train_manifests :  ['/metadata/librispeech-train-clean-100-wav-tokenized.pkl', '/metadata/librispeech-train-clean-360-wav-tokenized.pkl', '/metadata/librispeech-train-other-500-wav-tokenized.pkl']
DLL 2021-10-19 07:03:27.443018 - PARAMETER | val_manifests :  ['/metadata/librispeech-dev-clean-wav-tokenized.pkl']
DLL 2021-10-19 07:03:27.443039 - PARAMETER | max_duration :  16.7
DLL 2021-10-19 07:03:27.443058 - PARAMETER | max_txt_len :  125
DLL 2021-10-19 07:03:27.443082 - PARAMETER | max_eval_sample_duration :  32.7
DLL 2021-10-19 07:03:27.443102 - PARAMETER | dataset_dir :  /datasets/LibriSpeech
DLL 2021-10-19 07:03:27.443120 - PARAMETER | output_dir :  /results
DLL 2021-10-19 07:03:27.443140 - PARAMETER | log_file : 
DLL 2021-10-19 07:03:27.443157 - PARAMETER | max_symbol_per_sample :  300
DLL 2021-10-19 07:03:27.443175 - PARAMETER | data_cpu_threads :  8
DLL 2021-10-19 07:03:27.443193 - PARAMETER | synthetic_audio_seq_len : 
DLL 2021-10-19 07:03:27.443210 - PARAMETER | synthetic_text_seq_len : 
DLL 2021-10-19 07:03:27.443228 - PARAMETER | enable_seq_len_stats :  False
DLL 2021-10-19 07:03:27.443245 - PARAMETER | vectorized_sa :  True
DLL 2021-10-19 07:03:27.443265 - PARAMETER | in_mem_file_list :  False
DLL 2021-10-19 07:03:27.443283 - PARAMETER | enable_prefetch :  True
DLL 2021-10-19 07:03:27.443304 - PARAMETER | tokenized_transcript :  True
DLL 2021-10-19 07:03:27.443331 - PARAMETER | dali_dont_use_mmap :  False
:::MLLOG {"namespace": "", "time_ms": 1634627007466, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "train.py", "lineno": 438}}
:::MLLOG {"namespace": "", "time_ms": 1634627007466, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "rnnt", "metadata": {"file": "train.py", "lineno": 445}}
:::MLLOG {"namespace": "", "time_ms": 1634627007466, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "train.py", "lineno": 446}}
:::MLLOG {"namespace": "", "time_ms": 1634627007466, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "train.py", "lineno": 447}}
:::MLLOG {"namespace": "", "time_ms": 1634627007466, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "train.py", "lineno": 448}}
:::MLLOG {"namespace": "", "time_ms": 1634627007466, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "16xND96amsr_A100_v4", "metadata": {"file": "train.py", "lineno": 449}}
:::MLLOG {"namespace": "", "time_ms": 1634627007469, "event_type": "POINT_IN_TIME", "key": "model_weights_initialization_scale", "value": 0.5, "metadata": {"file": "train.py", "lineno": 456}}
:::MLLOG {"namespace": "", "time_ms": 1634627007624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "pre_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634627007945, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "post_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634627007949, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 201, "tensor": "pred_embed"}}
:::MLLOG {"namespace": "", "time_ms": 1634627007974, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/common/rnn.py", "lineno": 195, "tensor": "dec_rnn"}}
:::MLLOG {"namespace": "", "time_ms": 1634627007976, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 221, "tensor": "joint_pred"}}
:::MLLOG {"namespace": "", "time_ms": 1634627007979, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 226, "tensor": "joint_enc"}}
:::MLLOG {"namespace": "", "time_ms": 1634627007987, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/rnnt/rnnt/model.py", "lineno": 243, "tensor": "joint_net"}}
:::MLLOG {"namespace": "", "time_ms": 1634627011144, "event_type": "POINT_IN_TIME", "key": "eval_max_prediction_symbols", "value": 300, "metadata": {"file": "train.py", "lineno": 483}}
Model size: 49.1M params

:::MLLOG {"namespace": "", "time_ms": 1634627011167, "event_type": "POINT_IN_TIME", "key": "model_eval_ema_factor", "value": 0.995, "metadata": {"file": "train.py", "lineno": 497}}
[ip-0A0C04DD:0:77758 - context.c:584] INFO job (ID: 867749143124370462) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:77758 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:77758 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:77759 - context.c:584] INFO job (ID: 867749036184240456) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:77759 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:77759 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:77761 - context.c:584] INFO job (ID: 867748927472054889) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:77761 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:77761 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:77762 - context.c:584] INFO job (ID: 867748959605331829) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:77762 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:77762 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:77764 - context.c:584] INFO job (ID: 867749517585053970) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:77764 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:77764 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:77766 - context.c:584] INFO job (ID: 867749549369794419) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:77766 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:77766 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:77760 - context.c:584] INFO job (ID: 867749893556360319) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:77760 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:77760 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C04DD:0:77763 - context.c:584] INFO job (ID: 867748892971208682) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C04DD:0:77763 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C04DD:0:77763 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
Starting with LRs: 0.007000000216066837
Setting up datasets...
:::MLLOG {"namespace": "", "time_ms": 1634627040709, "event_type": "POINT_IN_TIME", "key": "data_train_max_duration", "value": 16.7, "metadata": {"file": "train.py", "lineno": 568}}
:::MLLOG {"namespace": "", "time_ms": 1634627040710, "event_type": "POINT_IN_TIME", "key": "data_speed_perturbaton_max", "value": 1.15, "metadata": {"file": "train.py", "lineno": 570}}
:::MLLOG {"namespace": "", "time_ms": 1634627040710, "event_type": "POINT_IN_TIME", "key": "data_speed_perturbaton_min", "value": 0.85, "metadata": {"file": "train.py", "lineno": 572}}
:::MLLOG {"namespace": "", "time_ms": 1634627040710, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_n", "value": 2, "metadata": {"file": "train.py", "lineno": 574}}
:::MLLOG {"namespace": "", "time_ms": 1634627040710, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_min", "value": 0, "metadata": {"file": "train.py", "lineno": 576}}
:::MLLOG {"namespace": "", "time_ms": 1634627040710, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_freq_max", "value": 20, "metadata": {"file": "train.py", "lineno": 578}}
:::MLLOG {"namespace": "", "time_ms": 1634627040710, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_n", "value": 10, "metadata": {"file": "train.py", "lineno": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634627040710, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_min", "value": 0, "metadata": {"file": "train.py", "lineno": 582}}
:::MLLOG {"namespace": "", "time_ms": 1634627040710, "event_type": "POINT_IN_TIME", "key": "data_spec_augment_time_max", "value": 0.03, "metadata": {"file": "train.py", "lineno": 584}}
:::MLLOG {"namespace": "", "time_ms": 1634627040710, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 2048, "metadata": {"file": "train.py", "lineno": 586}}
Graph with max_seq_len of 641
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:565: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:506.)
  return torch.floor_divide(self, other)
:::MLLOG {"namespace": "", "time_ms": 1634627131413, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train.py", "lineno": 691}}
:::MLLOG {"namespace": "", "time_ms": 1634627131507, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "train.py", "lineno": 694}}
:::MLLOG {"namespace": "", "time_ms": 1634627131512, "event_type": "POINT_IN_TIME", "key": "data_train_num_buckets", "value": 1, "metadata": {"file": "train.py", "lineno": 700}}
Launching vectorized bucketing sampler
Launching simple sampler
Dataset read by DALI. Number of samples: 278528
Initializing DALI with parameters:
	           dither : 1e-05
	    dont_use_mmap : False
	        file_root : /datasets/LibriSpeech
	     gpu_pipeline : True
	 in_mem_file_list : False
	             nfft : 512
	          nfilter : 80
	   resample_range : [0.85, 1.15]
	      sample_rate : 16000
	          sampler : <common.data.dali.sampler.VectorizedBucketingSampler object at 0x153acda732b0>
	   spect_wind_len : 320.0
	  spect_wind_step : 160.0
	synthetic_seq_len : None
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:162: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
  _iterator_deprecation_warning()
Dataset read by DALI. Number of samples: 2703
Initializing DALI with parameters:
	           dither : 1e-05
	    dont_use_mmap : False
	        file_root : /datasets/LibriSpeech
	     gpu_pipeline : True
	 in_mem_file_list : False
	             nfft : 512
	          nfilter : 80
	   resample_range : None
	      sample_rate : 16000
	          sampler : <common.data.dali.sampler.SimpleSampler object at 0x153acda4d1f0>
	   spect_wind_len : 320.0
	  spect_wind_step : 160.0
	synthetic_seq_len : None
:::MLLOG {"namespace": "", "time_ms": 1634627135870, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 278528, "metadata": {"file": "train.py", "lineno": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634627135870, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 2703, "metadata": {"file": "train.py", "lineno": 781}}
:::MLLOG {"namespace": "", "time_ms": 1634627135871, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "lamb", "metadata": {"file": "train.py", "lineno": 783}}
:::MLLOG {"namespace": "", "time_ms": 1634627135871, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.007, "metadata": {"file": "train.py", "lineno": 784}}
:::MLLOG {"namespace": "", "time_ms": 1634627135871, "event_type": "POINT_IN_TIME", "key": "opt_lamb_epsilon", "value": 1e-09, "metadata": {"file": "train.py", "lineno": 785}}
:::MLLOG {"namespace": "", "time_ms": 1634627135871, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 0.935, "metadata": {"file": "train.py", "lineno": 786}}
:::MLLOG {"namespace": "", "time_ms": 1634627135871, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 6, "metadata": {"file": "train.py", "lineno": 787}}
:::MLLOG {"namespace": "", "time_ms": 1634627135871, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_hold_epochs", "value": 33, "metadata": {"file": "train.py", "lineno": 788}}
:::MLLOG {"namespace": "", "time_ms": 1634627135871, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.905, "metadata": {"file": "train.py", "lineno": 789}}
:::MLLOG {"namespace": "", "time_ms": 1634627135871, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.999, "metadata": {"file": "train.py", "lineno": 790}}
:::MLLOG {"namespace": "", "time_ms": 1634627135871, "event_type": "POINT_IN_TIME", "key": "opt_gradient_clip_norm", "value": 1, "metadata": {"file": "train.py", "lineno": 791}}
:::MLLOG {"namespace": "", "time_ms": 1634627135872, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_alt_decay_func", "value": true, "metadata": {"file": "train.py", "lineno": 792}}
:::MLLOG {"namespace": "", "time_ms": 1634627135872, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_alt_warmup_func", "value": true, "metadata": {"file": "train.py", "lineno": 793}}
:::MLLOG {"namespace": "", "time_ms": 1634627135872, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_min", "value": 1e-05, "metadata": {"file": "train.py", "lineno": 794}}
:::MLLOG {"namespace": "", "time_ms": 1634627135872, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.001, "metadata": {"file": "train.py", "lineno": 795}}
Pre-allocate buffer with max_seq_len of 1921 and max_txt_len of 125
:::MLLOG {"namespace": "", "time_ms": 1634627135980, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 1, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627135980, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627142278, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 1}}
DLL 2021-10-19 07:05:42.278899 - epoch    1 | avg train utts/s 44222 | took  6.30 s
:::MLLOG {"namespace": "", "time_ms": 1634627142279, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 44222.08710323024, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627142279, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627142463, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 14.71151795889857, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627142463, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 1}}
DLL 2021-10-19 07:05:42.463777 - epoch    1 |   dev ema wer 1471.15 | took  0.18 s
:::MLLOG {"namespace": "", "time_ms": 1634627142463, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627142464, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 2, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627142464, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634627147652, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 2}}
DLL 2021-10-19 07:05:47.652577 - epoch    2 | avg train utts/s 53688 | took  5.19 s
:::MLLOG {"namespace": "", "time_ms": 1634627147652, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 53687.57971749927, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627147652, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634627147786, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634627147787, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 2}}
DLL 2021-10-19 07:05:47.787616 - epoch    2 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634627147787, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1634627147788, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 3, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627147788, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627152782, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 3}}
DLL 2021-10-19 07:05:52.782712 - epoch    3 | avg train utts/s 55772 | took  4.99 s
:::MLLOG {"namespace": "", "time_ms": 1634627152782, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 55771.521042614186, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627152782, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627152916, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627152916, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 3}}
DLL 2021-10-19 07:05:52.916840 - epoch    3 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634627152917, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1634627152917, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 4, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627152917, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634627157742, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 4}}
DLL 2021-10-19 07:05:57.742473 - epoch    4 | avg train utts/s 57730 | took  4.82 s
:::MLLOG {"namespace": "", "time_ms": 1634627157742, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 57729.52989993271, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627157742, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634627157870, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9773905371126062, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634627157870, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 4}}
DLL 2021-10-19 07:05:57.871336 - epoch    4 |   dev ema wer  97.74 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634627157871, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1634627157871, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 5, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627157872, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634627162513, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 5}}
DLL 2021-10-19 07:06:02.514108 - epoch    5 | avg train utts/s 60003 | took  4.64 s
:::MLLOG {"namespace": "", "time_ms": 1634627162514, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60002.61147258215, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627162514, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634627162649, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9954781074225212, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634627162650, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 5}}
DLL 2021-10-19 07:06:02.650547 - epoch    5 |   dev ema wer  99.55 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627162650, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 5}}
:::MLLOG {"namespace": "", "time_ms": 1634627162651, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 6, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627162651, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634627167459, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 6}}
DLL 2021-10-19 07:06:07.459883 - epoch    6 | avg train utts/s 57924 | took  4.81 s
:::MLLOG {"namespace": "", "time_ms": 1634627167459, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 57924.054795629025, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627167460, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634627167597, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634627167597, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 6}}
DLL 2021-10-19 07:06:07.597851 - epoch    6 |   dev ema wer 100.00 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627167598, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 6}}
:::MLLOG {"namespace": "", "time_ms": 1634627167598, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 7, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627167598, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634627172337, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 7}}
DLL 2021-10-19 07:06:12.337815 - epoch    7 | avg train utts/s 58773 | took  4.74 s
:::MLLOG {"namespace": "", "time_ms": 1634627172337, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 58772.7165071724, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627172338, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634627172468, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634627172469, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 7}}
DLL 2021-10-19 07:06:12.469516 - epoch    7 |   dev ema wer 100.00 | took  0.13 s
:::MLLOG {"namespace": "", "time_ms": 1634627172469, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1634627172470, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 8, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627172470, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 8}}
DLL 2021-10-19 07:06:14.123776 - epoch    8 | iter   48/136 | loss  238.75 | utts/s  1256 | took  1.63 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634627177124, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 8}}
DLL 2021-10-19 07:06:17.124756 - epoch    8 | avg train utts/s 59842 | took  4.65 s
:::MLLOG {"namespace": "", "time_ms": 1634627177124, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59841.80426851976, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627177124, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634627177233, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634627177233, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 8}}
DLL 2021-10-19 07:06:17.233954 - epoch    8 |   dev ema wer 100.00 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634627177234, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1634627177234, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 9, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627177234, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634627181913, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 9}}
DLL 2021-10-19 07:06:21.913877 - epoch    9 | avg train utts/s 59529 | took  4.68 s
:::MLLOG {"namespace": "", "time_ms": 1634627181913, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 59528.925054661, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627181914, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634627182020, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 1.0, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634627182021, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 9}}
DLL 2021-10-19 07:06:22.021628 - epoch    9 |   dev ema wer 100.00 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634627182021, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 9}}
:::MLLOG {"namespace": "", "time_ms": 1634627182021, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 10, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627182022, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634627186612, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 10}}
DLL 2021-10-19 07:06:26.612992 - epoch   10 | avg train utts/s 60673 | took  4.59 s
:::MLLOG {"namespace": "", "time_ms": 1634627186613, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60673.32323446992, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627186613, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634627186721, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9870592992904672, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634627186722, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 10}}
DLL 2021-10-19 07:06:26.722529 - epoch   10 |   dev ema wer  98.71 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634627186722, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1634627186723, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 11, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627186723, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634627191329, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 11}}
DLL 2021-10-19 07:06:31.329507 - epoch   11 | avg train utts/s 60470 | took  4.61 s
:::MLLOG {"namespace": "", "time_ms": 1634627191329, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60470.108908104135, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627191329, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634627191439, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9537517003051358, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634627191439, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 11}}
DLL 2021-10-19 07:06:31.440040 - epoch   11 |   dev ema wer  95.38 | took  0.11 s
:::MLLOG {"namespace": "", "time_ms": 1634627191440, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1634627191440, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 12, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627191440, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634627196021, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 12}}
DLL 2021-10-19 07:06:36.021495 - epoch   12 | avg train utts/s 60808 | took  4.58 s
:::MLLOG {"namespace": "", "time_ms": 1634627196021, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60808.2168395966, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627196021, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634627196144, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7982243299878681, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634627196144, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 12}}
DLL 2021-10-19 07:06:36.145010 - epoch   12 |   dev ema wer  79.82 | took  0.12 s
:::MLLOG {"namespace": "", "time_ms": 1634627196145, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1634627196145, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 13, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627196145, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634627200726, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 13}}
DLL 2021-10-19 07:06:40.726711 - epoch   13 | avg train utts/s 60802 | took  4.58 s
:::MLLOG {"namespace": "", "time_ms": 1634627200726, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60802.1561608869, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627200726, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634627200861, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5047608543803537, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634627200862, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 13}}
DLL 2021-10-19 07:06:40.862615 - epoch   13 |   dev ema wer  50.48 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627200862, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 13}}
:::MLLOG {"namespace": "", "time_ms": 1634627200863, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 14, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627200863, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634627205402, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 14}}
DLL 2021-10-19 07:06:45.402623 - epoch   14 | avg train utts/s 61361 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634627205402, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61360.916779332016, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627205402, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634627205543, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.32691812800999964, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634627205544, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 14}}
DLL 2021-10-19 07:06:45.544655 - epoch   14 |   dev ema wer  32.69 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627205544, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 14}}
:::MLLOG {"namespace": "", "time_ms": 1634627205545, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 15, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627205545, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 15}}
DLL 2021-10-19 07:06:48.808241 - epoch   15 | iter   96/136 | loss   58.22 | utts/s   632 | took  3.24 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634627210138, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 15}}
DLL 2021-10-19 07:06:50.139094 - epoch   15 | avg train utts/s 60634 | took  4.59 s
:::MLLOG {"namespace": "", "time_ms": 1634627210139, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60633.7047111321, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627210139, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634627210283, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.22942171243704276, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634627210283, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 15}}
DLL 2021-10-19 07:06:50.284061 - epoch   15 |   dev ema wer  22.94 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627210284, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1634627210284, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 16, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627210284, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634627214831, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 16}}
DLL 2021-10-19 07:06:54.832092 - epoch   16 | avg train utts/s 61252 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634627214832, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61251.72417345406, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627214832, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634627214977, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.18225432888496745, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634627214977, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 16}}
DLL 2021-10-19 07:06:54.977825 - epoch   16 |   dev ema wer  18.23 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627214978, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1634627214978, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 17, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627214978, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634627219557, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 17}}
DLL 2021-10-19 07:06:59.558184 - epoch   17 | avg train utts/s 60821 | took  4.58 s
:::MLLOG {"namespace": "", "time_ms": 1634627219558, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60821.39309310824, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627219558, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634627219703, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.1544428513657586, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634627219703, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 17}}
DLL 2021-10-19 07:06:59.703870 - epoch   17 |   dev ema wer  15.44 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627219704, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 17}}
:::MLLOG {"namespace": "", "time_ms": 1634627219704, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 18, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627219704, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634627224250, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 18}}
DLL 2021-10-19 07:07:04.250495 - epoch   18 | avg train utts/s 61272 | took  4.55 s
:::MLLOG {"namespace": "", "time_ms": 1634627224250, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61271.61945054111, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627224250, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634627224393, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.13374508290136392, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634627224393, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 18}}
DLL 2021-10-19 07:07:04.394364 - epoch   18 |   dev ema wer  13.37 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627224394, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 18}}
:::MLLOG {"namespace": "", "time_ms": 1634627224394, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 19, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627224395, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634627228915, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 19}}
DLL 2021-10-19 07:07:08.916013 - epoch   19 | avg train utts/s 61611 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634627228916, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61611.35642433705, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627228916, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634627229067, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.12152126760045587, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634627229067, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 19}}
DLL 2021-10-19 07:07:09.068347 - epoch   19 |   dev ema wer  12.15 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627229068, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1634627229068, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 20, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627229068, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634627233653, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 20}}
DLL 2021-10-19 07:07:13.653829 - epoch   20 | avg train utts/s 60751 | took  4.58 s
:::MLLOG {"namespace": "", "time_ms": 1634627233653, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 60751.401530694864, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627233654, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634627233798, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.11199955883974853, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634627233799, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 20}}
DLL 2021-10-19 07:07:13.799565 - epoch   20 |   dev ema wer  11.20 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627233799, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634627233800, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 21, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627233800, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634627238315, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 21}}
DLL 2021-10-19 07:07:18.316144 - epoch   21 | avg train utts/s 61681 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634627238316, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61680.78811354897, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627238316, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634627238461, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.10470203301349215, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634627238461, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 21}}
DLL 2021-10-19 07:07:18.462040 - epoch   21 |   dev ema wer  10.47 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627238462, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 21}}
:::MLLOG {"namespace": "", "time_ms": 1634627238462, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 22, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627238462, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634627242987, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 22}}
DLL 2021-10-19 07:07:22.987578 - epoch   22 | avg train utts/s 61561 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634627242987, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61561.17256061522, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627242987, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634627243132, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.09779052240726444, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634627243132, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 22}}
DLL 2021-10-19 07:07:23.133011 - epoch   22 |   dev ema wer   9.78 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627243133, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 22}}
:::MLLOG {"namespace": "", "time_ms": 1634627243133, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 23, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627243133, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 23}}
DLL 2021-10-19 07:07:23.396595 - epoch   23 | iter    8/136 | loss   48.50 | utts/s  8558 | took  0.24 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634627247640, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 23}}
DLL 2021-10-19 07:07:27.640793 - epoch   23 | avg train utts/s 61801 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634627247640, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61801.37288882672, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627247641, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634627247787, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0923127826182861, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634627247787, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 23}}
DLL 2021-10-19 07:07:27.788025 - epoch   23 |   dev ema wer   9.23 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627247788, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1634627247788, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 24, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627247788, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634627252295, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 24}}
DLL 2021-10-19 07:07:32.296203 - epoch   24 | avg train utts/s 61798 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634627252296, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61797.63292654413, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627252296, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634627252440, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0893900959523547, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634627252440, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 24}}
DLL 2021-10-19 07:07:32.441323 - epoch   24 |   dev ema wer   8.94 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627252441, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1634627252442, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 25, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627252442, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634627256941, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 25}}
DLL 2021-10-19 07:07:36.941759 - epoch   25 | avg train utts/s 61904 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634627256941, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61904.20928470589, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627256941, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634627257087, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08659608102643285, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634627257087, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 25}}
DLL 2021-10-19 07:07:37.088205 - epoch   25 |   dev ema wer   8.66 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627257088, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 25}}
:::MLLOG {"namespace": "", "time_ms": 1634627257088, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 26, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627257088, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634627261628, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 26}}
DLL 2021-10-19 07:07:41.628583 - epoch   26 | avg train utts/s 61352 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634627261628, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61352.37390193492, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627261628, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634627261774, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08468438660343369, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634627261774, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 26}}
DLL 2021-10-19 07:07:41.774812 - epoch   26 |   dev ema wer   8.47 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627261775, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 26}}
:::MLLOG {"namespace": "", "time_ms": 1634627261775, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 27, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627261775, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634627266297, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 27}}
DLL 2021-10-19 07:07:46.297421 - epoch   27 | avg train utts/s 61599 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634627266297, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61598.54376272295, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627266297, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634627266443, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08257049373184809, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634627266444, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 27}}
DLL 2021-10-19 07:07:46.444750 - epoch   27 |   dev ema wer   8.26 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627266445, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1634627266445, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 28, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627266445, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634627270927, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 28}}
DLL 2021-10-19 07:07:50.927577 - epoch   28 | avg train utts/s 62145 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634627270927, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62144.68594161002, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627270927, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634627271071, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.08056689092312783, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634627271071, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 28}}
DLL 2021-10-19 07:07:51.072382 - epoch   28 |   dev ema wer   8.06 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627271072, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1634627271072, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 29, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627271073, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634627275617, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 29}}
DLL 2021-10-19 07:07:55.618003 - epoch   29 | avg train utts/s 61285 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634627275618, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61284.7015389122, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627275618, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634627275763, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0785265247601191, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634627275763, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 29}}
DLL 2021-10-19 07:07:55.764325 - epoch   29 |   dev ema wer   7.85 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627275764, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 29}}
:::MLLOG {"namespace": "", "time_ms": 1634627275764, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 30, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627275764, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 30}}
DLL 2021-10-19 07:07:57.626301 - epoch   30 | iter   56/136 | loss   47.03 | utts/s  1115 | took  1.84 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634627280257, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 30}}
DLL 2021-10-19 07:08:00.257991 - epoch   30 | avg train utts/s 61995 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634627280258, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61994.815250445856, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627280258, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634627280404, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07749715084004265, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634627280405, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 30}}
DLL 2021-10-19 07:08:00.405436 - epoch   30 |   dev ema wer   7.75 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627280405, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1634627280406, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 31, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627280406, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634627284879, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 31}}
DLL 2021-10-19 07:08:04.879736 - epoch   31 | avg train utts/s 62265 | took  4.47 s
:::MLLOG {"namespace": "", "time_ms": 1634627284879, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62264.92934152673, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627284879, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634627285025, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0756773648027646, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634627285025, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 31}}
DLL 2021-10-19 07:08:05.026296 - epoch   31 |   dev ema wer   7.57 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627285026, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1634627285026, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 32, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627285027, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634627289487, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 32}}
DLL 2021-10-19 07:08:09.488404 - epoch   32 | avg train utts/s 62433 | took  4.46 s
:::MLLOG {"namespace": "", "time_ms": 1634627289488, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62433.07899444696, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627289488, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634627289634, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07560383809418772, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634627289635, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 32}}
DLL 2021-10-19 07:08:09.635630 - epoch   32 |   dev ema wer   7.56 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627289636, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1634627289636, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 33, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627289636, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634627294132, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 33}}
DLL 2021-10-19 07:08:14.133393 - epoch   33 | avg train utts/s 61940 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634627294133, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61939.574549334255, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627294133, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634627294277, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07534649461416859, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634627294277, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 33}}
DLL 2021-10-19 07:08:14.277820 - epoch   33 |   dev ema wer   7.53 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627294277, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 33}}
:::MLLOG {"namespace": "", "time_ms": 1634627294278, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 34, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627294278, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634627298778, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 34}}
DLL 2021-10-19 07:08:18.778426 - epoch   34 | avg train utts/s 61897 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634627298778, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61897.03613239976, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627298778, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634627298923, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0745377008198228, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634627298923, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 34}}
DLL 2021-10-19 07:08:18.924266 - epoch   34 |   dev ema wer   7.45 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627298924, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 34}}
:::MLLOG {"namespace": "", "time_ms": 1634627298924, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 35, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627298925, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634627303469, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 35}}
DLL 2021-10-19 07:08:23.469485 - epoch   35 | avg train utts/s 61291 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634627303469, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61290.97456518511, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627303469, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634627303615, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07301202161685232, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634627303616, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 35}}
DLL 2021-10-19 07:08:23.616672 - epoch   35 |   dev ema wer   7.30 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627303617, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1634627303617, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 36, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627303617, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634627308120, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 36}}
DLL 2021-10-19 07:08:28.121167 - epoch   36 | avg train utts/s 61845 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634627308121, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61845.43977792562, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627308121, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634627308268, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07343480019116944, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634627308268, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 36}}
DLL 2021-10-19 07:08:28.268978 - epoch   36 |   dev ema wer   7.34 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627308269, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 36}}
:::MLLOG {"namespace": "", "time_ms": 1634627308269, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 37, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627308269, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 37}}
DLL 2021-10-19 07:08:31.735965 - epoch   37 | iter  104/136 | loss   26.88 | utts/s   595 | took  3.44 s | lrate 7.00e-03
:::MLLOG {"namespace": "", "time_ms": 1634627312802, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 37}}
DLL 2021-10-19 07:08:32.803179 - epoch   37 | avg train utts/s 61439 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634627312803, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61438.930898084196, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627312803, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634627312950, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07255247968824675, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634627312950, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 37}}
DLL 2021-10-19 07:08:32.950877 - epoch   37 |   dev ema wer   7.26 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627312951, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 37}}
:::MLLOG {"namespace": "", "time_ms": 1634627312951, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 38, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627312951, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634627317452, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 38}}
DLL 2021-10-19 07:08:37.453228 - epoch   38 | avg train utts/s 61875 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634627317453, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61875.087498429595, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627317453, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634627317600, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0715231057681703, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634627317600, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 38}}
DLL 2021-10-19 07:08:37.600988 - epoch   38 |   dev ema wer   7.15 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627317601, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 38}}
:::MLLOG {"namespace": "", "time_ms": 1634627317601, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 39, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627317601, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634627322143, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 39}}
DLL 2021-10-19 07:08:42.144282 - epoch   39 | avg train utts/s 61315 | took  4.54 s
:::MLLOG {"namespace": "", "time_ms": 1634627322144, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61315.23312903689, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627322144, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634627322290, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07029153339950737, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634627322291, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 39}}
DLL 2021-10-19 07:08:42.291512 - epoch   39 |   dev ema wer   7.03 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627322291, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 39}}
:::MLLOG {"namespace": "", "time_ms": 1634627322292, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 40, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627322292, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634627326819, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 40}}
DLL 2021-10-19 07:08:46.819860 - epoch   40 | avg train utts/s 61520 | took  4.53 s
:::MLLOG {"namespace": "", "time_ms": 1634627326819, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61520.04951552803, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627326820, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634627326964, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07073269365096871, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634627326965, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 40}}
DLL 2021-10-19 07:08:46.965556 - epoch   40 |   dev ema wer   7.07 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627326965, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634627326966, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 41, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627326966, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634627331468, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 41}}
DLL 2021-10-19 07:08:51.468573 - epoch   41 | avg train utts/s 61865 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634627331468, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61865.28039482576, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627331468, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634627331613, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.07065916694239183, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634627331614, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 41}}
DLL 2021-10-19 07:08:51.614672 - epoch   41 |   dev ema wer   7.07 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627331615, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 41}}
:::MLLOG {"namespace": "", "time_ms": 1634627331615, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 42, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627331615, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634627336115, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 42}}
DLL 2021-10-19 07:08:56.115969 - epoch   42 | avg train utts/s 61891 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634627336116, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61891.235196431364, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627336116, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634627336262, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06929892283371934, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634627336262, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 42}}
DLL 2021-10-19 07:08:56.263291 - epoch   42 |   dev ema wer   6.93 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627336263, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 42}}
:::MLLOG {"namespace": "", "time_ms": 1634627336264, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 43, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627336264, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634627340723, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 43}}
DLL 2021-10-19 07:09:00.724352 - epoch   43 | avg train utts/s 62451 | took  4.46 s
:::MLLOG {"namespace": "", "time_ms": 1634627340724, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62450.86132327403, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627340724, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634627340870, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06815925885077755, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634627340870, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 43}}
DLL 2021-10-19 07:09:00.870895 - epoch   43 |   dev ema wer   6.82 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627340871, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 43}}
:::MLLOG {"namespace": "", "time_ms": 1634627340871, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 44, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627340871, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634627345334, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 44}}
DLL 2021-10-19 07:09:05.334434 - epoch   44 | avg train utts/s 62416 | took  4.46 s
:::MLLOG {"namespace": "", "time_ms": 1634627345334, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62416.46727777468, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627345334, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634627345480, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06628432778206683, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634627345481, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 44}}
DLL 2021-10-19 07:09:05.481591 - epoch   44 |   dev ema wer   6.63 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627345482, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 44}}
:::MLLOG {"namespace": "", "time_ms": 1634627345482, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 45, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627345482, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 45}}
DLL 2021-10-19 07:09:06.005065 - epoch   45 | iter   16/136 | loss   40.09 | utts/s  4121 | took  0.50 s | lrate 4.68e-03
:::MLLOG {"namespace": "", "time_ms": 1634627350003, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 45}}
DLL 2021-10-19 07:09:10.004354 - epoch   45 | avg train utts/s 61595 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634627350004, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61595.20178202691, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627350004, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634627350150, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.0643910150362119, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634627350150, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 45}}
DLL 2021-10-19 07:09:10.151250 - epoch   45 |   dev ema wer   6.44 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627350151, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 45}}
:::MLLOG {"namespace": "", "time_ms": 1634627350151, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 46, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627350152, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634627354631, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 46}}
DLL 2021-10-19 07:09:14.632116 - epoch   46 | avg train utts/s 62174 | took  4.48 s
:::MLLOG {"namespace": "", "time_ms": 1634627354632, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62173.827182118424, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627354632, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634627354776, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06411528987904856, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634627354777, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 46}}
DLL 2021-10-19 07:09:14.777630 - epoch   46 |   dev ema wer   6.41 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627354777, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634627354778, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 47, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627354778, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634627359271, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 47}}
DLL 2021-10-19 07:09:19.272082 - epoch   47 | avg train utts/s 61982 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634627359272, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61981.961008431645, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627359272, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634627359419, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06338002279327966, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634627359420, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 47}}
DLL 2021-10-19 07:09:19.420596 - epoch   47 |   dev ema wer   6.34 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627359420, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634627359421, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 48, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627359421, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634627363906, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 48}}
DLL 2021-10-19 07:09:23.907287 - epoch   48 | avg train utts/s 62091 | took  4.49 s
:::MLLOG {"namespace": "", "time_ms": 1634627363907, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62091.17776589113, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627363907, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634627364051, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06246093893606853, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634627364052, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 48}}
DLL 2021-10-19 07:09:24.052432 - epoch   48 |   dev ema wer   6.25 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627364052, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 48}}
:::MLLOG {"namespace": "", "time_ms": 1634627364053, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 49, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627364053, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634627368575, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 49}}
DLL 2021-10-19 07:09:28.575682 - epoch   49 | avg train utts/s 61592 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634627368575, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61592.21736528458, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627368575, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634627368722, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06143156501599206, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634627368723, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 49}}
DLL 2021-10-19 07:09:28.723556 - epoch   49 |   dev ema wer   6.14 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627368723, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 49}}
:::MLLOG {"namespace": "", "time_ms": 1634627368723, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 50, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627368724, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634627373192, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 50}}
DLL 2021-10-19 07:09:33.192415 - epoch   50 | avg train utts/s 62340 | took  4.47 s
:::MLLOG {"namespace": "", "time_ms": 1634627373192, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62340.38333202772, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627373192, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634627373338, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.061376419984559394, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634627373338, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 50}}
DLL 2021-10-19 07:09:33.339361 - epoch   50 |   dev ema wer   6.14 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627373339, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1634627373339, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 51, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627373340, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634627377838, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 51}}
DLL 2021-10-19 07:09:37.839175 - epoch   51 | avg train utts/s 61908 | took  4.50 s
:::MLLOG {"namespace": "", "time_ms": 1634627377839, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61908.401773028076, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627377839, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634627377984, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06110069482739605, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634627377984, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 51}}
DLL 2021-10-19 07:09:37.984937 - epoch   51 |   dev ema wer   6.11 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627377985, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 51}}
:::MLLOG {"namespace": "", "time_ms": 1634627377985, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 52, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627377985, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 52}}
DLL 2021-10-19 07:09:40.154728 - epoch   52 | iter   64/136 | loss   28.61 | utts/s   956 | took  2.14 s | lrate 2.92e-03
:::MLLOG {"namespace": "", "time_ms": 1634627382509, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 52}}
DLL 2021-10-19 07:09:42.509539 - epoch   52 | avg train utts/s 61570 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634627382509, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61570.28963786228, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627382509, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634627382653, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.060953641410242274, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634627382653, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 52}}
DLL 2021-10-19 07:09:42.654336 - epoch   52 |   dev ema wer   6.10 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627382654, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 52}}
:::MLLOG {"namespace": "", "time_ms": 1634627382655, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 53, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627382655, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634627387171, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 53}}
DLL 2021-10-19 07:09:47.172335 - epoch   53 | avg train utts/s 61673 | took  4.52 s
:::MLLOG {"namespace": "", "time_ms": 1634627387172, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61672.605238262564, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627387172, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634627387317, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.06062277122164626, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634627387317, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 53}}
DLL 2021-10-19 07:09:47.318207 - epoch   53 |   dev ema wer   6.06 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627387318, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 53}}
:::MLLOG {"namespace": "", "time_ms": 1634627387318, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 54, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627387318, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634627391786, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 54}}
DLL 2021-10-19 07:09:51.786940 - epoch   54 | avg train utts/s 62340 | took  4.47 s
:::MLLOG {"namespace": "", "time_ms": 1634627391787, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 62339.71467783707, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627391787, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634627391931, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05896842027866622, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634627391932, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 54}}
DLL 2021-10-19 07:09:51.932702 - epoch   54 |   dev ema wer   5.90 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627391932, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 54}}
:::MLLOG {"namespace": "", "time_ms": 1634627391933, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 55, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627391933, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634627396442, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 55}}
DLL 2021-10-19 07:09:56.443269 - epoch   55 | avg train utts/s 61761 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634627396443, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61761.32587346307, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627396443, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634627396587, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.05896842027866622, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634627396587, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 55}}
DLL 2021-10-19 07:09:56.588378 - epoch   55 |   dev ema wer   5.90 | took  0.14 s
:::MLLOG {"namespace": "", "time_ms": 1634627396588, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 55}}
:::MLLOG {"namespace": "", "time_ms": 1634627396588, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "train.py", "lineno": 872, "first_epoch_num": 56, "epoch_count": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634627396589, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "train.py", "lineno": 875, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634627401095, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "train.py", "lineno": 995, "epoch_num": 56}}
DLL 2021-10-19 07:10:01.096333 - epoch   56 | avg train utts/s 61798 | took  4.51 s
:::MLLOG {"namespace": "", "time_ms": 1634627401096, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 61797.62965754434, "metadata": {"file": "train.py", "lineno": 1006}}
:::MLLOG {"namespace": "", "time_ms": 1634627401096, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "train.py", "lineno": 243, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634627401242, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.057920664681445536, "metadata": {"file": "train.py", "lineno": 263, "epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634627401242, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "train.py", "lineno": 264, "epoch_num": 56}}
DLL 2021-10-19 07:10:01.242898 - epoch   56 |   dev ema wer   5.79 | took  0.15 s
:::MLLOG {"namespace": "", "time_ms": 1634627401243, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1025, "first_epoch_num": 56}}
:::MLLOG {"namespace": "", "time_ms": 1634627401243, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "train.py", "lineno": 1028, "status": "success"}}
Finished after 0 epochs.
DLL 2021-10-19 07:10:01.243438 -  | avg train utts/s 58800
ENDING TIMING RUN AT 2021-10-19 07:10:18 AM
RESULT,RNN_SPEECH_RECOGNITION,,417,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:18 AM
RESULT,RNN_SPEECH_RECOGNITION,,417,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:18 AM
RESULT,RNN_SPEECH_RECOGNITION,,417,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:18 AM
RESULT,RNN_SPEECH_RECOGNITION,,417,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:18 AM
RESULT,RNN_SPEECH_RECOGNITION,,417,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:18 AM
RESULT,RNN_SPEECH_RECOGNITION,,417,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:19 AM
RESULT,RNN_SPEECH_RECOGNITION,,418,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:19 AM
RESULT,RNN_SPEECH_RECOGNITION,,418,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:19 AM
RESULT,RNN_SPEECH_RECOGNITION,,418,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:19 AM
RESULT,RNN_SPEECH_RECOGNITION,,418,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:19 AM
RESULT,RNN_SPEECH_RECOGNITION,,418,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:19 AM
RESULT,RNN_SPEECH_RECOGNITION,,418,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:19 AM
RESULT,RNN_SPEECH_RECOGNITION,,418,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:19 AM
RESULT,RNN_SPEECH_RECOGNITION,,418,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:20 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:20 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:20 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:20 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:20 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:20 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:20 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:20 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:20 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:20 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:20 AM
RESULT,RNN_SPEECH_RECOGNITION,,419,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,420,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:22 AM
RESULT,RNN_SPEECH_RECOGNITION,,421,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:23 AM
RESULT,RNN_SPEECH_RECOGNITION,,422,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:24 AM
RESULT,RNN_SPEECH_RECOGNITION,,423,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:25 AM
RESULT,RNN_SPEECH_RECOGNITION,,424,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 07:03:21 AM
ENDING TIMING RUN AT 2021-10-19 07:10:26 AM
RESULT,RNN_SPEECH_RECOGNITION,,425,nvidia,2021-10-19 07:03:21 AM
