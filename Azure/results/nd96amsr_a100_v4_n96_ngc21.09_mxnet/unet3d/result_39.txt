+ : DGXA100_96x8x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019064803061805705
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data
+ : /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ LOGBASE=unet3d_96x8x1_211019064803061805705
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019064803061805705
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019064803061805705
+ readonly _cont_name=image_segmentation
+ _cont_name=image_segmentation
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07402/slurm_script: line 39: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh --container-name=image_segmentation true
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019064803061805705_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=96 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C048D
Clearing cache on ip-0A0C0483
Clearing cache on ip-0A0C0495
Clearing cache on ip-0A0C047E
Clearing cache on ip-0A0C0472
Clearing cache on ip-0A0C0466
Clearing cache on ip-0A0C0449
Clearing cache on ip-0A0C045F
Clearing cache on ip-0A0C048C
Clearing cache on ip-0A0C049F
Clearing cache on ip-0A0C0494
Clearing cache on ip-0A0C040F
Clearing cache on ip-0A0C0435
Clearing cache on ip-0A0C0436
Clearing cache on ip-0A0C0438
Clearing cache on ip-0A0C046C
Clearing cache on ip-0A0C0491
Clearing cache on ip-0A0C044D
Clearing cache on ip-0A0C0460
Clearing cache on ip-0A0C0464
Clearing cache on ip-0A0C0487
Clearing cache on ip-0A0C048B
Clearing cache on ip-0A0C046E
Clearing cache on ip-0A0C0441
Clearing cache on ip-0A0C0486
Clearing cache on ip-0A0C0437
Clearing cache on ip-0A0C0473
Clearing cache on ip-0A0C0493
Clearing cache on ip-0A0C0484
Clearing cache on ip-0A0C0443
Clearing cache on ip-0A0C0429
Clearing cache on ip-0A0C0492
Clearing cache on ip-0A0C04C2
Clearing cache on ip-0A0C04AC
Clearing cache on ip-0A0C0461
Clearing cache on ip-0A0C0490
Clearing cache on ip-0A0C0497
Clearing cache on ip-0A0C04A9
Clearing cache on ip-0A0C0499
Clearing cache on ip-0A0C049C
Clearing cache on ip-0A0C0488
Clearing cache on ip-0A0C04AD
Clearing cache on ip-0A0C04DA
Clearing cache on ip-0A0C04D9
Clearing cache on ip-0A0C04A7
Clearing cache on ip-0A0C04BE
Clearing cache on ip-0A0C0498
Clearing cache on ip-0A0C04A0
Clearing cache on ip-0A0C04AF
Clearing cache on ip-0A0C04C8
Clearing cache on ip-0A0C04B9
Clearing cache on ip-0A0C0489
Clearing cache on ip-0A0C04B1
Clearing cache on ip-0A0C04AA
Clearing cache on ip-0A0C04AB
Clearing cache on ip-0A0C04C0
Clearing cache on ip-0A0C04CF
Clearing cache on ip-0A0C04BD
Clearing cache on ip-0A0C0485
Clearing cache on ip-0A0C04A2
Clearing cache on ip-0A0C046B
Clearing cache on ip-0A0C04D8
Clearing cache on ip-0A0C04B6
Clearing cache on ip-0A0C048F
Clearing cache on ip-0A0C04A1
Clearing cache on ip-0A0C04B5
Clearing cache on ip-0A0C04C4
Clearing cache on ip-0A0C04A6
Clearing cache on ip-0A0C0482
Clearing cache on ip-0A0C04CD
Clearing cache on ip-0A0C04A5
Clearing cache on ip-0A0C04C9
Clearing cache on ip-0A0C04C5
Clearing cache on ip-0A0C04CC
Clearing cache on ip-0A0C04C3
Clearing cache on ip-0A0C04B0
Clearing cache on ip-0A0C04AE
Clearing cache on ip-0A0C04D3
Clearing cache on ip-0A0C04BB
Clearing cache on ip-0A0C048A
Clearing cache on ip-0A0C04B7
Clearing cache on ip-0A0C04B2
Clearing cache on ip-0A0C049D
Clearing cache on ip-0A0C0496
Clearing cache on ip-0A0C049B
Clearing cache on ip-0A0C04A8
Clearing cache on ip-0A0C04B4
Clearing cache on ip-0A0C04A4
Clearing cache on ip-0A0C042D
Clearing cache on ip-0A0C04BA
Clearing cache on ip-0A0C04DB
Clearing cache on ip-0A0C04C6
Clearing cache on ip-0A0C04B3
Clearing cache on ip-0A0C04BC
Clearing cache on ip-0A0C04C7
Clearing cache on ip-0A0C04D4
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=768 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:48:05 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
[1634626090.523011] [ip-0A0C0435:19040:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.536139] [ip-0A0C0464:76738:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.561764] [ip-0A0C0464:76737:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.566418] [ip-0A0C0435:19036:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.566936] [ip-0A0C04A0:51062:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.581266] [ip-0A0C0498:71688:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.590118] [ip-0A0C04C5:95766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.596294] [ip-0A0C0435:19042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.596561] [ip-0A0C0435:19039:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.605065] [ip-0A0C04A0:51063:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.605497] [ip-0A0C049C:48137:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.607001] [ip-0A0C04C5:95765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.621543] [ip-0A0C04A0:51059:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.632967] [ip-0A0C0485:41764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.640684] [ip-0A0C04B0:48079:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.642694] [ip-0A0C04BE:94682:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.644585] [ip-0A0C04A0:51066:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.647848] [ip-0A0C04BD:91722:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.648321] [ip-0A0C04A1:79109:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.647837] [ip-0A0C04C0:93519:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.654092] [ip-0A0C0437:72899:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.653689] [ip-0A0C044D:73801:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.654980] [ip-0A0C04B0:48077:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.656413] [ip-0A0C049C:48133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.655278] [ip-0A0C049B:50377:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.658489] [ip-0A0C0437:72896:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.660734] [ip-0A0C042D:48063:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.662816] [ip-0A0C0483:75605:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.665179] [ip-0A0C0486:76738:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.669840] [ip-0A0C0498:71689:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.671336] [ip-0A0C04A6:61246:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.672949] [ip-0A0C042D:48062:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.674765] [ip-0A0C046B:73781:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.677261] [ip-0A0C04B7:32522:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.676152] [ip-0A0C04A8:66710:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.677605] [ip-0A0C0461:40262:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.678926] [ip-0A0C04C8:97985:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.679557] [ip-0A0C0497:11747:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.684831] [ip-0A0C04B5:62270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.685649] [ip-0A0C04C4:93862:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.686205] [ip-0A0C0473:74883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.686731] [ip-0A0C04C6:89839:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.688103] [ip-0A0C0498:71686:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.691609] [ip-0A0C0473:74882:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.692023] [ip-0A0C04A1:79104:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.691172] [ip-0A0C04D3:96380:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.691586] [ip-0A0C044D:73804:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.692576] [ip-0A0C04C3:92938:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.692119] [ip-0A0C044D:73803:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.694464] [ip-0A0C04D9:17938:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.693634] [ip-0A0C04A6:61243:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.696416] [ip-0A0C048B:59356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.698326] [ip-0A0C046B:73782:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.698114] [ip-0A0C0489:76952:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.697499] [ip-0A0C0486:76736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.699280] [ip-0A0C04A1:79107:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.699348] [ip-0A0C0485:41769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.699361] [ip-0A0C04AD:38419:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.699746] [ip-0A0C0438:77436:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.701863] [ip-0A0C04BE:94681:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.702761] [ip-0A0C04D4:94117:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.703082] [ip-0A0C04BD:91723:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.703399] [ip-0A0C0464:76742:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.704619] [ip-0A0C0464:76739:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.704665] [ip-0A0C042D:48064:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.706188] [ip-0A0C04C8:97980:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.708335] [ip-0A0C04BB:36634:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.707777] [ip-0A0C0461:40256:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.708245] [ip-0A0C0435:19043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.710247] [ip-0A0C0435:19041:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.713035] [ip-0A0C04BB:36628:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.712149] [ip-0A0C0498:71692:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.713583] [ip-0A0C04C0:93523:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.714367] [ip-0A0C0435:19037:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.714560] [ip-0A0C04C5:95761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.715072] [ip-0A0C04AD:38415:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.714760] [ip-0A0C04B5:62276:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.715646] [ip-0A0C04A8:66711:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.717804] [ip-0A0C046C:71925:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.720339] [ip-0A0C0461:40260:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.723401] [ip-0A0C04B7:32524:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.724572] [ip-0A0C049B:50374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.725972] [ip-0A0C049D:67139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.726892] [ip-0A0C0435:19038:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.730396] [ip-0A0C0494:58096:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.731179] [ip-0A0C0473:74884:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.730049] [ip-0A0C0497:11744:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.732575] [ip-0A0C04C4:93863:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.733399] [ip-0A0C04C5:95763:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.734535] [ip-0A0C04C4:93868:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.735611] [ip-0A0C04A0:51061:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.738239] [ip-0A0C045F:74320:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.739053] [ip-0A0C0498:71690:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.741770] [ip-0A0C0464:76743:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.742130] [ip-0A0C0441:69550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.743048] [ip-0A0C049C:48136:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.744095] [ip-0A0C049C:48131:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.743419] [ip-0A0C0489:76953:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.744272] [ip-0A0C045F:74322:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.745361] [ip-0A0C0483:75600:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.744758] [ip-0A0C0489:76949:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.745093] [ip-0A0C0493:57911:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.747598] [ip-0A0C04A0:51060:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.747159] [ip-0A0C04C0:93522:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.747875] [ip-0A0C0487:76767:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.749418] [ip-0A0C046B:73783:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.749596] [ip-0A0C0436:77054:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.749602] [ip-0A0C0436:77058:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.750309] [ip-0A0C04DB:90181:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.751427] [ip-0A0C04BE:94684:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.751257] [ip-0A0C0499:62734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.752661] [ip-0A0C0441:69553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.752204] [ip-0A0C04A8:66709:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.753502] [ip-0A0C04A7:38550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.753264] [ip-0A0C04B5:62277:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.754751] [ip-0A0C0485:41763:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.755336] [ip-0A0C04A0:51064:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.755359] [ip-0A0C04B0:48075:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.755975] [ip-0A0C0464:76741:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.756116] [ip-0A0C04C3:92944:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.756590] [ip-0A0C04C8:97984:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.757102] [ip-0A0C04C3:92945:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.758136] [ip-0A0C04A0:51065:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.758245] [ip-0A0C04B7:32520:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.759439] [ip-0A0C0487:76766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.758712] [ip-0A0C0497:11745:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.760052] [ip-0A0C0464:76736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.760032] [ip-0A0C048D:62498:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.761764] [ip-0A0C0464:76740:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.762439] [ip-0A0C0441:69547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.763360] [ip-0A0C0466:79337:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.764603] [ip-0A0C04CC:97832:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.764650] [ip-0A0C049D:67137:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.765775] [ip-0A0C04D4:94123:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.766136] [ip-0A0C0460:76379:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.765860] [ip-0A0C04CF:20159:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.767439] [ip-0A0C04D9:17937:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.767680] [ip-0A0C0491:58925:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.767617] [ip-0A0C04BA:28902:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.767708] [ip-0A0C0491:58922:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.767626] [ip-0A0C04C5:95760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.768997] [ip-0A0C04C0:93516:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.771107] [ip-0A0C04BD:91718:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.771432] [ip-0A0C0438:77435:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.771438] [ip-0A0C0498:71693:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.772775] [ip-0A0C04C9:96875:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.772273] [ip-0A0C0461:40257:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.772836] [ip-0A0C0490:62661:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.772352] [ip-0A0C04C6:89837:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.773754] [ip-0A0C04D9:17935:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.774871] [ip-0A0C04A7:38528:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.774883] [ip-0A0C046C:71924:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.774964] [ip-0A0C046C:71931:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.774965] [ip-0A0C0437:72900:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.775158] [ip-0A0C0443:39891:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.774703] [ip-0A0C048A:73467:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.775698] [ip-0A0C04B5:62273:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.776761] [ip-0A0C04C2:19240:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.780712] [ip-0A0C0437:72898:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.780908] [ip-0A0C049B:50375:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.782588] [ip-0A0C0484:78719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.783024] [ip-0A0C042D:48060:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.783610] [ip-0A0C048D:62503:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.783604] [ip-0A0C0498:71691:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.785167] [ip-0A0C0485:41766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.785337] [ip-0A0C04AA:36199:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.785919] [ip-0A0C04DA:91573:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.787494] [ip-0A0C0499:62730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.787909] [ip-0A0C04B1:64642:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.788013] [ip-0A0C04AE:66626:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.788361] [ip-0A0C049D:67140:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.788898] [ip-0A0C049C:48134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.788488] [ip-0A0C04A4:61512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.789199] [ip-0A0C049C:48135:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.790726] [ip-0A0C04A1:79108:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.790141] [ip-0A0C04C5:95759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.790570] [ip-0A0C04B0:48080:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.790707] [ip-0A0C0466:79334:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.790968] [ip-0A0C0488:75404:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.791255] [ip-0A0C048B:59351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.791467] [ip-0A0C04C5:95767:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.790779] [ip-0A0C0449:74231:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.791067] [ip-0A0C04A9:60681:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.791714] [ip-0A0C0486:76735:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.793238] [ip-0A0C0483:75599:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.792520] [ip-0A0C04CF:20156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.793029] [ip-0A0C0493:57910:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.794295] [ip-0A0C04D8:97895:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.794424] [ip-0A0C0443:39890:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.794002] [ip-0A0C0497:11763:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.796956] [ip-0A0C04A2:53039:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.795457] [ip-0A0C0498:71687:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.795989] [ip-0A0C0429:67144:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.796081] [ip-0A0C0449:74228:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.798600] [ip-0A0C04AF:53127:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.800109] [ip-0A0C0494:58093:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.801014] [ip-0A0C04BA:28904:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.800600] [ip-0A0C04C5:95762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.801352] [ip-0A0C04DB:90182:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.800990] [ip-0A0C04D3:96375:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.802444] [ip-0A0C04BE:94679:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.802460] [ip-0A0C0495:60659:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.802940] [ip-0A0C04BC:89682:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.802974] [ip-0A0C04BC:89683:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.804852] [ip-0A0C04BD:91724:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.803886] [ip-0A0C044D:73806:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.806020] [ip-0A0C048A:73462:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.807071] [ip-0A0C04A9:60677:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.808542] [ip-0A0C0482:63912:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.808567] [ip-0A0C0482:63914:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.809225] [ip-0A0C0493:57909:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.811564] [ip-0A0C049C:48138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.812363] [ip-0A0C04B2:37744:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.812926] [ip-0A0C0472:78757:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.813720] [ip-0A0C049C:48132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.814402] [ip-0A0C04DA:91570:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.815110] [ip-0A0C04BB:36625:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.815061] [ip-0A0C0485:41765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.816093] [ip-0A0C0472:78759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.816289] [ip-0A0C04AE:66623:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.815879] [ip-0A0C04A6:61249:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.816482] [ip-0A0C040F:46682:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.817737] [ip-0A0C0485:41768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.818290] [ip-0A0C04B0:48078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.818501] [ip-0A0C04C8:97979:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.819495] [ip-0A0C0484:78726:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.818531] [ip-0A0C049B:50379:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.819937] [ip-0A0C04B1:64641:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.820480] [ip-0A0C04BE:94680:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.819397] [ip-0A0C04D3:96379:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.821211] [ip-0A0C0483:75602:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.820124] [ip-0A0C04A6:61242:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.820703] [ip-0A0C04B9:94815:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.822090] [ip-0A0C04BD:91717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.822325] [ip-0A0C0437:72897:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.823241] [ip-0A0C046C:71923:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.822206] [ip-0A0C0486:76741:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.823585] [ip-0A0C0488:75411:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.824346] [ip-0A0C047E:73158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.823386] [ip-0A0C04B6:31222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.825571] [ip-0A0C048B:59355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.825896] [ip-0A0C04D8:97899:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.827231] [ip-0A0C0483:75604:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.827740] [ip-0A0C0484:78725:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.828973] [ip-0A0C0473:74879:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.829090] [ip-0A0C04D8:97894:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.830035] [ip-0A0C042D:48059:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.830434] [ip-0A0C0437:72893:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.830863] [ip-0A0C04A1:79105:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.829928] [ip-0A0C0482:63917:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.831088] [ip-0A0C04D9:17936:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.830442] [ip-0A0C044D:73800:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.831821] [ip-0A0C04D4:94121:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.832775] [ip-0A0C04AD:38417:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.831906] [ip-0A0C04AF:53120:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.833003] [ip-0A0C0437:72894:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.831988] [ip-0A0C04AF:53122:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.833778] [ip-0A0C04B0:48076:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.834051] [ip-0A0C0483:75603:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.834418] [ip-0A0C04A4:61508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.835146] [ip-0A0C04AB:51808:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.835098] [ip-0A0C040F:46679:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.835986] [ip-0A0C04C7:1095 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.835572] [ip-0A0C044D:73805:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.835978] [ip-0A0C048A:73465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.836012] [ip-0A0C04C6:89834:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.838196] [ip-0A0C04B6:31221:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.838740] [ip-0A0C0429:67147:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.839467] [ip-0A0C0485:41762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.839399] [ip-0A0C04CC:97835:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.840840] [ip-0A0C042D:48061:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.840523] [ip-0A0C0489:76956:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.841904] [ip-0A0C046B:73785:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.841619] [ip-0A0C048F:65928:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.842208] [ip-0A0C04CD:94761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.841351] [ip-0A0C049B:50373:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.842742] [ip-0A0C046B:73784:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.842209] [ip-0A0C04CD:94758:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.841372] [ip-0A0C049B:50376:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.841581] [ip-0A0C0486:76740:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.843149] [ip-0A0C0492:56467:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.843417] [ip-0A0C04B2:37747:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.843605] [ip-0A0C0437:72895:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.843953] [ip-0A0C04B7:32523:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.843552] [ip-0A0C04B5:62274:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.843217] [ip-0A0C04D3:96374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.844318] [ip-0A0C04BD:91721:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.844698] [ip-0A0C04A1:79102:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.844476] [ip-0A0C0485:41767:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.845530] [ip-0A0C04BB:36638:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.845021] [ip-0A0C04CF:20157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.845777] [ip-0A0C048D:62500:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.846041] [ip-0A0C040F:46677:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.846833] [ip-0A0C04AC:55025:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.845915] [ip-0A0C04A6:61245:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.848009] [ip-0A0C045F:74331:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.848259] [ip-0A0C0483:75598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.848093] [ip-0A0C042D:48058:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.848002] [ip-0A0C0461:40258:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.847984] [ip-0A0C0461:40255:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.849593] [ip-0A0C04A1:79101:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.849506] [ip-0A0C048B:59357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.849663] [ip-0A0C0438:77441:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.850235] [ip-0A0C046E:78704:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.852140] [ip-0A0C04A1:79103:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.851885] [ip-0A0C0496:43021:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.851197] [ip-0A0C04C6:89833:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.851693] [ip-0A0C04A8:66705:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.852302] [ip-0A0C0497:11748:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.853603] [ip-0A0C04BD:91719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.853627] [ip-0A0C04BD:91720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.853104] [ip-0A0C04B9:94814:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.852932] [ip-0A0C049B:50372:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.854279] [ip-0A0C0438:77439:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.854730] [ip-0A0C04A7:38525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.854754] [ip-0A0C04C0:93517:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.855719] [ip-0A0C04C3:92939:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.856114] [ip-0A0C0497:11746:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.857500] [ip-0A0C04BE:94677:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.857970] [ip-0A0C04B0:48074:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.857031] [ip-0A0C049F:49330:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.858014] [ip-0A0C04B0:48081:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.858468] [ip-0A0C04BE:94678:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.858976] [ip-0A0C0466:79340:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.859071] [ip-0A0C047E:73161:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.859132] [ip-0A0C0487:76769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.859360] [ip-0A0C0494:58098:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.859771] [ip-0A0C04BE:94683:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.860230] [ip-0A0C04C9:96864:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.860916] [ip-0A0C0483:75601:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.861243] [ip-0A0C04D4:94116:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.861766] [ip-0A0C04C9:96865:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.861521] [ip-0A0C04A5:64229:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.861037] [ip-0A0C049B:50378:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.862537] [ip-0A0C0496:43018:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.862499] [ip-0A0C0499:62732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.862571] [ip-0A0C042D:48057:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.862747] [ip-0A0C0460:76382:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.862885] [ip-0A0C0460:76384:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.863111] [ip-0A0C04B5:62275:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.862853] [ip-0A0C044D:73807:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.862875] [ip-0A0C044D:73802:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.864318] [ip-0A0C04AD:38413:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.864531] [ip-0A0C04B4:71772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.865057] [ip-0A0C0473:74880:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.864400] [ip-0A0C0497:11750:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.867619] [ip-0A0C04BB:36627:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.867626] [ip-0A0C048B:59358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.868376] [ip-0A0C0488:75410:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.868357] [ip-0A0C04C7:1094 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.869473] [ip-0A0C04DB:90184:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.869479] [ip-0A0C04C4:93864:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.870053] [ip-0A0C04AA:36198:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.868712] [ip-0A0C0486:76734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.869202] [ip-0A0C0497:11749:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.870856] [ip-0A0C0461:40261:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.872502] [ip-0A0C04B5:62272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.873608] [ip-0A0C04D4:94119:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.872676] [ip-0A0C04D3:96378:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.873338] [ip-0A0C04C0:93521:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.873952] [ip-0A0C0499:62727:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.874170] [ip-0A0C04B5:62271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.875312] [ip-0A0C046B:73780:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.875467] [ip-0A0C046B:73779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.874914] [ip-0A0C0482:63913:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.876221] [ip-0A0C046B:73778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.876442] [ip-0A0C0473:74878:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.876727] [ip-0A0C04B7:32519:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.876644] [ip-0A0C0495:60660:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.876719] [ip-0A0C049D:67135:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.877229] [ip-0A0C04C8:97978:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.877186] [ip-0A0C0494:58095:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.876282] [ip-0A0C04C6:89835:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.877512] [ip-0A0C0487:76768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.877858] [ip-0A0C0473:74885:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.877708] [ip-0A0C04AE:66628:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.877880] [ip-0A0C0461:40259:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.877841] [ip-0A0C04C0:93520:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.877695] [ip-0A0C0489:76951:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.877434] [ip-0A0C04A8:66704:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.879533] [ip-0A0C04C8:97981:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.880531] [ip-0A0C04A2:53046:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.879802] [ip-0A0C0490:62667:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.881879] [ip-0A0C048B:59352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.881883] [ip-0A0C0473:74881:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.881149] [ip-0A0C04A8:66706:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.882192] [ip-0A0C04AB:51814:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.881992] [ip-0A0C04C0:93518:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.883453] [ip-0A0C04C4:93860:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.882826] [ip-0A0C04C6:89836:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.884385] [ip-0A0C0460:76380:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.883568] [ip-0A0C04A9:60674:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.884420] [ip-0A0C0489:76954:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.885001] [ip-0A0C04D9:17932:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.885091] [ip-0A0C04AD:38421:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.884368] [ip-0A0C0449:74232:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.885675] [ip-0A0C0436:77051:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.886282] [ip-0A0C04B7:32518:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.884919] [ip-0A0C0486:76739:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.885559] [ip-0A0C0486:76737:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.886279] [ip-0A0C04A6:61244:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.886448] [ip-0A0C04A6:61248:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.887587] [ip-0A0C0441:69552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.886867] [ip-0A0C04A6:61247:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.888279] [ip-0A0C04C4:93861:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.888501] [ip-0A0C046C:71922:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.888516] [ip-0A0C04C3:92940:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.889220] [ip-0A0C0495:60658:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.889230] [ip-0A0C0438:77437:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.889358] [ip-0A0C0438:77434:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.889996] [ip-0A0C04A7:38524:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.891675] [ip-0A0C04AD:38418:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.891942] [ip-0A0C04B7:32521:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.891607] [ip-0A0C046E:78699:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.892300] [ip-0A0C04A8:66712:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.892626] [ip-0A0C049F:49336:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.895465] [ip-0A0C04C8:97982:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.895578] [ip-0A0C04B2:37748:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.895630] [ip-0A0C04BC:89688:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.894923] [ip-0A0C04A8:66707:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.895923] [ip-0A0C04C8:97983:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.896120] [ip-0A0C04C7:1096 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.897015] [ip-0A0C0472:78758:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.897162] [ip-0A0C04D4:94122:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.897836] [ip-0A0C04C3:92952:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.898012] [ip-0A0C04D9:17934:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.897976] [ip-0A0C045F:74332:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.897827] [ip-0A0C04B4:71771:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.897950] [ip-0A0C0436:77052:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.898317] [ip-0A0C04C3:92941:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.897580] [ip-0A0C04D3:96376:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.899011] [ip-0A0C04BB:36633:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.899237] [ip-0A0C04BB:36631:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.899012] [ip-0A0C04AA:36200:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.900487] [ip-0A0C04BB:36626:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.900849] [ip-0A0C0490:62663:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.900661] [ip-0A0C048F:65922:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.902012] [ip-0A0C04D9:17939:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.902362] [ip-0A0C04AC:55023:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.903576] [ip-0A0C04C4:93866:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.903687] [ip-0A0C04DA:91576:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.904662] [ip-0A0C0491:58924:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.904029] [ip-0A0C0429:67146:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.904937] [ip-0A0C04D9:17933:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.904963] [ip-0A0C04C3:92942:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.905244] [ip-0A0C04B7:32525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.905879] [ip-0A0C04C4:93865:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.905235] [ip-0A0C04C6:89840:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.905464] [ip-0A0C048A:73464:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.907177] [ip-0A0C04C2:19237:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.907450] [ip-0A0C04CC:97833:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.908215] [ip-0A0C0484:78722:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.908290] [ip-0A0C048B:59353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.908869] [ip-0A0C04DB:90180:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.908897] [ip-0A0C0460:76386:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.909487] [ip-0A0C04AD:38414:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.909249] [ip-0A0C0494:58094:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.909921] [ip-0A0C048B:59354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.908605] [ip-0A0C04C6:89838:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.910339] [ip-0A0C046C:71926:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.910450] [ip-0A0C046C:71930:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.912337] [ip-0A0C04D4:94120:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.912691] [ip-0A0C04B3:69462:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.912043] [ip-0A0C0489:76955:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.912684] [ip-0A0C04B3:69463:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.912302] [ip-0A0C0489:76950:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.913329] [ip-0A0C04AD:38416:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.913431] [ip-0A0C04D3:96377:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.913457] [ip-0A0C04D3:96381:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.916009] [ip-0A0C0494:58100:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.917085] [ip-0A0C045F:74319:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.916346] [ip-0A0C04B9:94822:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.917548] [ip-0A0C04B1:64636:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.917468] [ip-0A0C04D4:94124:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.917632] [ip-0A0C045F:74323:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.917938] [ip-0A0C0491:58921:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.917547] [ip-0A0C0494:58099:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.917978] [ip-0A0C0495:60655:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.917976] [ip-0A0C04CC:97837:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.918023] [ip-0A0C04CF:20161:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.919714] [ip-0A0C0488:75405:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.918767] [ip-0A0C048C:57310:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.918908] [ip-0A0C04CF:20158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.920891] [ip-0A0C0441:69548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.921134] [ip-0A0C049D:67138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.922621] [ip-0A0C0492:56464:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.923128] [ip-0A0C046C:71927:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.924233] [ip-0A0C0484:78720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.923941] [ip-0A0C0436:77057:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.924761] [ip-0A0C046E:78703:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.925364] [ip-0A0C0441:69546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.925058] [ip-0A0C0429:67148:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.925746] [ip-0A0C049D:67134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.927606] [ip-0A0C040F:46692:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.928175] [ip-0A0C04AA:36203:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.928077] [ip-0A0C0438:77442:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.928395] [ip-0A0C0490:62668:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.928586] [ip-0A0C0460:76383:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.931177] [ip-0A0C0492:56465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.930960] [ip-0A0C0438:77440:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.932119] [ip-0A0C0441:69551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.932695] [ip-0A0C04A7:38551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.932661] [ip-0A0C04A5:64235:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.932348] [ip-0A0C049F:49331:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.933171] [ip-0A0C0436:77055:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.934465] [ip-0A0C0466:79336:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.933790] [ip-0A0C0493:57913:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.933897] [ip-0A0C0493:57914:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.934377] [ip-0A0C04A9:60675:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.935515] [ip-0A0C0494:58097:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.937384] [ip-0A0C04D8:97898:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.938818] [ip-0A0C049D:67136:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.939987] [ip-0A0C045F:74318:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.939834] [ip-0A0C049D:67133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.940262] [ip-0A0C04C2:19233:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.941249] [ip-0A0C04BA:28905:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.942212] [ip-0A0C04B1:64639:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.942083] [ip-0A0C0441:69549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.943979] [ip-0A0C04A2:53045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.942633] [ip-0A0C0493:57915:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.943621] [ip-0A0C0491:58928:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.943503] [ip-0A0C0436:77053:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.943891] [ip-0A0C04C2:19235:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.943973] [ip-0A0C0499:62733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.944304] [ip-0A0C04A7:38529:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.943660] [ip-0A0C04B9:94818:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.944035] [ip-0A0C0482:63919:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.944668] [ip-0A0C048D:62501:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.944768] [ip-0A0C048D:62499:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.944924] [ip-0A0C0443:39897:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.946215] [ip-0A0C045F:74321:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.946714] [ip-0A0C048C:57303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.948304] [ip-0A0C0499:62731:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.948499] [ip-0A0C04CC:97834:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.948634] [ip-0A0C0487:76771:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.948710] [ip-0A0C04CC:97831:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.948477] [ip-0A0C0493:57912:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.949421] [ip-0A0C0487:76770:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.949284] [ip-0A0C0443:39894:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.949431] [ip-0A0C0487:76765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.949530] [ip-0A0C0487:76764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.949619] [ip-0A0C04A4:61510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.949852] [ip-0A0C0436:77056:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.950769] [ip-0A0C0499:62729:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.950923] [ip-0A0C0499:62728:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.952500] [ip-0A0C04A2:53040:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.952626] [ip-0A0C04C9:96862:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.951527] [ip-0A0C04A9:60679:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.952716] [ip-0A0C04C9:96861:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.952137] [ip-0A0C0493:57916:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.952109] [ip-0A0C0449:74234:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.952479] [ip-0A0C04B6:31217:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.954432] [ip-0A0C0490:62664:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.954947] [ip-0A0C0460:76393:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.955429] [ip-0A0C04A7:38527:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.955946] [ip-0A0C0460:76381:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.956682] [ip-0A0C04BC:89681:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.957044] [ip-0A0C04A7:38526:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.957611] [ip-0A0C0488:75408:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.957309] [ip-0A0C0482:63915:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.958332] [ip-0A0C04A5:64231:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.960187] [ip-0A0C0472:78761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.960228] [ip-0A0C04DA:91574:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.961050] [ip-0A0C04AC:55024:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.960701] [ip-0A0C048F:65929:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.962212] [ip-0A0C0491:58926:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.962158] [ip-0A0C04BA:28903:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.962233] [ip-0A0C04DB:90179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.962181] [ip-0A0C04B6:31215:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.963814] [ip-0A0C0466:79339:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.963949] [ip-0A0C04DB:90183:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.964599] [ip-0A0C0466:79335:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.964515] [ip-0A0C048D:62502:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.963985] [ip-0A0C0482:63936:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.967073] [ip-0A0C04BA:28907:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.966976] [ip-0A0C0490:62662:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.967230] [ip-0A0C04AE:66625:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.968437] [ip-0A0C048D:62507:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.968704] [ip-0A0C04AE:66627:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.968066] [ip-0A0C04CF:20171:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.968807] [ip-0A0C04CD:94756:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.969447] [ip-0A0C04AA:36195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.969840] [ip-0A0C04CC:97836:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.970227] [ip-0A0C04D8:97897:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.970649] [ip-0A0C048A:73469:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.971948] [ip-0A0C0443:39889:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.971989] [ip-0A0C048D:62508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.971907] [ip-0A0C048C:57307:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.972988] [ip-0A0C0472:78755:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.973096] [ip-0A0C040F:46678:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.972785] [ip-0A0C0482:63916:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.973037] [ip-0A0C04A9:60676:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.974133] [ip-0A0C04CC:97830:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.973967] [ip-0A0C04C7:1097 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.975918] [ip-0A0C04A2:53042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.974883] [ip-0A0C04DA:91571:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.975508] [ip-0A0C0466:79338:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.975748] [ip-0A0C04B1:64643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.975946] [ip-0A0C0466:79341:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.976214] [ip-0A0C04C9:96866:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.976083] [ip-0A0C0491:58927:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.976325] [ip-0A0C0491:58923:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.976548] [ip-0A0C0484:78724:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.975459] [ip-0A0C0449:74235:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.975908] [ip-0A0C04CF:20163:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.976855] [ip-0A0C0443:39896:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.977463] [ip-0A0C04C9:96868:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.977964] [ip-0A0C04DB:90185:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.978292] [ip-0A0C04C9:96863:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.978498] [ip-0A0C0484:78721:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.977558] [ip-0A0C0449:74230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.979602] [ip-0A0C04BC:89687:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.979919] [ip-0A0C0488:75406:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.979349] [ip-0A0C0449:74233:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.979442] [ip-0A0C0449:74229:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.980861] [ip-0A0C04C2:19262:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.980895] [ip-0A0C04DB:90186:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.980816] [ip-0A0C04A4:61509:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.981154] [ip-0A0C04AE:66624:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.982009] [ip-0A0C0495:60656:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.981244] [ip-0A0C04CF:20160:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.982203] [ip-0A0C047E:73159:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.982967] [ip-0A0C04B4:71769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.982771] [ip-0A0C04AF:53121:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.984555] [ip-0A0C0484:78723:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.983154] [ip-0A0C04AF:53125:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.984782] [ip-0A0C047E:73156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.984767] [ip-0A0C0490:62666:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.985000] [ip-0A0C0429:67145:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.985981] [ip-0A0C0492:56466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.986056] [ip-0A0C04A9:60698:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.987594] [ip-0A0C04AE:66622:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.986724] [ip-0A0C04AF:53119:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.988150] [ip-0A0C04A5:64230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.988404] [ip-0A0C0472:78760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.987531] [ip-0A0C048A:73463:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.988244] [ip-0A0C0429:67149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.989601] [ip-0A0C04BC:89685:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.990229] [ip-0A0C04B2:37741:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.989405] [ip-0A0C048A:73466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.989895] [ip-0A0C04AF:53123:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.990404] [ip-0A0C048C:57308:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.991509] [ip-0A0C04D8:97896:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.991837] [ip-0A0C04D8:97900:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.992424] [ip-0A0C04D8:97893:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.992125] [ip-0A0C04DA:91572:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.992622] [ip-0A0C04BA:28906:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.992797] [ip-0A0C04B1:64637:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.992824] [ip-0A0C04B1:64638:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.992444] [ip-0A0C0490:62665:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.992037] [ip-0A0C048A:73468:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.992060] [ip-0A0C04A9:60678:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.993244] [ip-0A0C0495:60657:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.995474] [ip-0A0C0495:60662:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.995661] [ip-0A0C0488:75409:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.996767] [ip-0A0C04A2:53047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.996673] [ip-0A0C04B1:64640:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.997495] [ip-0A0C0472:78756:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.998295] [ip-0A0C04AC:55028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.998439] [ip-0A0C04AA:36202:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.998833] [ip-0A0C04A4:61507:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.999213] [ip-0A0C04BA:28900:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.999273] [ip-0A0C04A4:61511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626090.999464] [ip-0A0C040F:46700:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.000097] [ip-0A0C047E:73157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.000819] [ip-0A0C040F:46676:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.001275] [ip-0A0C04C2:19236:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.001107] [ip-0A0C04AF:53124:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.002224] [ip-0A0C04CD:94755:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.002288] [ip-0A0C04AE:66629:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.002581] [ip-0A0C0496:43017:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.003281] [ip-0A0C0429:67143:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.003109] [ip-0A0C04B9:94817:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.003792] [ip-0A0C04DA:91578:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.004351] [ip-0A0C04AA:36201:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.003994] [ip-0A0C04DA:91577:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.004748] [ip-0A0C04AB:51813:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.004906] [ip-0A0C04BC:89684:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.004475] [ip-0A0C049F:49337:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.006136] [ip-0A0C0488:75407:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.005700] [ip-0A0C0429:67142:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.007023] [ip-0A0C04BA:28901:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.007521] [ip-0A0C04BC:89686:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.007318] [ip-0A0C0443:39893:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.007773] [ip-0A0C04C7:1100 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.007944] [ip-0A0C0472:78754:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.008208] [ip-0A0C0496:43023:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.008170] [ip-0A0C04CD:94760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.008421] [ip-0A0C0443:39892:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.008486] [ip-0A0C040F:46675:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.009290] [ip-0A0C0495:60661:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.010175] [ip-0A0C04AA:36196:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.009221] [ip-0A0C04B6:31219:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.014598] [ip-0A0C04B2:37746:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.013797] [ip-0A0C04B9:94820:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.015144] [ip-0A0C046E:78700:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.014643] [ip-0A0C04B6:31218:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.014995] [ip-0A0C04B9:94821:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.016106] [ip-0A0C04C2:19234:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.016246] [ip-0A0C04C2:19238:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.019043] [ip-0A0C04A2:53043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.021254] [ip-0A0C04A2:53038:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.022800] [ip-0A0C04CD:94759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.023268] [ip-0A0C04B2:37743:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.023238] [ip-0A0C046E:78706:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.024835] [ip-0A0C04B4:71770:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.024939] [ip-0A0C04B4:71766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.027566] [ip-0A0C04C7:1101 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.027091] [ip-0A0C04B6:31220:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.028897] [ip-0A0C04A4:61513:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.029242] [ip-0A0C047E:73160:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.030171] [ip-0A0C04B2:37745:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.029944] [ip-0A0C04A4:61536:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.029655] [ip-0A0C04B6:31216:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.030577] [ip-0A0C04CD:94757:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.032756] [ip-0A0C04C7:1098 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.033937] [ip-0A0C04AB:51810:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.033793] [ip-0A0C04CD:94762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.034816] [ip-0A0C0492:56469:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.033902] [ip-0A0C049F:49333:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.034255] [ip-0A0C04B9:94816:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.035786] [ip-0A0C04C7:1099 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.035946] [ip-0A0C048F:65925:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.036735] [ip-0A0C049F:49334:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.038871] [ip-0A0C048F:65926:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.039845] [ip-0A0C04B2:37742:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.038968] [ip-0A0C048F:65923:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.040464] [ip-0A0C04AB:51815:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.042204] [ip-0A0C0496:43022:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.045092] [ip-0A0C047E:73162:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.045242] [ip-0A0C047E:73163:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.044999] [ip-0A0C048F:65927:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.047760] [ip-0A0C04B3:69461:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.048136] [ip-0A0C0496:43024:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.049329] [ip-0A0C0496:43019:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.050287] [ip-0A0C04AC:55027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.050165] [ip-0A0C046E:78705:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.050518] [ip-0A0C04A5:64234:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.052249] [ip-0A0C04AC:55026:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.052002] [ip-0A0C048F:65924:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.053578] [ip-0A0C0492:56468:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.053801] [ip-0A0C0492:56491:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.053800] [ip-0A0C0492:56470:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.053766] [ip-0A0C046E:78702:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.054321] [ip-0A0C049F:49332:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.056393] [ip-0A0C04B3:69466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.059166] [ip-0A0C0496:43020:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.060672] [ip-0A0C04A5:64233:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.062586] [ip-0A0C04AB:51811:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.064347] [ip-0A0C049F:49335:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.066367] [ip-0A0C046E:78701:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.069131] [ip-0A0C04A5:64236:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.069839] [ip-0A0C04AB:51812:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.071805] [ip-0A0C04B4:71767:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.071894] [ip-0A0C04B4:71765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.072587] [ip-0A0C04B4:71768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.073558] [ip-0A0C04AB:51809:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.073877] [ip-0A0C04AC:55022:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.074605] [ip-0A0C04A5:64232:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.075251] [ip-0A0C04B3:69464:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.075384] [ip-0A0C04AC:55029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.088303] [ip-0A0C048C:57305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.089661] [ip-0A0C048C:57309:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.091843] [ip-0A0C048C:57306:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.099633] [ip-0A0C04B3:69465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.102427] [ip-0A0C04B3:69467:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.109964] [ip-0A0C04B3:69468:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634626091.110840] [ip-0A0C048C:57304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
:::MLLOG {"namespace": "", "time_ms": 1634626092021, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634626092061, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634626092062, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1634626092062, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634626092062, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1634626092062, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1634626092062, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "96xND96amsr_A100_v4", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[06:48:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:48:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[ip-0A0C0435:0:19041 - context.c:584] INFO job (ID: 867564832543201881) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:19041 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:19041 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:19040 - context.c:584] INFO job (ID: 867564351913418667) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:19040 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:19040 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:19036 - context.c:584] INFO job (ID: 867565180723893034) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:19036 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:19036 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:19038 - context.c:584] INFO job (ID: 867565146466258095) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:19038 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:19038 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:19042 - context.c:584] INFO job (ID: 867564930322154449) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:19042 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:19042 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:19043 - context.c:584] INFO job (ID: 867564941459137837) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:19043 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:19043 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:19037 - context.c:584] INFO job (ID: 867564872181760597) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:19037 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:19037 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:19039 - context.c:584] INFO job (ID: 867564211374902230) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:19039 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:19039 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634626187225, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3384900642, "metadata": {"file": "main.py", "lineno": 72}}
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634626187226, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 138}}
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634626187226, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 139}}
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634626187226, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1500, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 140}}
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634626187226, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 142}}
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634626187226, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 143}}
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634626187226, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 144}}
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634626187226, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 145}}
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634626187226, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 146}}
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634626187226, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 147}}
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634626187226, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 148}}
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634626187226, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 149}}
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:49:48] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634626211353, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1634626211390, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626211394, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1634626211394, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 95}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634626213983, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 84, "metadata": {"file": "main.py", "lineno": 136}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634626213983, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 137}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634626213984, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634626213984, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1, "epoch_count": 20}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634626215535, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2166.5549439154534, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626215536, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.02989933774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626215536, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2166.5549439154534, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634626215536, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626215536, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626216207, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5007.789614624183, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626216208, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.04976556291390729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626216208, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5007.789614624183, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626216208, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626216208, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626216864, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5120.011160738614, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626216865, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0696317880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626216865, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5120.011160738614, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634626216865, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626216865, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626217498, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5311.302538807224, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626217499, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.08949801324503312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626217499, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5311.302538807224, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 60}}
:::MLLOG {"namespace": "", "time_ms": 1634626217499, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626217499, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626218131, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5318.7051865527865, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626218131, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.10936423841059603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626218132, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5318.7051865527865, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 80}}
:::MLLOG {"namespace": "", "time_ms": 1634626218132, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626218132, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626218761, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5342.092272445215, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626218761, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.12923046357615892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626218761, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5342.092272445215, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 100}}
:::MLLOG {"namespace": "", "time_ms": 1634626218761, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626218761, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626219388, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5360.457079216338, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626219389, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.14909668874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626219389, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5360.457079216338, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634626219389, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626219389, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626220012, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5395.307471998144, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626220012, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.16896291390728477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626220012, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5395.307471998144, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1634626220013, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626220013, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626220633, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5416.314917245981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626220634, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.18882913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626220634, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5416.314917245981, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 160}}
:::MLLOG {"namespace": "", "time_ms": 1634626220634, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626220634, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626221244, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5511.71556718078, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626221244, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.20869536423841056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626221244, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5511.71556718078, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 180}}
:::MLLOG {"namespace": "", "time_ms": 1634626221244, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626221244, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626221870, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5371.293479491275, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626221870, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.22856158940397348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626221870, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5371.293479491275, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 200}}
:::MLLOG {"namespace": "", "time_ms": 1634626221871, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626221871, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626222483, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5488.306105075243, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626222483, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.24842781456953641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626222483, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5488.306105075243, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 220}}
:::MLLOG {"namespace": "", "time_ms": 1634626222484, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626222484, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626223097, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5478.391740153823, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626223098, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26829403973509935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626223098, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5478.391740153823, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 240}}
:::MLLOG {"namespace": "", "time_ms": 1634626223098, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626223098, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626223715, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5447.021729551727, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626223715, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.28816026490066227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626223715, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5447.021729551727, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 260}}
:::MLLOG {"namespace": "", "time_ms": 1634626223716, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626223716, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626224329, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5478.48118665699, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626224329, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3080264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626224330, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5478.48118665699, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1634626224330, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626224330, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626224945, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5467.329327100266, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626224945, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32789271523178803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626224945, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5467.329327100266, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 300}}
:::MLLOG {"namespace": "", "time_ms": 1634626224945, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626224945, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626225564, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5435.909384933515, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626225564, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.347758940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626225564, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5435.909384933515, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 320}}
:::MLLOG {"namespace": "", "time_ms": 1634626225564, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626225564, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626226184, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5417.839117083065, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626226185, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36762516556291386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626226185, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5417.839117083065, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 340}}
:::MLLOG {"namespace": "", "time_ms": 1634626226185, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626226185, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626226809, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5390.571223330888, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626226809, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3874913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626226809, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5390.571223330888, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 360}}
:::MLLOG {"namespace": "", "time_ms": 1634626226810, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626226810, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626227431, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5409.292205982713, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626227432, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.40735761589403974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626227432, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5409.292205982713, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 380}}
:::MLLOG {"namespace": "", "time_ms": 1634626227432, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626227432, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626228052, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5421.042313626518, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626228052, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626228053, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5421.042313626518, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 400}}
:::MLLOG {"namespace": "", "time_ms": 1634626228053, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626228053, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626228670, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5444.631130630707, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626228670, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.44709006622516556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626228671, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5444.631130630707, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1634626228671, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626228671, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626229289, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5441.477742735616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626229289, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4669562913907285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626229289, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5441.477742735616, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 440}}
:::MLLOG {"namespace": "", "time_ms": 1634626229289, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626229289, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626229910, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5412.188061654925, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626229911, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4868225165562914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626229911, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5412.188061654925, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 460}}
:::MLLOG {"namespace": "", "time_ms": 1634626229911, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626229911, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626230529, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5439.747035573123, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626230530, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5066887417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626230530, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5439.747035573123, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 480}}
:::MLLOG {"namespace": "", "time_ms": 1634626230530, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626230530, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626231146, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5455.331470871387, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626231147, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5265549668874172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626231147, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5455.331470871387, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 500}}
:::MLLOG {"namespace": "", "time_ms": 1634626231147, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626231147, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626231764, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5444.700546252593, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626231765, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5464211920529801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626231765, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5444.700546252593, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 520}}
:::MLLOG {"namespace": "", "time_ms": 1634626231765, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626231765, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626232376, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5501.145262812744, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626232376, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.566287417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626232376, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5501.145262812744, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 540}}
:::MLLOG {"namespace": "", "time_ms": 1634626232376, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626232377, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626232989, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5487.333779031895, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626232989, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5861536423841059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626232989, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5487.333779031895, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1634626232990, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626232990, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626233604, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5472.675358001065, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626233604, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6060198675496689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626233604, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5472.675358001065, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634626233604, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626233604, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626234214, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5513.2119812315, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626234214, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6258860927152318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626234214, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5513.2119812315, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 600}}
:::MLLOG {"namespace": "", "time_ms": 1634626234214, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626234214, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626234839, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5382.4060619022885, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626234839, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6457523178807947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626234839, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5382.4060619022885, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 620}}
:::MLLOG {"namespace": "", "time_ms": 1634626234839, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626234839, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626235454, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5465.522788037395, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626235455, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6656185430463576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626235455, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5465.522788037395, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 640}}
:::MLLOG {"namespace": "", "time_ms": 1634626235455, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626235455, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626236065, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5503.774901086902, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626236066, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6854847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626236066, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5503.774901086902, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 660}}
:::MLLOG {"namespace": "", "time_ms": 1634626236066, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626236066, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626236685, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5432.6676576348755, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626236685, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7053509933774835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626236685, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5432.6676576348755, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 680}}
:::MLLOG {"namespace": "", "time_ms": 1634626236685, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626236685, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626237304, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5429.743574727422, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626237304, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7252172185430463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626237305, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5429.743574727422, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 700}}
:::MLLOG {"namespace": "", "time_ms": 1634626237305, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626237305, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626237918, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5483.898139277518, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626237918, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7450834437086092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626237918, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5483.898139277518, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 720}}
:::MLLOG {"namespace": "", "time_ms": 1634626237918, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626237918, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626238533, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5470.194247564336, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626238533, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7649496688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626238533, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5470.194247564336, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 740}}
:::MLLOG {"namespace": "", "time_ms": 1634626238533, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626238533, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626239141, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5528.951834913675, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626239141, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7848158940397352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626239141, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5528.951834913675, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 760}}
:::MLLOG {"namespace": "", "time_ms": 1634626239141, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626239142, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626239753, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5493.733947539841, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626239754, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8046821192052981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626239754, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5493.733947539841, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634626239754, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626239754, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626240365, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5495.087765130941, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626240366, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8245483443708609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626240366, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5495.087765130941, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 800}}
:::MLLOG {"namespace": "", "time_ms": 1634626240366, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626240366, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626240977, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5500.608472495712, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626240977, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626240977, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5500.608472495712, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 820}}
:::MLLOG {"namespace": "", "time_ms": 1634626240978, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626240978, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626241590, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5486.180256641933, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626241591, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8642807947019867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626241591, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5486.180256641933, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 840}}
:::MLLOG {"namespace": "", "time_ms": 1634626241591, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626241591, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626242198, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5536.395465870279, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626242198, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8841470198675497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626242198, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5536.395465870279, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 860}}
:::MLLOG {"namespace": "", "time_ms": 1634626242198, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626242199, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626242812, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5481.771439040414, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626242812, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9040132450331126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626242812, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5481.771439040414, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 880}}
:::MLLOG {"namespace": "", "time_ms": 1634626242812, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626242812, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626243441, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5341.814862770902, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626243442, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9238794701986754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626243442, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5341.814862770902, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 900}}
:::MLLOG {"namespace": "", "time_ms": 1634626243442, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626243442, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626244047, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5557.455115606298, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626244047, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9437456953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626244047, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5557.455115606298, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 920}}
:::MLLOG {"namespace": "", "time_ms": 1634626244047, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626244047, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626244655, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5525.75204566191, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626244656, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9636119205298014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626244656, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5525.75204566191, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 940}}
:::MLLOG {"namespace": "", "time_ms": 1634626244656, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626244656, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626245268, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5491.713031499822, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626245268, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9834781456953643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626245268, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5491.713031499822, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 960}}
:::MLLOG {"namespace": "", "time_ms": 1634626245268, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626245268, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626245890, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5405.910018504482, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626245890, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0033443708609273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626245891, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5405.910018504482, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 980}}
:::MLLOG {"namespace": "", "time_ms": 1634626245964, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626245965, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626245981, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634626246408, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.872409999370575, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634626246409, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634626246570, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5548.420887275751, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626246571, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0232105960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626246571, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5548.420887275751, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634626246708, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626246709, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626246715, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634626247122, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8862153887748718, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634626247122, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634626247331, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5397.057550286993, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626247332, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.043076821192053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626247332, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5397.057550286993, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634626247412, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626247412, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626247428, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634626247870, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.895526111125946, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634626247871, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634626248084, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4999.124334087956, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626248085, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.062943046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626248085, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4999.124334087956, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634626248143, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626248143, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626248159, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634626248562, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.887607991695404, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634626248562, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634626248743, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5608.346836663102, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626248743, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0828092715231787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626248743, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5608.346836663102, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634626248798, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626248798, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626248813, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634626249248, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8773912191390991, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634626249249, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634626249440, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5235.2588809519475, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626249440, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1026754966887418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626249440, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5235.2588809519475, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634626249520, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626249521, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626249536, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634626249968, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8643921613693237, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634626249968, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634626250178, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5111.626440277387, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626250178, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1225417218543046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626250178, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5111.626440277387, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634626250226, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626250226, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626250242, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634626250659, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8125845789909363, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634626250659, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634626250848, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5400.68115242234, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626250849, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1424079470198676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626250849, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5400.68115242234, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634626250905, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626250906, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626250920, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634626251361, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8879827857017517, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634626251361, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634626251556, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5164.698606290931, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626251557, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1622741721854304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626251557, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5164.698606290931, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634626251650, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626251650, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626251665, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634626252064, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8716974258422852, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634626252064, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634626252283, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5311.967192352923, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626252283, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1821403973509934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626252283, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5311.967192352923, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634626252319, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626252319, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626252335, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634626252759, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8917515277862549, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634626252759, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634626252944, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5380.195067870608, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626252944, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2020066225165562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626252944, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5380.195067870608, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634626253050, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626253051, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626253065, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634626253477, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8904949426651001, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634626253477, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634626253680, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5339.098985511968, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626253681, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2218728476821192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626253681, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5339.098985511968, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634626253751, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626253751, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626253766, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634626254179, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8923872709274292, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634626254179, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634626254372, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5410.98904238029, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626254373, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.241739072847682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626254373, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5410.98904238029, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634626254457, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626254458, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626254473, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634626254871, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8900886178016663, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634626254871, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634626255065, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5534.979916697595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626255065, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626255065, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5534.979916697595, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634626255143, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626255143, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626255158, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634626255595, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8961116075515747, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634626255595, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634626255812, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5024.988425975448, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626255813, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.281471523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626255813, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5024.988425975448, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634626255862, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626255863, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626255878, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634626256297, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.88839191198349, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634626256297, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634626256489, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5365.563366848922, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626256489, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3013377483443709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626256489, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5365.563366848922, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634626256587, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626256587, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626256602, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634626257020, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8921644687652588, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634626257020, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634626257224, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5279.241561858725, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626257224, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3212039735099337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626257224, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5279.241561858725, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634626257276, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626257277, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626257292, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634626257741, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8956490159034729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634626257741, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634626257940, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5063.413269197811, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626257941, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3410701986754967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626257941, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5063.413269197811, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634626257989, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626257990, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626258005, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634626258452, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8632597923278809, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634626258452, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634626258647, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5109.384036362437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626258648, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3609364238410595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626258648, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5109.384036362437, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634626258721, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626258721, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626258736, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634626259150, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8802371025085449, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634626259150, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634626259343, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5405.041292804393, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626259343, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3808026490066225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626259343, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5405.041292804393, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634626259393, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626259393, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626259410, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634626259821, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8747333288192749, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634626259821, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634626260009, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5462.268943325641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626260009, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4006688741721853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626260009, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5462.268943325641, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634626260052, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626260052, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626260068, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634626260536, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8969447016716003, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634626260537, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634626260746, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4844.99888611717, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626260746, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4205350993377484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626260746, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4844.99888611717, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634626260815, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626260816, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626260830, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634626261243, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8841534852981567, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634626261243, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634626261443, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5353.920063094287, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626261444, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4404013245033112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626261444, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5353.920063094287, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634626261498, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626261499, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626261514, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634626261982, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.900381863117218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634626261982, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634626262197, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4811.610746320838, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626262197, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4602675496688742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626262198, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4811.610746320838, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634626262259, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626262259, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626262274, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634626262709, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.891287088394165, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634626262710, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634626262914, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5128.632461618579, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626262915, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4801337748344372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626262915, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5128.632461618579, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634626262983, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626262984, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626262998, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634626263453, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8786324858665466, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634626263453, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634626263667, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4920.654045255239, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626263667, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626263667, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4920.654045255239, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634626263748, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626263748, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626263763, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634626264178, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7550933361053467, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634626264178, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634626264370, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5405.984671448848, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626264371, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626264371, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5405.984671448848, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634626264459, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626264459, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626264474, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634626264881, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8963257074356079, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634626264881, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634626265088, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5344.03292074956, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626265088, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626265088, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5344.03292074956, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634626265158, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626265159, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626265174, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634626265579, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8929821252822876, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634626265579, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634626265794, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5285.9581995233475, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626265795, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626265795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5285.9581995233475, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634626265900, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626265900, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626265915, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634626266314, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8859089612960815, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634626266314, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634626266545, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5215.4677498623305, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626266545, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626266545, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5215.4677498623305, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634626266603, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626266603, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626266618, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634626267050, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8522379398345947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634626267050, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634626267275, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5002.268645018944, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626267275, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626267275, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5002.268645018944, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634626267312, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626267312, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626267327, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634626267750, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8896915912628174, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634626267751, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634626267941, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5338.330460791125, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626267942, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626267942, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5338.330460791125, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634626268007, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626268007, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626268023, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634626268440, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8875460028648376, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634626268441, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634626268639, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5321.231571566605, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626268640, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626268640, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5321.231571566605, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634626268687, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626268687, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626268702, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634626269146, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8923636674880981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634626269146, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634626269351, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5059.236127889039, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626269352, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626269352, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5059.236127889039, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634626269388, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626269388, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626269403, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634626269827, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.874912440776825, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634626269827, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634626270018, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5334.89099195954, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626270018, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626270019, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5334.89099195954, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634626270079, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626270079, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626270095, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634626270506, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8843944072723389, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634626270506, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634626270693, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5470.99483951966, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626270694, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626270694, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5470.99483951966, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634626270750, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626270750, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626270765, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634626271186, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8842307329177856, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634626271186, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634626271384, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5304.868813027227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626271384, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626271384, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5304.868813027227, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634626271436, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626271436, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626271451, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634626271867, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8952120542526245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634626271867, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634626272058, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5400.929522407965, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626272059, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626272059, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5400.929522407965, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634626272136, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626272136, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626272151, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634626272550, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8952907919883728, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634626272550, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634626272737, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5595.465075743799, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626272737, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626272738, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5595.465075743799, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634626272820, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626272821, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626272836, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634626273245, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.892963171005249, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634626273245, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634626273434, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5482.249109655785, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626273434, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626273434, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5482.249109655785, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634626273486, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626273486, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626273501, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634626273926, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8925416469573975, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634626273926, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634626274117, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5323.517023485202, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626274118, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626274118, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5323.517023485202, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634626274153, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626274153, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626274169, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634626274589, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9043279886245728, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634626274589, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634626274769, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5450.664269738015, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626274770, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626274770, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5450.664269738015, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634626274834, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626274834, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626274849, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634626275251, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8960973620414734, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634626275251, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634626275440, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5549.1658804647595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626275440, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626275440, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5549.1658804647595, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634626275533, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626275533, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626275548, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634626275950, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8880168199539185, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634626275950, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634626276147, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5474.18041472578, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626276148, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626276148, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5474.18041472578, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634626276212, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626276212, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626276227, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634626276633, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8787939548492432, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634626276633, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634626276837, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5380.277228448519, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626276837, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626276837, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5380.277228448519, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634626276929, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626276929, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626276944, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634626277343, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8970061540603638, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634626277343, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634626277544, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5464.850941458086, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626277544, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626277544, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5464.850941458086, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634626277605, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626277606, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626277621, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634626278071, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8881140947341919, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634626278071, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634626278283, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4961.8313855028455, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626278283, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626278284, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4961.8313855028455, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634626278377, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626278378, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626278392, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634626278792, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8983228206634521, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634626278792, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634626278991, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5480.526474823669, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626278991, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626278991, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5480.526474823669, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634626279028, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626279028, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626279044, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634626279466, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8869444131851196, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634626279467, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634626279644, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5454.909152980876, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626279644, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626279644, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5454.909152980876, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634626279723, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626279723, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626279738, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634626280161, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8917768001556396, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634626280161, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634626280353, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5334.49923045884, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626280354, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626280354, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5334.49923045884, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634626280412, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626280412, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626280427, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634626280861, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8989869356155396, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634626280861, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634626281051, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5259.631378060855, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626281051, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626281052, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5259.631378060855, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634626281129, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626281129, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626281144, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634626281543, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9010536074638367, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634626281543, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634626281736, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5533.5238091498595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626281737, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626281737, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5533.5238091498595, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634626281774, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626281775, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626281791, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634626282210, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8988279104232788, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634626282210, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634626282403, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5344.525397079425, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626282404, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626282404, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5344.525397079425, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634626282482, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626282483, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626282498, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634626282900, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8945574760437012, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634626282901, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634626283090, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5537.339567632983, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626283090, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626283090, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5537.339567632983, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634626283161, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626283161, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626283177, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634626283600, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8936689496040344, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634626283601, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634626283794, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5314.214632579137, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626283794, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626283794, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5314.214632579137, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634626283865, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626283866, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626283880, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634626284285, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9005038738250732, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634626284285, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634626284474, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5524.794563671012, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626284474, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626284475, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5524.794563671012, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634626284537, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626284537, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626284552, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634626284955, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9031118154525757, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634626284955, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634626285137, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5602.9709356691665, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626285137, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626285137, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5602.9709356691665, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634626285202, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626285202, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626285218, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634626285631, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8913044929504395, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634626285631, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634626285825, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5395.173215360373, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626285825, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626285825, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5395.173215360373, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634626285870, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626285870, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626285887, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634626286298, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8986634016036987, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634626286298, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634626286477, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5541.047300870464, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626286477, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626286477, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5541.047300870464, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634626286516, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626286516, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626286532, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634626286951, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8984453678131104, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634626286951, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634626287135, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5426.005672855575, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626287136, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626287136, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5426.005672855575, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634626287192, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626287192, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626287208, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634626287618, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8875157833099365, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634626287619, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634626287805, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5487.908585100218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626287805, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626287805, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5487.908585100218, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634626287855, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626287855, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626287870, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634626288282, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9082309007644653, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634626288282, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634626288282, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 165, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1634626288462, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5538.453760746506, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626288462, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626288462, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5538.453760746506, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2200}}
ENDING TIMING RUN AT 2021-10-19 06:51:34 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:34 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:34 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:34 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:34 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:34 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:34 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:34 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:34 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:34 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:35 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:35 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:35 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:35 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:35 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:36 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:36 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:37 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:38 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:39 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:39 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:39 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:40 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:41 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:42 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:42 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:42 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:42 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:42 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:42 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:42 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:42 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:42 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:42 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:42 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:42 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:43 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:44 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:45 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:46 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:47 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:48 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:48 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:48 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:48:05 AM
ENDING TIMING RUN AT 2021-10-19 06:51:48 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:48:05 AM
