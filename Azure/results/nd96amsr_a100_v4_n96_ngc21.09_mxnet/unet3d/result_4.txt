+ : DGXA100_96x8x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019052736325394360
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data
+ : /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ LOGBASE=unet3d_96x8x1_211019052736325394360
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019052736325394360
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019052736325394360
+ readonly _cont_name=image_segmentation
+ _cont_name=image_segmentation
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07358/slurm_script: line 39: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ srun --ntasks=96 mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ srun --ntasks=96 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh --container-name=image_segmentation true
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019052736325394360_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=96 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C0416
Clearing cache on ip-0A0C040C
Clearing cache on ip-0A0C0424
Clearing cache on ip-0A0C0440
Clearing cache on ip-0A0C0421
Clearing cache on ip-0A0C0412
Clearing cache on ip-0A0C0408
Clearing cache on ip-0A0C040B
Clearing cache on ip-0A0C0409
Clearing cache on ip-0A0C0413
Clearing cache on ip-0A0C0426
Clearing cache on ip-0A0C0428
Clearing cache on ip-0A0C0418
Clearing cache on ip-0A0C0411
Clearing cache on ip-0A0C041F
Clearing cache on ip-0A0C041D
Clearing cache on ip-0A0C0433
Clearing cache on ip-0A0C040A
Clearing cache on ip-0A0C0423
Clearing cache on ip-0A0C041B
Clearing cache on ip-0A0C0417
Clearing cache on ip-0A0C041E
Clearing cache on ip-0A0C0407
Clearing cache on ip-0A0C0425
Clearing cache on ip-0A0C0420
Clearing cache on ip-0A0C041A
Clearing cache on ip-0A0C041C
Clearing cache on ip-0A0C040E
Clearing cache on ip-0A0C042E
Clearing cache on ip-0A0C042A
Clearing cache on ip-0A0C0452
Clearing cache on ip-0A0C0419
Clearing cache on ip-0A0C0410
Clearing cache on ip-0A0C0439
Clearing cache on ip-0A0C0518
Clearing cache on ip-0A0C045D
Clearing cache on ip-0A0C044A
Clearing cache on ip-0A0C043D
Clearing cache on ip-0A0C0480
Clearing cache on ip-0A0C043B
Clearing cache on ip-0A0C0455
Clearing cache on ip-0A0C0422
Clearing cache on ip-0A0C0453
Clearing cache on ip-0A0C0445
Clearing cache on ip-0A0C0457
Clearing cache on ip-0A0C044E
Clearing cache on ip-0A0C0442
Clearing cache on ip-0A0C045E
Clearing cache on ip-0A0C0446
Clearing cache on ip-0A0C043C
Clearing cache on ip-0A0C0414
Clearing cache on ip-0A0C044B
Clearing cache on ip-0A0C0427
Clearing cache on ip-0A0C047A
Clearing cache on ip-0A0C043A
Clearing cache on ip-0A0C043F
Clearing cache on ip-0A0C0458
Clearing cache on ip-0A0C0448
Clearing cache on ip-0A0C0434
Clearing cache on ip-0A0C0471
Clearing cache on ip-0A0C0430
Clearing cache on ip-0A0C0431
Clearing cache on ip-0A0C0465
Clearing cache on ip-0A0C0432
Clearing cache on ip-0A0C047F
Clearing cache on ip-0A0C0481
Clearing cache on ip-0A0C0475
Clearing cache on ip-0A0C045A
Clearing cache on ip-0A0C043E
Clearing cache on ip-0A0C0456
Clearing cache on ip-0A0C0477
Clearing cache on ip-0A0C0450
Clearing cache on ip-0A0C046D
Clearing cache on ip-0A0C042C
Clearing cache on ip-0A0C045B
Clearing cache on ip-0A0C0474
Clearing cache on ip-0A0C042F
Clearing cache on ip-0A0C0447
Clearing cache on ip-0A0C0463
Clearing cache on ip-0A0C044F
Clearing cache on ip-0A0C047B
Clearing cache on ip-0A0C044C
Clearing cache on ip-0A0C0470
Clearing cache on ip-0A0C0459
Clearing cache on ip-0A0C0451
Clearing cache on ip-0A0C046A
Clearing cache on ip-0A0C0467
Clearing cache on ip-0A0C0476
Clearing cache on ip-0A0C042B
Clearing cache on ip-0A0C0462
Clearing cache on ip-0A0C047C
Clearing cache on ip-0A0C047D
Clearing cache on ip-0A0C0479
Clearing cache on ip-0A0C0454
Clearing cache on ip-0A0C0469
Clearing cache on ip-0A0C045C
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=768 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:27:38 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
[1634621263.709464] [ip-0A0C0410:63450:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.713641] [ip-0A0C040E:34768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.745018] [ip-0A0C040B:90449:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.757857] [ip-0A0C040B:90457:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.764589] [ip-0A0C046A:21939:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.771815] [ip-0A0C0481:8197 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.773249] [ip-0A0C040C:59128:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.775059] [ip-0A0C040A:48406:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.777969] [ip-0A0C040E:34771:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.778982] [ip-0A0C046A:21937:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.780603] [ip-0A0C040C:59124:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.781741] [ip-0A0C041E:46587:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.784933] [ip-0A0C0433:40761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.797398] [ip-0A0C0410:63452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.797510] [ip-0A0C0410:63446:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.800624] [ip-0A0C0428:35730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.804552] [ip-0A0C0428:35732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.804841] [ip-0A0C041F:50529:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.808771] [ip-0A0C040A:48410:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.809325] [ip-0A0C045C:27764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.811572] [ip-0A0C0456:34471:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.811458] [ip-0A0C0481:8195 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.812583] [ip-0A0C040E:34773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.812985] [ip-0A0C0465:18900:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.815405] [ip-0A0C044E:23862:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.817713] [ip-0A0C0419:50506:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.821011] [ip-0A0C0417:77407:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.828335] [ip-0A0C041E:46582:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.831446] [ip-0A0C040B:90454:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.833981] [ip-0A0C0476:7316 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.839842] [ip-0A0C0456:34473:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.840988] [ip-0A0C0433:40762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.842265] [ip-0A0C0413:78704:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.846852] [ip-0A0C045C:27759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.849558] [ip-0A0C043A:32181:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.853398] [ip-0A0C0481:8198 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.854694] [ip-0A0C0410:63451:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.854684] [ip-0A0C043C:32944:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.855557] [ip-0A0C040A:48408:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.856350] [ip-0A0C0446:34761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.859592] [ip-0A0C041E:46586:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.862247] [ip-0A0C0457:27271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.864756] [ip-0A0C0457:27267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.865569] [ip-0A0C0410:63448:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.868287] [ip-0A0C0408:70970:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.873612] [ip-0A0C0427:43622:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.874085] [ip-0A0C0477:14859:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.878100] [ip-0A0C047B:16694:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.882632] [ip-0A0C0440:26275:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.883294] [ip-0A0C040E:34769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.883294] [ip-0A0C0410:63449:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.883832] [ip-0A0C0476:7311 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.887352] [ip-0A0C043B:31673:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.889153] [ip-0A0C0412:26273:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.889919] [ip-0A0C0453:32504:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.890018] [ip-0A0C040E:34770:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.890956] [ip-0A0C0428:35729:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.891102] [ip-0A0C0481:8196 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.893732] [ip-0A0C0410:63445:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.896810] [ip-0A0C044C:29094:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.897400] [ip-0A0C0428:35731:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.896902] [ip-0A0C0442:26731:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.897602] [ip-0A0C040A:48413:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.898144] [ip-0A0C0425:50066:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.899267] [ip-0A0C0418:43311:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.900345] [ip-0A0C040B:90450:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.900326] [ip-0A0C0409:7076 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.900936] [ip-0A0C041C:52580:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.901817] [ip-0A0C045E:28218:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.902544] [ip-0A0C045D:18415:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.902857] [ip-0A0C041F:50535:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.902587] [ip-0A0C046A:21938:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.902882] [ip-0A0C0410:63447:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.903573] [ip-0A0C041F:50534:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.906729] [ip-0A0C0442:26734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.906833] [ip-0A0C0422:68394:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.908384] [ip-0A0C0422:68399:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.909477] [ip-0A0C0408:70969:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.910380] [ip-0A0C0413:78703:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.910965] [ip-0A0C041F:50533:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.910706] [ip-0A0C046A:21940:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.911222] [ip-0A0C0470:12034:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.911727] [ip-0A0C0409:7072 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.913933] [ip-0A0C0423:40771:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.914102] [ip-0A0C047F:13333:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.915801] [ip-0A0C040E:34766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.915885] [ip-0A0C040E:34767:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.916377] [ip-0A0C0418:43307:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.916269] [ip-0A0C0425:50072:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.916623] [ip-0A0C041B:64859:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.917408] [ip-0A0C0440:26276:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.917177] [ip-0A0C047C:20022:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.917167] [ip-0A0C047C:20018:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.918488] [ip-0A0C040C:59121:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.918678] [ip-0A0C040C:59123:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.918857] [ip-0A0C044F:24878:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.920112] [ip-0A0C040B:90456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.920694] [ip-0A0C040E:34772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.920351] [ip-0A0C045C:27761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.921218] [ip-0A0C0408:70967:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.923309] [ip-0A0C040B:90451:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.924196] [ip-0A0C0446:34763:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.924125] [ip-0A0C041A:70160:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.924268] [ip-0A0C042F:41885:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.924535] [ip-0A0C044E:23859:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.924934] [ip-0A0C0462:58183:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.925194] [ip-0A0C040A:48411:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.926475] [ip-0A0C040A:48407:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.927057] [ip-0A0C0518:45417:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.927144] [ip-0A0C0411:46381:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.927052] [ip-0A0C0518:45392:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.927997] [ip-0A0C044E:23871:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.929539] [ip-0A0C0456:34474:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.931040] [ip-0A0C0433:40765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.931383] [ip-0A0C0417:77404:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.932001] [ip-0A0C0413:78705:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.931853] [ip-0A0C044E:23860:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.932224] [ip-0A0C0467:17028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.932914] [ip-0A0C041A:70155:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.934079] [ip-0A0C045E:28217:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.934003] [ip-0A0C044C:29092:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.934492] [ip-0A0C044C:29097:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.935010] [ip-0A0C041E:46588:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.935111] [ip-0A0C0455:25934:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.935307] [ip-0A0C0465:18904:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.935582] [ip-0A0C0426:45272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.936971] [ip-0A0C0474:13090:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.937006] [ip-0A0C040B:90455:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.936889] [ip-0A0C0481:8201 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.937141] [ip-0A0C047B:16693:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.937104] [ip-0A0C040B:90453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.937657] [ip-0A0C046A:21941:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.939453] [ip-0A0C0433:40763:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.940144] [ip-0A0C0470:12032:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.940154] [ip-0A0C040C:59125:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.940622] [ip-0A0C044F:24881:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.940277] [ip-0A0C045C:27762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.941054] [ip-0A0C043A:32178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.941740] [ip-0A0C0411:46378:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.942619] [ip-0A0C0471:16288:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.944578] [ip-0A0C0426:45275:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.944201] [ip-0A0C0477:14854:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.944460] [ip-0A0C0476:7317 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.944249] [ip-0A0C042F:41886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.945324] [ip-0A0C045B:34775:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.946041] [ip-0A0C0459:27246:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.946965] [ip-0A0C0455:25937:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.946748] [ip-0A0C040A:48409:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.947512] [ip-0A0C044F:24877:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.948037] [ip-0A0C0453:32503:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.948741] [ip-0A0C0481:8200 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.951297] [ip-0A0C0423:40770:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.955260] [ip-0A0C0412:26270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.955301] [ip-0A0C043A:32173:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.956538] [ip-0A0C043C:32942:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.956818] [ip-0A0C041F:50530:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.957771] [ip-0A0C0474:13091:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.959061] [ip-0A0C040A:48412:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.960276] [ip-0A0C0465:18907:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.961686] [ip-0A0C041C:52574:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.962068] [ip-0A0C0413:78708:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.962249] [ip-0A0C0480:9289 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.963088] [ip-0A0C0448:38550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.963936] [ip-0A0C0456:34484:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.963313] [ip-0A0C045C:27765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.965003] [ip-0A0C0476:7313 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.965582] [ip-0A0C0412:26274:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.965889] [ip-0A0C041D:43601:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.966504] [ip-0A0C046A:21934:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.967375] [ip-0A0C0417:77409:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.967981] [ip-0A0C041E:46583:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.968138] [ip-0A0C0459:27225:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.968121] [ip-0A0C046A:21935:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.968883] [ip-0A0C041C:52577:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.969269] [ip-0A0C0445:37400:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.969578] [ip-0A0C040C:59143:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.970098] [ip-0A0C0467:17026:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.970469] [ip-0A0C040C:59126:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.970586] [ip-0A0C0445:37402:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.970659] [ip-0A0C042E:45851:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.971876] [ip-0A0C0481:8194 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.972163] [ip-0A0C0451:29347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.971759] [ip-0A0C040C:59122:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.972430] [ip-0A0C0433:40760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.972721] [ip-0A0C0454:31411:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.973402] [ip-0A0C045E:28219:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.973027] [ip-0A0C0462:58184:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.973443] [ip-0A0C042B:44608:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.974479] [ip-0A0C0433:40778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.974777] [ip-0A0C0481:8193 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.974953] [ip-0A0C044B:30347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.975545] [ip-0A0C046A:21936:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.976607] [ip-0A0C0518:45396:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.977160] [ip-0A0C0440:26277:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.977261] [ip-0A0C0439:24192:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.977179] [ip-0A0C0462:58180:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.977291] [ip-0A0C043B:31670:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.978369] [ip-0A0C0419:50508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.978514] [ip-0A0C041E:46585:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.978757] [ip-0A0C0427:43623:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.978830] [ip-0A0C047F:13338:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.979340] [ip-0A0C046D:15761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.980722] [ip-0A0C045D:18419:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.980776] [ip-0A0C0417:77408:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.984119] [ip-0A0C0430:71894:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.984907] [ip-0A0C0428:35735:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.984697] [ip-0A0C045A:30824:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.985086] [ip-0A0C0440:26280:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.985945] [ip-0A0C0424:35750:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.986306] [ip-0A0C041E:46584:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.987277] [ip-0A0C0419:50513:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.987271] [ip-0A0C044E:23864:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.987825] [ip-0A0C0465:18901:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.988116] [ip-0A0C0439:24218:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.987994] [ip-0A0C043C:32946:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.989676] [ip-0A0C0480:9292 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.990754] [ip-0A0C0452:30558:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.992276] [ip-0A0C0433:40766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.993203] [ip-0A0C0433:40764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.993988] [ip-0A0C0465:18903:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.995071] [ip-0A0C042B:44605:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.995704] [ip-0A0C041E:46581:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.996059] [ip-0A0C045B:34779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.996056] [ip-0A0C043D:23228:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.997247] [ip-0A0C0446:34765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.996975] [ip-0A0C0458:34893:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.998320] [ip-0A0C047B:16697:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.998560] [ip-0A0C0451:29351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.999816] [ip-0A0C0428:35734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.999613] [ip-0A0C0451:29356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621263.999257] [ip-0A0C043A:32175:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.000674] [ip-0A0C0471:16290:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.000632] [ip-0A0C043F:27949:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.000830] [ip-0A0C042A:37466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.001432] [ip-0A0C0457:27272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.002390] [ip-0A0C0453:32502:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.003353] [ip-0A0C0467:17024:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.003770] [ip-0A0C045C:27766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.005422] [ip-0A0C0427:43617:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.005959] [ip-0A0C0456:34498:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.006532] [ip-0A0C0448:38547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.006824] [ip-0A0C0428:35728:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.007477] [ip-0A0C0417:77411:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.008060] [ip-0A0C0450:2468 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.008059] [ip-0A0C0409:7070 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.008162] [ip-0A0C043F:27950:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.008367] [ip-0A0C0419:50509:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.008609] [ip-0A0C0457:27268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.009014] [ip-0A0C0428:35733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.008773] [ip-0A0C0421:48690:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.009958] [ip-0A0C0456:34472:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.009673] [ip-0A0C0458:34890:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.009786] [ip-0A0C0447:34026:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.010529] [ip-0A0C0407:51595:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.010594] [ip-0A0C0475:13133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.010141] [ip-0A0C047D:10782:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.010683] [ip-0A0C043C:32943:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.011215] [ip-0A0C041F:50528:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.011095] [ip-0A0C043C:32949:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.011212] [ip-0A0C044E:23863:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.013525] [ip-0A0C044E:23861:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.013807] [ip-0A0C0417:77405:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.014212] [ip-0A0C045A:30823:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.014251] [ip-0A0C041F:50531:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.014659] [ip-0A0C0455:25939:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.014689] [ip-0A0C0442:26733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.015382] [ip-0A0C041F:50527:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.015948] [ip-0A0C0476:7310 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.017296] [ip-0A0C0465:18905:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.018542] [ip-0A0C0463:21381:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.018525] [ip-0A0C0463:21378:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.019066] [ip-0A0C0459:27229:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.019599] [ip-0A0C0424:35752:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.019689] [ip-0A0C0418:43310:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.019858] [ip-0A0C0457:27264:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.021573] [ip-0A0C0456:34475:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.021302] [ip-0A0C0465:18902:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.021688] [ip-0A0C047B:16696:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.021654] [ip-0A0C0475:13130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.021738] [ip-0A0C041C:52573:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.022109] [ip-0A0C0471:16286:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.022057] [ip-0A0C043A:32176:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.023148] [ip-0A0C045D:18420:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.022912] [ip-0A0C045C:27763:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.023655] [ip-0A0C0465:18906:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.022967] [ip-0A0C045C:27760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.024243] [ip-0A0C0434:35522:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.024641] [ip-0A0C0422:68397:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.026311] [ip-0A0C044E:23866:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.027814] [ip-0A0C041B:64864:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.028032] [ip-0A0C047A:15064:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.028373] [ip-0A0C0413:78706:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.029071] [ip-0A0C0423:40773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.028843] [ip-0A0C0442:26732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.029576] [ip-0A0C0456:34470:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.029766] [ip-0A0C0477:14861:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.030051] [ip-0A0C0416:33885:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.030286] [ip-0A0C0446:34764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.030721] [ip-0A0C0419:50507:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.031576] [ip-0A0C0411:46380:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.031560] [ip-0A0C043B:31678:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.032947] [ip-0A0C044C:29090:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.033032] [ip-0A0C0424:35753:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.033082] [ip-0A0C0454:31408:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.033160] [ip-0A0C0454:31406:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.032699] [ip-0A0C043A:32180:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.033685] [ip-0A0C0427:43615:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.034345] [ip-0A0C0419:50510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.033756] [ip-0A0C042E:45854:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.034632] [ip-0A0C0463:21375:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.035604] [ip-0A0C0448:38548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.037018] [ip-0A0C042F:41887:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.037090] [ip-0A0C042F:41882:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.038283] [ip-0A0C0479:10656:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.038276] [ip-0A0C0479:10652:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.038994] [ip-0A0C042B:44604:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.040342] [ip-0A0C0477:14858:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.040384] [ip-0A0C0474:13093:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.040928] [ip-0A0C045E:28215:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.040872] [ip-0A0C043C:32948:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.041140] [ip-0A0C0470:12036:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.041420] [ip-0A0C043D:23226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.041629] [ip-0A0C0422:68398:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.042196] [ip-0A0C0477:14857:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.043032] [ip-0A0C043B:31676:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.043519] [ip-0A0C042C:40019:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.043671] [ip-0A0C0407:51594:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.043568] [ip-0A0C0476:7312 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.043651] [ip-0A0C0413:78701:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.044021] [ip-0A0C0431:37390:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.044381] [ip-0A0C047B:16698:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.044894] [ip-0A0C0457:27269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.044804] [ip-0A0C0476:7314 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.045103] [ip-0A0C0476:7315 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.045664] [ip-0A0C0409:7069 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.046565] [ip-0A0C0446:34767:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.047083] [ip-0A0C0446:34766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.047208] [ip-0A0C045B:34773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.047236] [ip-0A0C0453:32501:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.047721] [ip-0A0C0419:50511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.048223] [ip-0A0C045B:34772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.048116] [ip-0A0C041D:43604:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.048544] [ip-0A0C045D:18417:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.048610] [ip-0A0C047F:13335:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.049865] [ip-0A0C043C:32945:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.050214] [ip-0A0C043C:32947:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.051329] [ip-0A0C0423:40769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.050776] [ip-0A0C043A:32189:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.051525] [ip-0A0C0452:30553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.051735] [ip-0A0C0452:30556:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.051191] [ip-0A0C043A:32177:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.052288] [ip-0A0C041D:43600:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.053249] [ip-0A0C0430:71891:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.053579] [ip-0A0C041B:64866:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.053503] [ip-0A0C0417:77406:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.054043] [ip-0A0C0413:78707:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.054442] [ip-0A0C0417:77410:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.055301] [ip-0A0C0419:50512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.055522] [ip-0A0C043D:23229:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.055982] [ip-0A0C043F:27952:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.055950] [ip-0A0C0412:26271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.057774] [ip-0A0C0425:50068:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.058126] [ip-0A0C0418:43306:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.058229] [ip-0A0C0413:78702:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.058631] [ip-0A0C0425:50071:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.058491] [ip-0A0C046D:15762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.058930] [ip-0A0C047B:16695:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.059388] [ip-0A0C0457:27265:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.059472] [ip-0A0C0412:26267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.060111] [ip-0A0C0408:70966:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.060366] [ip-0A0C0408:70964:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.061052] [ip-0A0C041A:70157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.062082] [ip-0A0C0424:35751:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.062059] [ip-0A0C047C:20019:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.062304] [ip-0A0C047C:20016:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.062610] [ip-0A0C0457:27266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.063158] [ip-0A0C0408:70968:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.064140] [ip-0A0C0416:33884:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.064691] [ip-0A0C0426:45268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.064964] [ip-0A0C0426:45271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.064822] [ip-0A0C0446:34762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.065149] [ip-0A0C0427:43619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.066669] [ip-0A0C0420:47998:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.067590] [ip-0A0C0470:12040:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.068125] [ip-0A0C0477:14855:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.067831] [ip-0A0C0422:68393:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.068030] [ip-0A0C047D:10777:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.068797] [ip-0A0C0477:14862:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.068004] [ip-0A0C047D:10784:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.068830] [ip-0A0C0427:43618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.070161] [ip-0A0C0423:40767:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.070194] [ip-0A0C0409:7074 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.070537] [ip-0A0C047B:16691:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.070512] [ip-0A0C042A:37470:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.070723] [ip-0A0C0477:14856:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.070508] [ip-0A0C044F:24875:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.071065] [ip-0A0C0471:16285:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.070927] [ip-0A0C0408:70971:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.071757] [ip-0A0C0480:9291 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.072113] [ip-0A0C0474:13089:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.072110] [ip-0A0C0425:50067:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.072612] [ip-0A0C0446:34768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.073426] [ip-0A0C0450:2478 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.074002] [ip-0A0C047B:16692:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.074443] [ip-0A0C0409:7075 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.074725] [ip-0A0C046D:15765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.075519] [ip-0A0C0416:33886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.075801] [ip-0A0C047F:13331:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.075604] [ip-0A0C0412:26269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.076132] [ip-0A0C0408:70965:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.075957] [ip-0A0C042E:45852:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.077027] [ip-0A0C044C:29093:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.077156] [ip-0A0C044C:29091:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.077586] [ip-0A0C044A:26185:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.078147] [ip-0A0C045E:28220:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.078860] [ip-0A0C044F:24876:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.079353] [ip-0A0C0475:13129:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.079682] [ip-0A0C0455:25941:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.079985] [ip-0A0C041C:52578:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.080172] [ip-0A0C0440:26282:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.080232] [ip-0A0C0462:58182:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.080754] [ip-0A0C044C:29095:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.080608] [ip-0A0C0442:26736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.081329] [ip-0A0C0427:43616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.081624] [ip-0A0C0453:32499:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.081675] [ip-0A0C0453:32498:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.082194] [ip-0A0C0418:43308:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.083878] [ip-0A0C043B:31697:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.084175] [ip-0A0C0411:46374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.083907] [ip-0A0C047C:20015:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.083912] [ip-0A0C0422:68395:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.084677] [ip-0A0C041B:64863:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.084903] [ip-0A0C0427:43620:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.085106] [ip-0A0C043B:31671:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.086163] [ip-0A0C0409:7073 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.086809] [ip-0A0C0423:40766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.086405] [ip-0A0C047F:13334:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.087005] [ip-0A0C0412:26268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.087317] [ip-0A0C0469:16589:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.088412] [ip-0A0C044C:29098:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.088427] [ip-0A0C0440:26281:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.088128] [ip-0A0C0442:26737:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.089549] [ip-0A0C041C:52579:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.090283] [ip-0A0C0423:40768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.089919] [ip-0A0C041A:70158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.090601] [ip-0A0C0423:40772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.090219] [ip-0A0C045D:18421:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.090173] [ip-0A0C0432:63932:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.092288] [ip-0A0C0418:43312:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.092461] [ip-0A0C0418:43305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.093057] [ip-0A0C0409:7071 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.094341] [ip-0A0C0480:9293 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.094452] [ip-0A0C0425:50069:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.095866] [ip-0A0C047C:20014:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.096583] [ip-0A0C0471:16287:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.096171] [ip-0A0C0412:26272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.097302] [ip-0A0C045D:18416:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.097948] [ip-0A0C047C:20021:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.098406] [ip-0A0C0455:25938:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.099364] [ip-0A0C0418:43309:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.099892] [ip-0A0C044F:24879:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.100054] [ip-0A0C0470:12033:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.100330] [ip-0A0C045D:18418:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.100955] [ip-0A0C042C:40021:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.100801] [ip-0A0C0422:68396:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.101119] [ip-0A0C0422:68400:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.101539] [ip-0A0C041B:64865:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.101942] [ip-0A0C041B:64860:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.102528] [ip-0A0C045E:28216:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.103225] [ip-0A0C045E:28239:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.102797] [ip-0A0C0445:37404:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.103359] [ip-0A0C045E:28222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.103107] [ip-0A0C041C:52576:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.104297] [ip-0A0C0431:37389:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.105408] [ip-0A0C0453:32497:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.105235] [ip-0A0C0459:27228:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.105416] [ip-0A0C047C:20017:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.105670] [ip-0A0C0469:16584:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.106071] [ip-0A0C043B:31672:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.106425] [ip-0A0C0440:26278:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.106468] [ip-0A0C0453:32500:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.106811] [ip-0A0C0470:12037:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.106571] [ip-0A0C042F:41889:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.107067] [ip-0A0C0455:25936:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.107617] [ip-0A0C042B:44607:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.107919] [ip-0A0C045B:34777:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.107771] [ip-0A0C047F:13336:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.108151] [ip-0A0C044F:24882:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.108951] [ip-0A0C0518:45395:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.109033] [ip-0A0C0440:26279:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.109493] [ip-0A0C0407:51587:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.110037] [ip-0A0C0439:24194:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.109700] [ip-0A0C0442:26742:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.110075] [ip-0A0C0414:63501:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.110380] [ip-0A0C0411:46379:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.110838] [ip-0A0C0518:45394:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.110831] [ip-0A0C0467:17025:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.111104] [ip-0A0C0471:16284:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.110983] [ip-0A0C044F:24880:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.111325] [ip-0A0C0411:46377:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.111504] [ip-0A0C044B:30348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.111711] [ip-0A0C0459:27231:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.111959] [ip-0A0C041A:70161:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.113176] [ip-0A0C045D:18422:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.112755] [ip-0A0C042E:45855:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.113710] [ip-0A0C0518:45393:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.113523] [ip-0A0C041C:52603:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.113981] [ip-0A0C0462:58179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.114069] [ip-0A0C044B:30349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.114680] [ip-0A0C047F:13332:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.114872] [ip-0A0C043B:31675:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.115151] [ip-0A0C0447:34027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.116114] [ip-0A0C0518:45391:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.116132] [ip-0A0C0518:45398:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.116024] [ip-0A0C0425:50070:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.116303] [ip-0A0C0448:38546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.116294] [ip-0A0C0445:37407:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.117091] [ip-0A0C042F:41883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.117733] [ip-0A0C0425:50073:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.117513] [ip-0A0C0442:26730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.118149] [ip-0A0C041D:43598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.118595] [ip-0A0C041A:70159:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.119460] [ip-0A0C0454:31409:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.119513] [ip-0A0C041B:64861:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.119803] [ip-0A0C047F:13337:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.119969] [ip-0A0C0470:12039:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.120306] [ip-0A0C042F:41888:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.121459] [ip-0A0C044A:26184:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.121478] [ip-0A0C0434:35519:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.122091] [ip-0A0C0411:46375:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.122114] [ip-0A0C0462:58178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.121817] [ip-0A0C042F:41884:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.123026] [ip-0A0C0470:12035:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.123636] [ip-0A0C0474:13095:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.124670] [ip-0A0C0463:21380:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.124788] [ip-0A0C0467:17027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.126017] [ip-0A0C0430:71890:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.126277] [ip-0A0C044A:26183:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.126093] [ip-0A0C0451:29350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.126394] [ip-0A0C041A:70154:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.126371] [ip-0A0C0459:27227:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.126639] [ip-0A0C045A:30825:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.126976] [ip-0A0C041B:64862:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.127281] [ip-0A0C0462:58185:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.127697] [ip-0A0C0426:45276:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.127811] [ip-0A0C0474:13092:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.129977] [ip-0A0C0480:9288 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.129978] [ip-0A0C0416:33882:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.130166] [ip-0A0C0462:58181:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.130947] [ip-0A0C043E:20563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.130939] [ip-0A0C043E:20570:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.132079] [ip-0A0C0421:48694:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.132160] [ip-0A0C0421:48689:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.133652] [ip-0A0C042A:37465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.134295] [ip-0A0C0450:2470 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.134335] [ip-0A0C0421:48693:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.134476] [ip-0A0C046D:15769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.134900] [ip-0A0C0451:29346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.135996] [ip-0A0C045A:30820:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.136299] [ip-0A0C041D:43599:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.136899] [ip-0A0C0450:2524 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.136998] [ip-0A0C0471:16291:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.137187] [ip-0A0C0411:46376:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.137096] [ip-0A0C041A:70156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.137172] [ip-0A0C0447:34034:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.137669] [ip-0A0C042B:44602:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.137807] [ip-0A0C046D:15768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.138151] [ip-0A0C0434:35546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.138425] [ip-0A0C0454:31407:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.139125] [ip-0A0C0474:13087:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.139258] [ip-0A0C0474:13088:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.139517] [ip-0A0C0426:45269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.139801] [ip-0A0C0430:71893:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.142900] [ip-0A0C0426:45273:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.144022] [ip-0A0C0471:16289:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.143442] [ip-0A0C042E:45856:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.144178] [ip-0A0C042A:37467:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.144054] [ip-0A0C044B:30350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.144424] [ip-0A0C0432:63937:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.144783] [ip-0A0C0431:37392:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.145698] [ip-0A0C0445:37401:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.146888] [ip-0A0C0459:27232:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.147743] [ip-0A0C0424:35757:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.148074] [ip-0A0C0458:34889:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.148466] [ip-0A0C0455:25940:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.148619] [ip-0A0C042E:45853:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.149191] [ip-0A0C0455:25935:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.150050] [ip-0A0C0448:38549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.150185] [ip-0A0C0445:37408:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.151604] [ip-0A0C041D:43605:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.151938] [ip-0A0C0459:27226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.152865] [ip-0A0C042B:44606:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.153814] [ip-0A0C0448:38551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.153889] [ip-0A0C0467:17030:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.154266] [ip-0A0C0467:17029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.154588] [ip-0A0C0426:45270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.154365] [ip-0A0C0467:17031:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.154446] [ip-0A0C0451:29348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.155070] [ip-0A0C042C:40015:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.155275] [ip-0A0C042B:44603:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.156396] [ip-0A0C045B:34776:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.156574] [ip-0A0C045B:34774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.156491] [ip-0A0C0475:13134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.157521] [ip-0A0C0480:9287 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.157889] [ip-0A0C045B:34778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.158133] [ip-0A0C0480:9290 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.159697] [ip-0A0C042E:45857:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.159945] [ip-0A0C042E:45850:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.160822] [ip-0A0C042B:44616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.160725] [ip-0A0C0445:37403:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.160767] [ip-0A0C0445:37405:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.162425] [ip-0A0C0447:34032:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.162708] [ip-0A0C0439:24189:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.162704] [ip-0A0C047A:15061:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.163115] [ip-0A0C0439:24188:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.163145] [ip-0A0C043D:23233:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.163928] [ip-0A0C047A:15066:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.164052] [ip-0A0C043F:27946:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.164495] [ip-0A0C0463:21376:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.165505] [ip-0A0C0420:47986:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.166002] [ip-0A0C042C:40022:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.166895] [ip-0A0C0454:31422:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.167291] [ip-0A0C0454:31412:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.168450] [ip-0A0C047D:10780:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.169186] [ip-0A0C0463:21374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.169247] [ip-0A0C0451:29344:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.170502] [ip-0A0C046D:15766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.171032] [ip-0A0C0424:35755:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.171281] [ip-0A0C0424:35754:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.171509] [ip-0A0C046D:15764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.171870] [ip-0A0C0458:34887:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.171743] [ip-0A0C0432:63934:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.173303] [ip-0A0C0454:31410:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.173282] [ip-0A0C0424:35756:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.173796] [ip-0A0C0448:38553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.174061] [ip-0A0C0448:38552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.174830] [ip-0A0C046D:15763:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.175230] [ip-0A0C0451:29345:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.175651] [ip-0A0C0480:9294 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.176314] [ip-0A0C0479:10651:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.176009] [ip-0A0C0469:16588:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.176378] [ip-0A0C0479:10654:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.176845] [ip-0A0C0430:71896:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.178397] [ip-0A0C0450:2487 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.180374] [ip-0A0C0431:37391:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.180846] [ip-0A0C0420:47985:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.180784] [ip-0A0C042A:37469:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.181099] [ip-0A0C0463:21379:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.181645] [ip-0A0C042A:37468:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.182254] [ip-0A0C044B:30351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.182645] [ip-0A0C0434:35520:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.182937] [ip-0A0C0407:51592:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.183153] [ip-0A0C043F:27953:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.184997] [ip-0A0C0439:24195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.185992] [ip-0A0C0458:34888:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.187405] [ip-0A0C041D:43603:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.188274] [ip-0A0C0439:24193:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.188439] [ip-0A0C047A:15072:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.188964] [ip-0A0C045A:30822:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.189944] [ip-0A0C0439:24191:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.190413] [ip-0A0C0463:21377:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.190881] [ip-0A0C045A:30826:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.191188] [ip-0A0C0475:13132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.191476] [ip-0A0C043D:23227:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.191507] [ip-0A0C0452:30551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.191564] [ip-0A0C043D:23231:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.191910] [ip-0A0C0452:30552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.193790] [ip-0A0C0434:35518:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.193813] [ip-0A0C041D:43602:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.194199] [ip-0A0C0450:2469 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.194021] [ip-0A0C0447:34028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.194781] [ip-0A0C0416:33887:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.195211] [ip-0A0C0430:71895:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.195256] [ip-0A0C0475:13127:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.195442] [ip-0A0C0475:13128:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.196154] [ip-0A0C043F:27948:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.197087] [ip-0A0C0458:34895:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.197767] [ip-0A0C0407:51593:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.198280] [ip-0A0C0431:37393:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.198428] [ip-0A0C0420:47984:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.198286] [ip-0A0C043F:27951:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.198376] [ip-0A0C043F:27947:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.198722] [ip-0A0C0450:2472 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.199029] [ip-0A0C0452:30555:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.199389] [ip-0A0C0475:13131:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.200101] [ip-0A0C0407:51588:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.200059] [ip-0A0C0430:71892:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.200209] [ip-0A0C0430:71889:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.200816] [ip-0A0C0452:30557:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.200975] [ip-0A0C0452:30554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.201443] [ip-0A0C043D:23232:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.201527] [ip-0A0C045A:30827:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.202400] [ip-0A0C045A:30821:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.202898] [ip-0A0C0458:34894:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.203147] [ip-0A0C0421:48691:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.203310] [ip-0A0C0458:34891:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.203504] [ip-0A0C042A:37464:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.203539] [ip-0A0C042A:37463:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.204340] [ip-0A0C044B:30345:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.204677] [ip-0A0C044B:30346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.208977] [ip-0A0C044B:30344:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.210120] [ip-0A0C0447:34031:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.210792] [ip-0A0C043D:23230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.210822] [ip-0A0C0407:51586:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.212369] [ip-0A0C0416:33883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.212980] [ip-0A0C0416:33881:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.212502] [ip-0A0C047D:10778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.213337] [ip-0A0C0447:34030:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.214940] [ip-0A0C0450:2471 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.215161] [ip-0A0C0479:10653:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.214801] [ip-0A0C047D:10783:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.215891] [ip-0A0C047A:15060:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.216402] [ip-0A0C0421:48696:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.217955] [ip-0A0C0479:10657:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.218328] [ip-0A0C0416:33880:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.220031] [ip-0A0C0479:10655:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.220803] [ip-0A0C0434:35523:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.221819] [ip-0A0C042C:40014:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.223798] [ip-0A0C0431:37386:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.224216] [ip-0A0C0434:35521:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.224556] [ip-0A0C0447:34029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.225607] [ip-0A0C0434:35524:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.225578] [ip-0A0C0432:63948:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.225221] [ip-0A0C047D:10779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.225411] [ip-0A0C047D:10781:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.228070] [ip-0A0C0469:16583:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.228266] [ip-0A0C0432:63936:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.229470] [ip-0A0C0414:63502:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.231366] [ip-0A0C0407:51589:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.231542] [ip-0A0C0421:48692:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.232597] [ip-0A0C0479:10680:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.232850] [ip-0A0C0431:37387:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.234152] [ip-0A0C0431:37388:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.236056] [ip-0A0C0414:63503:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.236131] [ip-0A0C047A:15058:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.238597] [ip-0A0C0420:47990:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.239571] [ip-0A0C0421:48695:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.244103] [ip-0A0C0420:47987:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.244093] [ip-0A0C042C:40016:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.244196] [ip-0A0C042C:40013:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.247990] [ip-0A0C042C:40017:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.250757] [ip-0A0C0469:16582:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.252360] [ip-0A0C047A:15059:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.252747] [ip-0A0C047A:15062:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.255876] [ip-0A0C0420:47983:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.255766] [ip-0A0C044A:26182:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.256370] [ip-0A0C0432:63931:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.257054] [ip-0A0C0420:47988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.269071] [ip-0A0C0414:63505:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.272470] [ip-0A0C044A:26186:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.273176] [ip-0A0C044A:26188:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.272950] [ip-0A0C0469:16581:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.273355] [ip-0A0C044A:26187:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.275515] [ip-0A0C0432:63933:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.277801] [ip-0A0C0469:16586:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.277754] [ip-0A0C0432:63930:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.278480] [ip-0A0C044A:26189:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.288031] [ip-0A0C043E:20566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.288131] [ip-0A0C043E:20569:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.289208] [ip-0A0C0469:16585:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.292209] [ip-0A0C0414:63499:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.317420] [ip-0A0C043E:20565:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.317964] [ip-0A0C0414:63519:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.321138] [ip-0A0C0414:63500:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.331505] [ip-0A0C043E:20572:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.332663] [ip-0A0C043E:20568:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.335476] [ip-0A0C043E:20571:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621264.339558] [ip-0A0C0414:63506:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
:::MLLOG {"namespace": "", "time_ms": 1634621265250, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634621265290, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634621265290, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1634621265291, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634621265291, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1634621265291, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1634621265291, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "96xND96amsr_A100_v4", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:27:57] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[ip-0A0C0409:0:7073 - context.c:584] INFO job (ID: 867538721505398971) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:7073 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:7073 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:7075 - context.c:584] INFO job (ID: 867538333646533650) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:7075 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:7075 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:7071 - context.c:584] INFO job (ID: 867537996713452727) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:7071 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:7071 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:7069 - context.c:584] INFO job (ID: 867538575679348066) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:7069 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:7069 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:7076 - context.c:584] INFO job (ID: 867538132841527068) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:7076 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:7076 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:7070 - context.c:584] INFO job (ID: 867538003103665337) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:7070 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:7070 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:7074 - context.c:584] INFO job (ID: 867538780156620838) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:7074 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:7074 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:7072 - context.c:584] INFO job (ID: 867538646424388281) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:7072 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:7072 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621357079, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2291791550, "metadata": {"file": "main.py", "lineno": 72}}
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621357079, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 138}}
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621357079, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 139}}
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621357079, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1500, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 140}}
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621357080, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 142}}
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621357080, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 143}}
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621357080, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 144}}
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621357080, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 145}}
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621357080, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 146}}
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621357080, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 147}}
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621357080, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 148}}
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621357080, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 149}}
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:29:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621381090, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1634621381106, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621381109, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1634621381110, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 95}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621383819, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 84, "metadata": {"file": "main.py", "lineno": 136}}
:::MLLOG {"namespace": "", "time_ms": 1634621383820, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1634621383820, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 40}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621383820, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1, "epoch_count": 20}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621385215, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2408.957080383003, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621385215, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.02989933774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621385216, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2408.957080383003, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634621385216, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621385216, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621385907, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4859.764916517984, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621385908, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.04976556291390729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621385908, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4859.764916517984, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621385908, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621385908, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621386552, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5216.616432225703, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621386552, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0696317880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621386553, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5216.616432225703, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634621386553, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621386553, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621387197, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5214.543379781078, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621387198, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.08949801324503312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621387198, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5214.543379781078, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 60}}
:::MLLOG {"namespace": "", "time_ms": 1634621387198, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621387198, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621387832, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5300.770407771782, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621387832, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.10936423841059603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621387833, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5300.770407771782, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 80}}
:::MLLOG {"namespace": "", "time_ms": 1634621387833, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621387833, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621388457, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5380.727102095079, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621388458, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.12923046357615892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621388458, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5380.727102095079, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 100}}
:::MLLOG {"namespace": "", "time_ms": 1634621388458, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621388458, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621389085, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5365.618523730332, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621389085, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.14909668874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621389085, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5365.618523730332, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634621389085, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621389085, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621389720, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5292.288474429241, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621389720, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.16896291390728477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621389721, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5292.288474429241, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1634621389721, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621389721, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621390347, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5366.783211510384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621390347, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.18882913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621390348, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5366.783211510384, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 160}}
:::MLLOG {"namespace": "", "time_ms": 1634621390348, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621390348, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621390972, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5385.773301542449, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621390972, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.20869536423841056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621390972, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5385.773301542449, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 180}}
:::MLLOG {"namespace": "", "time_ms": 1634621390972, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621390973, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621391600, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5359.207500302321, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621391600, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.22856158940397348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621391600, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5359.207500302321, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 200}}
:::MLLOG {"namespace": "", "time_ms": 1634621391600, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621391600, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621392228, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5354.2211076086305, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621392228, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.24842781456953641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621392228, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5354.2211076086305, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 220}}
:::MLLOG {"namespace": "", "time_ms": 1634621392228, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621392228, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621392855, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5361.952039106528, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621392856, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26829403973509935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621392856, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5361.952039106528, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 240}}
:::MLLOG {"namespace": "", "time_ms": 1634621392856, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621392856, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621393482, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5370.112509402457, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621393482, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.28816026490066227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621393482, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5370.112509402457, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 260}}
:::MLLOG {"namespace": "", "time_ms": 1634621393482, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621393482, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621394112, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5341.575949064826, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621394112, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3080264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621394112, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5341.575949064826, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1634621394112, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621394112, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621394752, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5255.602546790165, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621394752, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32789271523178803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621394752, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5255.602546790165, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 300}}
:::MLLOG {"namespace": "", "time_ms": 1634621394752, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621394752, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621395383, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5326.623719639874, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621395384, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.347758940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621395384, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5326.623719639874, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 320}}
:::MLLOG {"namespace": "", "time_ms": 1634621395384, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621395384, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621396014, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5332.908543106051, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621396014, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36762516556291386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621396014, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5332.908543106051, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 340}}
:::MLLOG {"namespace": "", "time_ms": 1634621396015, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621396015, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621396644, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5342.746425370656, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621396644, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3874913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621396644, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5342.746425370656, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 360}}
:::MLLOG {"namespace": "", "time_ms": 1634621396644, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621396644, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621397266, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5406.16716510435, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621397266, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.40735761589403974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621397266, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5406.16716510435, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 380}}
:::MLLOG {"namespace": "", "time_ms": 1634621397267, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621397267, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621397888, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5411.217583923078, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621397888, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621397888, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5411.217583923078, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 400}}
:::MLLOG {"namespace": "", "time_ms": 1634621397888, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621397888, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621398514, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5371.369226664634, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621398514, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.44709006622516556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621398515, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5371.369226664634, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1634621398515, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621398515, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621399138, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5390.9733264120505, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621399139, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4669562913907285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621399139, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5390.9733264120505, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 440}}
:::MLLOG {"namespace": "", "time_ms": 1634621399139, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621399139, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621399765, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5365.949488834313, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621399766, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4868225165562914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621399766, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5365.949488834313, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 460}}
:::MLLOG {"namespace": "", "time_ms": 1634621399766, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621399766, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621400392, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5366.364274353264, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621400392, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5066887417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621400393, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5366.364274353264, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 480}}
:::MLLOG {"namespace": "", "time_ms": 1634621400393, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621400393, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621401021, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5345.303816356115, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621401022, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5265549668874172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621401022, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5345.303816356115, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 500}}
:::MLLOG {"namespace": "", "time_ms": 1634621401022, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621401022, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621401646, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5384.324687178472, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621401647, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5464211920529801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621401647, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5384.324687178472, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 520}}
:::MLLOG {"namespace": "", "time_ms": 1634621401647, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621401647, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621402269, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5402.337383944247, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621402269, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.566287417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621402269, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5402.337383944247, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 540}}
:::MLLOG {"namespace": "", "time_ms": 1634621402269, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621402270, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621402890, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5414.920567832604, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621402891, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5861536423841059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621402891, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5414.920567832604, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1634621402891, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621402891, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621403511, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5415.438682513375, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621403512, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6060198675496689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621403512, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5415.438682513375, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634621403512, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621403512, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621404136, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5389.338481165238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621404136, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6258860927152318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621404136, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5389.338481165238, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 600}}
:::MLLOG {"namespace": "", "time_ms": 1634621404136, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621404137, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621404753, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5447.438615696106, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621404754, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6457523178807947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621404754, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5447.438615696106, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 620}}
:::MLLOG {"namespace": "", "time_ms": 1634621404754, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621404754, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621405372, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5436.916008022935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621405373, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6656185430463576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621405373, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5436.916008022935, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 640}}
:::MLLOG {"namespace": "", "time_ms": 1634621405373, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621405373, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621405998, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5372.0059968231935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621405999, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6854847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621405999, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5372.0059968231935, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 660}}
:::MLLOG {"namespace": "", "time_ms": 1634621405999, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621405999, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621406622, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5392.646306576851, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621406623, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7053509933774835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621406623, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5392.646306576851, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 680}}
:::MLLOG {"namespace": "", "time_ms": 1634621406623, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621406623, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621407240, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5449.492395267444, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621407240, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7252172185430463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621407240, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5449.492395267444, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 700}}
:::MLLOG {"namespace": "", "time_ms": 1634621407241, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621407241, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621407861, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5416.589709569851, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621407861, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7450834437086092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621407862, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5416.589709569851, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 720}}
:::MLLOG {"namespace": "", "time_ms": 1634621407862, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621407862, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621408489, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5360.173681528081, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621408489, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7649496688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621408489, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5360.173681528081, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 740}}
:::MLLOG {"namespace": "", "time_ms": 1634621408490, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621408490, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621409113, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5392.625671645446, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621409113, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7848158940397352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621409114, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5392.625671645446, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 760}}
:::MLLOG {"namespace": "", "time_ms": 1634621409114, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621409114, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621409734, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5421.2153982034, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621409734, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8046821192052981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621409734, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5421.2153982034, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634621409734, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621409734, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621410348, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5477.9679738043815, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621410348, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8245483443708609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621410348, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5477.9679738043815, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 800}}
:::MLLOG {"namespace": "", "time_ms": 1634621410348, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621410349, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621410973, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5377.957157565429, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621410974, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621410974, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5377.957157565429, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 820}}
:::MLLOG {"namespace": "", "time_ms": 1634621410974, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621410974, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621411593, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5432.328411437876, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621411593, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8642807947019867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621411593, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5432.328411437876, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 840}}
:::MLLOG {"namespace": "", "time_ms": 1634621411593, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621411593, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621412211, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5441.64793238127, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621412212, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8841470198675497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621412212, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5441.64793238127, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 860}}
:::MLLOG {"namespace": "", "time_ms": 1634621412212, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621412212, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621412837, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5378.373801608453, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621412837, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9040132450331126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621412837, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5378.373801608453, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 880}}
:::MLLOG {"namespace": "", "time_ms": 1634621412837, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621412838, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621413468, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5330.530338705523, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621413468, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9238794701986754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621413468, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5330.530338705523, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 900}}
:::MLLOG {"namespace": "", "time_ms": 1634621413469, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621413469, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621414096, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5358.477999339927, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621414096, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9437456953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621414096, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5358.477999339927, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 920}}
:::MLLOG {"namespace": "", "time_ms": 1634621414096, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621414096, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621414717, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5414.171661624967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621414718, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9636119205298014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621414718, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5414.171661624967, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 940}}
:::MLLOG {"namespace": "", "time_ms": 1634621414718, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621414718, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621415347, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5340.1125629344115, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621415348, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9834781456953643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621415348, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5340.1125629344115, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 960}}
:::MLLOG {"namespace": "", "time_ms": 1634621415348, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621415348, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621415968, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5421.169519287213, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621415969, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0033443708609273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621415969, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5421.169519287213, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 980}}
:::MLLOG {"namespace": "", "time_ms": 1634621416042, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621416043, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621416059, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621416487, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.878082275390625, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621416487, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621416655, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5491.740851814673, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621416655, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0232105960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621416655, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5491.740851814673, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621416746, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621416746, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621416760, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621417165, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8677932024002075, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621417165, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621417375, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5344.349067962601, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621417376, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.043076821192053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621417376, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5344.349067962601, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621417472, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621417472, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621417487, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621417884, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8864496946334839, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621417885, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621418088, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5460.277452858005, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621418088, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.062943046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621418088, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5460.277452858005, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621418197, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621418198, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621418213, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621418623, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8700388669967651, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621418623, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621418835, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5274.424512074445, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621418835, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0828092715231787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621418835, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5274.424512074445, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621418871, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621418871, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621418885, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621419297, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8667263984680176, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621419297, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621419489, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5439.518177386466, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621419489, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1026754966887418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621419490, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5439.518177386466, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621419528, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621419528, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621419544, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621419956, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8733644485473633, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621419956, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621420149, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5414.743724072428, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621420149, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1225417218543046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621420149, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5414.743724072428, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621420196, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621420197, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621420212, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621420614, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8637059926986694, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621420614, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621420805, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5520.204562547005, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621420806, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1424079470198676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621420806, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5520.204562547005, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621420843, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621420843, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621420859, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621421275, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8838005065917969, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621421275, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621421468, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5375.358182101822, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621421469, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1622741721854304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621421469, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5375.358182101822, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621421515, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621421515, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621421530, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621421927, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8685837984085083, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621421928, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621422125, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5512.075581065621, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621422125, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1821403973509934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621422126, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5512.075581065621, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621422163, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621422163, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621422180, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621422592, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8864723443984985, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621422592, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621422792, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5344.051158995143, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621422793, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2020066225165562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621422793, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5344.051158995143, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621422830, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621422830, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621422845, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621423247, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8848671913146973, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621423247, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621423444, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5472.490471684156, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621423445, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2218728476821192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621423445, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5472.490471684156, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621423481, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621423481, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621423495, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621423894, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8842573165893555, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621423895, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621424089, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5529.5353936119955, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621424089, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.241739072847682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621424089, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5529.5353936119955, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621424128, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621424128, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621424143, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621424543, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8816187381744385, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621424543, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621424738, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5510.030379164819, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621424739, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621424739, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5510.030379164819, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621424774, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621424775, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621424791, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621425201, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.879984974861145, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621425201, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621425399, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5381.947686175098, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621425400, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.281471523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621425400, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5381.947686175098, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621425436, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621425436, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621425452, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621425865, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8732067346572876, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621425865, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621426057, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5414.439995866037, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621426057, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3013377483443709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621426057, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5414.439995866037, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621426092, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621426092, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621426107, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621426527, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8914751410484314, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621426527, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621426729, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5281.075456828948, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621426729, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3212039735099337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621426729, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5281.075456828948, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621426766, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621426767, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621426782, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621427182, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8840019702911377, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621427182, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621427379, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5492.211699893842, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621427379, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3410701986754967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621427379, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5492.211699893842, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621427414, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621427415, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621427429, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621427845, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8870801329612732, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621427846, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621428040, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5380.114963723093, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621428040, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3609364238410595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621428040, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5380.114963723093, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621428077, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621428077, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621428093, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621428517, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8837394714355469, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621428517, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621428712, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5294.016098955837, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621428712, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3808026490066225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621428712, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5294.016098955837, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621428747, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621428748, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621428765, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621429173, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8813012838363647, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621429173, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621429381, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5304.940701374789, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621429382, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4006688741721853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621429382, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5304.940701374789, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621429419, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621429419, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621429435, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621429852, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8863277435302734, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621429852, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621430049, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5335.303009423662, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621430050, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4205350993377484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621430050, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5335.303009423662, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621430087, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621430087, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621430102, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621430518, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.894058346748352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621430518, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621430725, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5267.2232718400555, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621430726, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4404013245033112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621430726, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5267.2232718400555, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621430786, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621430786, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621430802, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621431204, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.889369010925293, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621431204, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621431406, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5418.914068628205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621431407, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4602675496688742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621431407, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5418.914068628205, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621431444, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621431444, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621431461, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621431878, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8854635953903198, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621431878, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621432076, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5320.739360870718, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621432076, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4801337748344372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621432076, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5320.739360870718, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621432137, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621432138, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621432152, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621432558, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8846724033355713, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621432558, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621432750, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5487.284637632404, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621432751, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621432751, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5487.284637632404, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621432786, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621432786, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621432802, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621433220, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8904443979263306, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621433220, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621433417, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5331.020329419668, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621433417, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621433417, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5331.020329419668, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621433454, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621433455, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621433469, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621433885, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8847411870956421, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621433885, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621434076, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5407.6732080215315, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621434077, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621434077, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5407.6732080215315, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621434113, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621434113, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621434128, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621434528, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8739565014839172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621434528, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621434768, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5133.635547998125, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621434768, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621434768, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5133.635547998125, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621434804, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621434804, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621434820, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621435225, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8925468921661377, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621435225, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621435414, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5505.649837540127, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621435415, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621435415, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5505.649837540127, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621435450, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621435451, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621435466, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621435883, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8839443922042847, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621435883, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621436091, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5252.088740414276, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621436091, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621436091, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5252.088740414276, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621436127, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621436127, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621436144, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621436556, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8808238506317139, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621436557, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621436754, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5362.074446551467, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621436754, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621436754, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5362.074446551467, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621436782, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621436783, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621436800, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621437205, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8849506378173828, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621437206, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621437420, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5276.276790668315, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621437420, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621437420, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5276.276790668315, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621437456, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621437456, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621437471, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621437871, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8905601501464844, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621437871, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621438068, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5495.194899435736, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621438068, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621438068, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5495.194899435736, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621438103, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621438104, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621438119, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621438519, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8937076330184937, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621438519, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621438706, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5582.257586506435, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621438706, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621438706, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5582.257586506435, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621438742, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621438742, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621438756, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621439157, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8866852521896362, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621439157, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621439348, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5547.145469051914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621439349, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621439349, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5547.145469051914, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621439384, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621439385, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621439399, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621439817, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8840680718421936, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621439817, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621440013, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5347.940773999941, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621440014, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621440014, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5347.940773999941, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621440050, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621440050, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621440067, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621440464, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8905006647109985, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621440465, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621440656, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5541.374115437713, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621440657, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621440657, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5541.374115437713, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621440693, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621440694, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621440709, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621441107, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8985251188278198, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621441107, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621441301, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5530.702880640348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621441302, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621441302, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5530.702880640348, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621441338, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621441338, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621441354, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621441771, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8905398845672607, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621441771, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621441963, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5376.857363272799, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621441964, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621441964, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5376.857363272799, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621442000, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621442000, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621442015, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621442429, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8979524970054626, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621442429, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621442624, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5390.208351022937, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621442624, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621442624, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5390.208351022937, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621442660, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621442660, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621442673, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621443076, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8953042030334473, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621443076, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621443272, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5489.642279659376, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621443273, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621443273, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5489.642279659376, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621443308, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621443308, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621443324, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621443740, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9006109237670898, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621443740, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621443930, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5405.2776248916, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621443931, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621443931, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5405.2776248916, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621443968, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621443968, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621443983, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621444502, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8954434990882874, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621444502, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621444726, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4433.543830949227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621444727, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621444727, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4433.543830949227, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621444762, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621444762, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621444779, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621445188, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8873892426490784, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621445189, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621445379, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5447.457566582517, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621445379, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621445379, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5447.457566582517, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621445415, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621445415, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621445431, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621445830, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8850587010383606, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621445830, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621446021, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5545.554202786773, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621446022, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621446022, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5545.554202786773, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621446059, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621446059, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621446075, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621446489, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9020605087280273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621446489, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621446682, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5391.7261421519825, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621446683, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621446683, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5391.7261421519825, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621446718, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621446719, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621446735, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621447143, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.897264838218689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621447143, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621447338, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5432.431018472297, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621447338, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621447338, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5432.431018472297, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621447374, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621447374, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621447390, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621447788, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8903547525405884, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621447788, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621447986, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5494.99777554314, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621447986, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621447986, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5494.99777554314, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621448022, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621448022, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621448040, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621448437, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8819139003753662, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621448437, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621448627, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5557.141740644978, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621448628, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621448628, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5557.141740644978, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621448663, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621448663, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621448680, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621449091, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9035611152648926, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621449091, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621449286, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5393.97965784081, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621449287, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621449287, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5393.97965784081, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621449322, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621449322, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621449339, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621449756, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8956750631332397, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621449756, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621449946, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5384.999512811901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621449947, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621449947, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5384.999512811901, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621449982, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621449982, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621449998, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621450412, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8988431692123413, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621450412, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621450605, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5398.312437155372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621450605, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621450605, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5398.312437155372, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621450641, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621450641, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621450657, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621451056, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9086319208145142, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621451056, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621451056, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 165, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1634621451245, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5570.133640254285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621451245, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621451245, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5570.133640254285, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2040}}
ENDING TIMING RUN AT 2021-10-19 05:30:57 AM
RESULT,image_segmentation,,199,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:57 AM
RESULT,image_segmentation,,199,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:57 AM
RESULT,image_segmentation,,199,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:57 AM
RESULT,image_segmentation,,199,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:57 AM
RESULT,image_segmentation,,199,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:57 AM
RESULT,image_segmentation,,199,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:57 AM
RESULT,image_segmentation,,199,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:57 AM
RESULT,image_segmentation,,199,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:57 AM
RESULT,image_segmentation,,199,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:58 AM
RESULT,image_segmentation,,200,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:58 AM
RESULT,image_segmentation,,200,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:58 AM
RESULT,image_segmentation,,200,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:58 AM
RESULT,image_segmentation,,200,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:58 AM
RESULT,image_segmentation,,200,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:58 AM
RESULT,image_segmentation,,200,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:30:58 AM
RESULT,image_segmentation,,200,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:00 AM
RESULT,image_segmentation,,202,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:01 AM
RESULT,image_segmentation,,203,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:02 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:04 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:05 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:06 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:07 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:08 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:09 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
ENDING TIMING RUN AT 2021-10-19 05:31:10 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:27:38 AM
