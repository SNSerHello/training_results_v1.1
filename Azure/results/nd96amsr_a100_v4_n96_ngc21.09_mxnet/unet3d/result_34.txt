+ : DGXA100_96x8x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019062840085946267
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data
+ : /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ LOGBASE=unet3d_96x8x1_211019062840085946267
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019062840085946267
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019062840085946267
+ readonly _cont_name=image_segmentation
+ _cont_name=image_segmentation
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07397/slurm_script: line 39: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh --container-name=image_segmentation true
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019062840085946267_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=96 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C040F
Clearing cache on ip-0A0C048C
Clearing cache on ip-0A0C048A
Clearing cache on ip-0A0C0483
Clearing cache on ip-0A0C046E
Clearing cache on ip-0A0C0437
Clearing cache on ip-0A0C0494
Clearing cache on ip-0A0C049C
Clearing cache on ip-0A0C0466
Clearing cache on ip-0A0C0473
Clearing cache on ip-0A0C0441
Clearing cache on ip-0A0C0490
Clearing cache on ip-0A0C0497
Clearing cache on ip-0A0C04C2
Clearing cache on ip-0A0C0487
Clearing cache on ip-0A0C0472
Clearing cache on ip-0A0C0484
Clearing cache on ip-0A0C0493
Clearing cache on ip-0A0C0438
Clearing cache on ip-0A0C044D
Clearing cache on ip-0A0C0460
Clearing cache on ip-0A0C049B
Clearing cache on ip-0A0C0464
Clearing cache on ip-0A0C047E
Clearing cache on ip-0A0C046C
Clearing cache on ip-0A0C0491
Clearing cache on ip-0A0C0492
Clearing cache on ip-0A0C0449
Clearing cache on ip-0A0C0496
Clearing cache on ip-0A0C048D
Clearing cache on ip-0A0C042D
Clearing cache on ip-0A0C0436
Clearing cache on ip-0A0C048B
Clearing cache on ip-0A0C0486
Clearing cache on ip-0A0C045F
Clearing cache on ip-0A0C0435
Clearing cache on ip-0A0C0498
Clearing cache on ip-0A0C0488
Clearing cache on ip-0A0C04AF
Clearing cache on ip-0A0C04DB
Clearing cache on ip-0A0C04AB
Clearing cache on ip-0A0C04A2
Clearing cache on ip-0A0C04CF
Clearing cache on ip-0A0C04C6
Clearing cache on ip-0A0C04A4
Clearing cache on ip-0A0C0429
Clearing cache on ip-0A0C04C4
Clearing cache on ip-0A0C04A0
Clearing cache on ip-0A0C04A8
Clearing cache on ip-0A0C04B1
Clearing cache on ip-0A0C04A9
Clearing cache on ip-0A0C04D9
Clearing cache on ip-0A0C0461
Clearing cache on ip-0A0C04B6
Clearing cache on ip-0A0C04A1
Clearing cache on ip-0A0C04C9
Clearing cache on ip-0A0C04AC
Clearing cache on ip-0A0C0495
Clearing cache on ip-0A0C04C3
Clearing cache on ip-0A0C04BE
Clearing cache on ip-0A0C0499
Clearing cache on ip-0A0C04BD
Clearing cache on ip-0A0C04B4
Clearing cache on ip-0A0C04CD
Clearing cache on ip-0A0C04D4
Clearing cache on ip-0A0C04AD
Clearing cache on ip-0A0C0443
Clearing cache on ip-0A0C04B2
Clearing cache on ip-0A0C0489
Clearing cache on ip-0A0C04C8
Clearing cache on ip-0A0C0485
Clearing cache on ip-0A0C04B9
Clearing cache on ip-0A0C046B
Clearing cache on ip-0A0C04AA
Clearing cache on ip-0A0C049D
Clearing cache on ip-0A0C04B7
Clearing cache on ip-0A0C0482
Clearing cache on ip-0A0C04BC
Clearing cache on ip-0A0C04DA
Clearing cache on ip-0A0C04A5
Clearing cache on ip-0A0C049F
Clearing cache on ip-0A0C04AE
Clearing cache on ip-0A0C04CC
Clearing cache on ip-0A0C04D3
Clearing cache on ip-0A0C048F
Clearing cache on ip-0A0C04B3
Clearing cache on ip-0A0C04B0
Clearing cache on ip-0A0C04C0
Clearing cache on ip-0A0C04C5
Clearing cache on ip-0A0C04A7
Clearing cache on ip-0A0C04BA
Clearing cache on ip-0A0C04B5
Clearing cache on ip-0A0C04C7
Clearing cache on ip-0A0C04A6
Clearing cache on ip-0A0C04D8
Clearing cache on ip-0A0C04BB
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=768 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:28:43 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
[1634624928.502873] [ip-0A0C0487:65539:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.584959] [ip-0A0C0487:65538:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.585124] [ip-0A0C0487:65541:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.589763] [ip-0A0C0487:65543:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.596999] [ip-0A0C0499:51694:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.599304] [ip-0A0C049D:53198:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.603599] [ip-0A0C0499:51721:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.606208] [ip-0A0C0437:61761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.606665] [ip-0A0C049D:53194:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.626398] [ip-0A0C0460:65047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.630535] [ip-0A0C04C8:84030:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.638727] [ip-0A0C04BE:83473:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.638768] [ip-0A0C04CC:83868:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.639243] [ip-0A0C0482:52803:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.650516] [ip-0A0C047E:62025:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.652953] [ip-0A0C0483:64438:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.655371] [ip-0A0C0437:61756:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.657081] [ip-0A0C04C0:82351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.663136] [ip-0A0C0497:97999:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.665826] [ip-0A0C04B0:36898:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.666361] [ip-0A0C0443:28843:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.666922] [ip-0A0C045F:63193:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.670853] [ip-0A0C0487:65542:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.671780] [ip-0A0C0486:65523:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.672127] [ip-0A0C04CC:83872:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.672770] [ip-0A0C04C7:84999:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.673279] [ip-0A0C0466:68144:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.678816] [ip-0A0C0482:52797:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.683428] [ip-0A0C042D:36829:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.685756] [ip-0A0C04B0:36899:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.687058] [ip-0A0C04A0:39929:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.687551] [ip-0A0C046E:67486:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.687413] [ip-0A0C04B7:21359:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.696395] [ip-0A0C046E:67492:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.697029] [ip-0A0C0460:65049:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.698412] [ip-0A0C04DA:77554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.698423] [ip-0A0C04DA:77560:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.701441] [ip-0A0C047E:62024:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.703226] [ip-0A0C0492:45443:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.703545] [ip-0A0C04A4:50483:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.704129] [ip-0A0C0460:65051:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.704671] [ip-0A0C04C4:82723:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.705144] [ip-0A0C04A4:50482:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.707007] [ip-0A0C04C3:81743:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.707023] [ip-0A0C04C3:81745:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.707436] [ip-0A0C0487:65540:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.707876] [ip-0A0C0483:64435:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.707748] [ip-0A0C04C7:84992:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.706068] [ip-0A0C049C:37109:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.708776] [ip-0A0C04C0:82353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.709704] [ip-0A0C0487:65545:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.710577] [ip-0A0C049F:38216:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.709770] [ip-0A0C049C:37115:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.712283] [ip-0A0C04C6:78628:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.712966] [ip-0A0C0494:46983:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.715063] [ip-0A0C0483:64442:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.714451] [ip-0A0C04B2:26483:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.714519] [ip-0A0C04B2:26480:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.716506] [ip-0A0C0497:97996:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.717985] [ip-0A0C0487:65544:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.718564] [ip-0A0C0466:68145:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.718558] [ip-0A0C0437:61760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.718242] [ip-0A0C0497:97995:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.719008] [ip-0A0C04BE:83476:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.719329] [ip-0A0C04D4:80225:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.719671] [ip-0A0C04BE:83475:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.719707] [ip-0A0C04CD:80780:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.719850] [ip-0A0C04B9:83617:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.719828] [ip-0A0C04B9:83618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.720846] [ip-0A0C0482:52800:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.725882] [ip-0A0C04D9:6688 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.725914] [ip-0A0C049D:53192:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.726262] [ip-0A0C04C6:78626:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.727160] [ip-0A0C0486:65529:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.727657] [ip-0A0C048D:51321:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.728998] [ip-0A0C04C5:84723:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.729747] [ip-0A0C0466:68151:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.732592] [ip-0A0C04D4:80229:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.733056] [ip-0A0C04B0:36901:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.736675] [ip-0A0C04DA:77553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.736760] [ip-0A0C042D:36835:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.738982] [ip-0A0C049F:38221:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.739287] [ip-0A0C0493:46844:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.739591] [ip-0A0C042D:36834:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.742547] [ip-0A0C04A2:41828:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.742461] [ip-0A0C04AA:25123:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.743627] [ip-0A0C04BC:78548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.747733] [ip-0A0C0435:5185 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.748545] [ip-0A0C04C8:84029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.748351] [ip-0A0C0443:28842:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.748692] [ip-0A0C0443:28845:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.749276] [ip-0A0C04BE:83470:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.748571] [ip-0A0C04CF:8877 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.748597] [ip-0A0C04CF:8873 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.752649] [ip-0A0C0499:51692:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.754918] [ip-0A0C04CC:83870:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.754413] [ip-0A0C049B:39226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.758562] [ip-0A0C0492:45437:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.759849] [ip-0A0C04C9:83010:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.761608] [ip-0A0C04C4:82722:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.761581] [ip-0A0C04DB:76152:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.761788] [ip-0A0C048C:46225:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.763659] [ip-0A0C04D3:82377:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.765508] [ip-0A0C04D4:80224:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.765759] [ip-0A0C04C7:84996:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.766312] [ip-0A0C0449:62963:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.767952] [ip-0A0C0499:51698:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.768574] [ip-0A0C0443:28839:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.770160] [ip-0A0C047E:62026:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.771930] [ip-0A0C04AA:25124:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.772476] [ip-0A0C04C8:84032:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.773141] [ip-0A0C04AC:43863:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.773479] [ip-0A0C0486:65526:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.773666] [ip-0A0C04C5:84721:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.774124] [ip-0A0C0496:31970:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.774258] [ip-0A0C04D9:6664 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.774912] [ip-0A0C049D:53191:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.775467] [ip-0A0C0464:65567:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.774911] [ip-0A0C044D:62612:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.776340] [ip-0A0C0437:61762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.777496] [ip-0A0C0494:46981:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.778250] [ip-0A0C04CD:80782:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.778579] [ip-0A0C04CD:80778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.780505] [ip-0A0C04A6:50106:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.781518] [ip-0A0C04C9:83011:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.781739] [ip-0A0C0499:51695:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.782899] [ip-0A0C045F:63199:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.782285] [ip-0A0C04A9:49552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.783118] [ip-0A0C0472:67533:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.783795] [ip-0A0C048A:62136:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.784662] [ip-0A0C0460:65050:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.785634] [ip-0A0C0464:65568:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.786389] [ip-0A0C0483:64436:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.786591] [ip-0A0C047E:62028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.787023] [ip-0A0C04C8:84031:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.786718] [ip-0A0C0493:46839:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.788087] [ip-0A0C04A7:27293:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.790147] [ip-0A0C04AC:43864:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.790191] [ip-0A0C04CC:83867:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.789982] [ip-0A0C040F:35466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.790068] [ip-0A0C0438:66266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.789918] [ip-0A0C049C:37112:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.793133] [ip-0A0C0460:65052:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.792747] [ip-0A0C04B9:83621:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.793520] [ip-0A0C049D:53197:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.794567] [ip-0A0C0483:64440:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.794546] [ip-0A0C0472:67532:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.796815] [ip-0A0C04A0:39931:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.796476] [ip-0A0C0482:52802:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.796783] [ip-0A0C0482:52798:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.797679] [ip-0A0C0499:51696:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.797783] [ip-0A0C04DB:76149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.797935] [ip-0A0C0441:58474:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.797377] [ip-0A0C04A8:55497:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.798188] [ip-0A0C046B:59751:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.798376] [ip-0A0C048D:51324:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.798469] [ip-0A0C048D:51322:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.800303] [ip-0A0C0466:68152:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.800173] [ip-0A0C0437:61757:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.800621] [ip-0A0C0435:5186 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.800661] [ip-0A0C0449:62966:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.801557] [ip-0A0C04B0:36896:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.801599] [ip-0A0C049D:53195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.804610] [ip-0A0C04BE:83472:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.806964] [ip-0A0C04A2:41830:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.804977] [ip-0A0C04A9:49554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.805797] [ip-0A0C048F:54835:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.807442] [ip-0A0C04A4:50480:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.808158] [ip-0A0C04B7:21358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.809013] [ip-0A0C045F:63198:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.809133] [ip-0A0C04B7:21361:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.809452] [ip-0A0C0449:62965:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.809757] [ip-0A0C04C0:82346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.810671] [ip-0A0C0499:51697:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.810930] [ip-0A0C046E:67489:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.812397] [ip-0A0C0496:31967:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.811570] [ip-0A0C0497:98000:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.814549] [ip-0A0C04A0:39934:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.813752] [ip-0A0C0496:31972:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.812437] [ip-0A0C04B2:26482:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.814194] [ip-0A0C04D9:6665 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.814532] [ip-0A0C0437:61769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.817484] [ip-0A0C04A0:39935:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.816825] [ip-0A0C0499:51693:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.817323] [ip-0A0C047E:62022:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.817160] [ip-0A0C0437:61759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.817794] [ip-0A0C04C4:82721:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.819008] [ip-0A0C0486:65522:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.819185] [ip-0A0C04DB:76153:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.819186] [ip-0A0C0494:46980:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.819805] [ip-0A0C04C0:82349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.821423] [ip-0A0C0472:67534:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.821612] [ip-0A0C045F:63194:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.820978] [ip-0A0C0490:51517:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.822110] [ip-0A0C04C8:84033:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.822597] [ip-0A0C04C8:84028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.823448] [ip-0A0C04C7:84995:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.824147] [ip-0A0C04B7:21356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.825946] [ip-0A0C04DA:77559:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.826204] [ip-0A0C04CC:83875:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.825905] [ip-0A0C0438:66288:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.826538] [ip-0A0C049D:53193:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.826788] [ip-0A0C04C5:84720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.827406] [ip-0A0C04B9:83620:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.828184] [ip-0A0C049D:53196:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.829311] [ip-0A0C047E:62027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.828013] [ip-0A0C049B:39227:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.831583] [ip-0A0C04A2:41827:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.829697] [ip-0A0C0489:65750:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.829747] [ip-0A0C0489:65751:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.831324] [ip-0A0C0492:45440:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.831500] [ip-0A0C04C8:84027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.831635] [ip-0A0C0437:61758:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.832401] [ip-0A0C04A4:50481:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.832829] [ip-0A0C046B:59746:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.832431] [ip-0A0C04BC:78547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.832561] [ip-0A0C0482:52799:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.833614] [ip-0A0C048A:62134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.834370] [ip-0A0C046E:67488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.834224] [ip-0A0C0482:52801:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.835354] [ip-0A0C04CC:83873:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.835070] [ip-0A0C0436:65849:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.835437] [ip-0A0C04C0:82352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.835681] [ip-0A0C04C5:84724:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.836554] [ip-0A0C0491:47338:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.838321] [ip-0A0C04AA:25126:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.838996] [ip-0A0C04A1:68050:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.838905] [ip-0A0C04C7:84994:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.839945] [ip-0A0C0483:64437:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.839977] [ip-0A0C04CC:83874:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.839940] [ip-0A0C0441:58475:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.840401] [ip-0A0C04C8:84034:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.840608] [ip-0A0C04B4:60454:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.841667] [ip-0A0C04B3:58191:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.841331] [ip-0A0C0443:28844:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.841068] [ip-0A0C04A8:55502:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.841688] [ip-0A0C04B3:58189:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.842373] [ip-0A0C0483:64439:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.842287] [ip-0A0C04BD:80625:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.843085] [ip-0A0C047E:62029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.843546] [ip-0A0C047E:62023:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.842676] [ip-0A0C0490:51519:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.843369] [ip-0A0C042D:36833:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.844095] [ip-0A0C04BB:25420:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.842898] [ip-0A0C0488:64080:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.844095] [ip-0A0C04BB:25417:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.843871] [ip-0A0C048B:48239:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.843532] [ip-0A0C04C6:78630:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.844250] [ip-0A0C0461:29187:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.844969] [ip-0A0C0497:97997:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.845792] [ip-0A0C04A5:53066:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.845822] [ip-0A0C04C3:81742:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.846301] [ip-0A0C04B0:36895:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.847086] [ip-0A0C0483:64441:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.847684] [ip-0A0C0493:46838:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.848975] [ip-0A0C0460:65046:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.849138] [ip-0A0C0460:65048:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.849553] [ip-0A0C04CC:83871:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.848365] [ip-0A0C0484:67477:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.848911] [ip-0A0C0494:46982:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.849480] [ip-0A0C0482:52796:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.851564] [ip-0A0C0495:49533:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.852027] [ip-0A0C0473:63715:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.853056] [ip-0A0C04A7:27296:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.853044] [ip-0A0C0466:68146:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.852582] [ip-0A0C04B5:51088:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.853145] [ip-0A0C0436:65853:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.852411] [ip-0A0C0498:60354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.853006] [ip-0A0C048F:54831:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.852849] [ip-0A0C049F:38217:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.853743] [ip-0A0C0435:5191 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.853843] [ip-0A0C04BA:17822:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.854194] [ip-0A0C0460:65045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.855256] [ip-0A0C04BE:83477:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.855535] [ip-0A0C04BE:83474:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.854797] [ip-0A0C04C6:78627:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.856728] [ip-0A0C0435:5188 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.857032] [ip-0A0C04B0:36910:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.855082] [ip-0A0C049C:37108:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.857522] [ip-0A0C04C0:82348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.858052] [ip-0A0C04C3:81749:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.858400] [ip-0A0C0441:58478:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.858321] [ip-0A0C04C0:82350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.858832] [ip-0A0C0486:65524:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.859988] [ip-0A0C0436:65850:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.859987] [ip-0A0C04CD:80783:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.858834] [ip-0A0C049B:39228:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.861218] [ip-0A0C04C5:84726:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.860578] [ip-0A0C04B2:26484:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.861899] [ip-0A0C04BE:83471:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.862713] [ip-0A0C04C3:81744:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.864088] [ip-0A0C04A0:39928:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.862406] [ip-0A0C04AF:41993:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.863060] [ip-0A0C04A4:50478:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.863791] [ip-0A0C045F:63195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.863460] [ip-0A0C048C:46227:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.863556] [ip-0A0C04D3:82376:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.864888] [ip-0A0C046C:60805:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.864988] [ip-0A0C0443:28841:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.865113] [ip-0A0C0443:28840:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.865965] [ip-0A0C04C7:84997:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.866334] [ip-0A0C04AB:40773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.865975] [ip-0A0C04B9:83619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.866383] [ip-0A0C04C0:82347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.866847] [ip-0A0C0486:65528:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.866642] [ip-0A0C04D3:82381:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.867883] [ip-0A0C045F:63200:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.867248] [ip-0A0C0497:97998:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.868543] [ip-0A0C04DA:77569:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.868580] [ip-0A0C046E:67485:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.868577] [ip-0A0C04CF:8879 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.869391] [ip-0A0C04C2:8005 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.869714] [ip-0A0C04B7:21355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.870486] [ip-0A0C04C4:82724:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.870239] [ip-0A0C0497:98002:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.870984] [ip-0A0C0443:28846:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.871644] [ip-0A0C0466:68147:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.871584] [ip-0A0C04C7:84993:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.871712] [ip-0A0C04C7:84998:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.872175] [ip-0A0C045F:63196:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.872469] [ip-0A0C04A1:68045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.872476] [ip-0A0C0486:65525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.871480] [ip-0A0C04B2:26481:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.873116] [ip-0A0C04AC:43871:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.873534] [ip-0A0C045F:63197:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.873544] [ip-0A0C0466:68150:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.872868] [ip-0A0C04BC:78549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.874303] [ip-0A0C0466:68149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.874314] [ip-0A0C04CD:80781:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.875225] [ip-0A0C0486:65527:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.874819] [ip-0A0C0493:46841:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.875253] [ip-0A0C048A:62130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.877405] [ip-0A0C04A0:39932:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.876936] [ip-0A0C0495:49530:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.876456] [ip-0A0C0497:97994:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.877588] [ip-0A0C0489:65753:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.878103] [ip-0A0C042D:36831:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.878677] [ip-0A0C04B7:21354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.878684] [ip-0A0C048C:46222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.879345] [ip-0A0C04B0:36900:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.879454] [ip-0A0C0485:30545:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.879447] [ip-0A0C0485:30572:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.879795] [ip-0A0C04A4:50476:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.879439] [ip-0A0C042D:36830:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.880334] [ip-0A0C040F:35459:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.881899] [ip-0A0C04A0:39933:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.878620] [ip-0A0C049C:37114:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.881029] [ip-0A0C04B0:36897:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.881291] [ip-0A0C04B7:21357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.881976] [ip-0A0C046C:60802:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.881508] [ip-0A0C04C6:78631:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.882712] [ip-0A0C04A1:68049:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.883111] [ip-0A0C04DA:77561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.882767] [ip-0A0C0494:46985:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.883324] [ip-0A0C04D3:82375:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.885926] [ip-0A0C04A2:41829:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.884607] [ip-0A0C04CF:8878 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.885635] [ip-0A0C0492:45438:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.886123] [ip-0A0C040F:35465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.884820] [ip-0A0C049B:39230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.887259] [ip-0A0C046E:67487:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.888912] [ip-0A0C04A0:39930:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.887787] [ip-0A0C04B7:21360:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.888463] [ip-0A0C04D9:6667 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.890133] [ip-0A0C0485:30550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.890490] [ip-0A0C04D4:80231:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.890504] [ip-0A0C04D4:80230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.890037] [ip-0A0C04A6:50107:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.891073] [ip-0A0C04DA:77566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.890859] [ip-0A0C0429:55922:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.891136] [ip-0A0C04A8:55501:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.892789] [ip-0A0C04AA:25129:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.892570] [ip-0A0C042D:36832:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.893303] [ip-0A0C04B4:60457:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.895102] [ip-0A0C04C3:81748:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.895534] [ip-0A0C0492:45441:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.896149] [ip-0A0C04C3:81747:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.896777] [ip-0A0C04BB:25418:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.897083] [ip-0A0C04A9:49549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.897117] [ip-0A0C0488:64077:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.897862] [ip-0A0C04BC:78554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.898669] [ip-0A0C04A4:50477:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.899687] [ip-0A0C04C9:83012:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.898841] [ip-0A0C044D:62615:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.899718] [ip-0A0C04A4:50479:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.899106] [ip-0A0C044D:62613:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.899478] [ip-0A0C0494:46979:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.899643] [ip-0A0C048F:54832:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.899238] [ip-0A0C04B2:26486:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.900488] [ip-0A0C046E:67491:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.899317] [ip-0A0C04B2:26479:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.900095] [ip-0A0C042D:36836:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.899925] [ip-0A0C0498:60327:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.900931] [ip-0A0C04C3:81741:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.901483] [ip-0A0C04C4:82720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.902627] [ip-0A0C04AC:43869:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.902354] [ip-0A0C04D8:83872:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.902481] [ip-0A0C046E:67490:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.902148] [ip-0A0C04B2:26485:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.900963] [ip-0A0C049C:37111:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.903948] [ip-0A0C04DA:77557:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.904833] [ip-0A0C04C4:82725:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.904058] [ip-0A0C049F:38222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.904646] [ip-0A0C04B5:51092:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.904557] [ip-0A0C04A6:50103:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.904606] [ip-0A0C049F:38218:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.904418] [ip-0A0C0488:64082:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.905039] [ip-0A0C04CF:8875 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.905959] [ip-0A0C0484:67478:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.909119] [ip-0A0C04A2:41824:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.908008] [ip-0A0C0435:5187 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.908713] [ip-0A0C04D4:80227:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.908663] [ip-0A0C04C4:82751:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.908470] [ip-0A0C0484:67476:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.909440] [ip-0A0C0473:63714:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.909782] [ip-0A0C04D4:80226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.909354] [ip-0A0C0498:60331:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.910667] [ip-0A0C0492:45442:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.910366] [ip-0A0C048C:46228:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.911285] [ip-0A0C04DB:76155:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.912216] [ip-0A0C0496:31968:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.912272] [ip-0A0C0492:45439:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.912379] [ip-0A0C0492:45451:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.912868] [ip-0A0C04C4:82719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.910672] [ip-0A0C049C:37110:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.914091] [ip-0A0C04C9:83008:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.915225] [ip-0A0C04D9:6670 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.914521] [ip-0A0C0494:46986:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.915307] [ip-0A0C046B:59748:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.914610] [ip-0A0C0494:46984:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.915208] [ip-0A0C04B6:19610:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.916978] [ip-0A0C04A7:27297:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.917308] [ip-0A0C048B:48220:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.917832] [ip-0A0C046B:59747:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.917489] [ip-0A0C04B9:83616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.918611] [ip-0A0C04D8:83869:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.918438] [ip-0A0C04B5:51090:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.919160] [ip-0A0C048D:51326:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.917188] [ip-0A0C049C:37113:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.919592] [ip-0A0C04D4:80228:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.919402] [ip-0A0C0429:55920:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.919920] [ip-0A0C0438:66262:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.919561] [ip-0A0C049F:38224:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.921112] [ip-0A0C048A:62143:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.921608] [ip-0A0C04AF:41988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.921874] [ip-0A0C04BC:78551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.922252] [ip-0A0C04D3:82374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.923262] [ip-0A0C0491:47340:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.924461] [ip-0A0C0491:47336:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.924217] [ip-0A0C04A9:49548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.924492] [ip-0A0C04C6:78632:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.926327] [ip-0A0C04A5:53064:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.925620] [ip-0A0C049F:38223:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.927169] [ip-0A0C0485:30549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.927327] [ip-0A0C04CF:8876 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.927980] [ip-0A0C048D:51320:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.927807] [ip-0A0C04CD:80779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.927867] [ip-0A0C04AE:55495:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.927566] [ip-0A0C04CF:8874 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.928460] [ip-0A0C04CD:80785:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.928149] [ip-0A0C0493:46842:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.929118] [ip-0A0C04CD:80784:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.929803] [ip-0A0C04B9:83615:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.930937] [ip-0A0C0496:31973:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.930153] [ip-0A0C04B9:83645:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.931070] [ip-0A0C0495:49532:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.931085] [ip-0A0C04C5:84722:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.930673] [ip-0A0C0449:62964:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.930654] [ip-0A0C04AF:41994:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.930551] [ip-0A0C049F:38220:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.931168] [ip-0A0C04C5:84725:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.930762] [ip-0A0C04CF:8902 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.930825] [ip-0A0C04A8:55500:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.930944] [ip-0A0C044D:62609:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.931266] [ip-0A0C04C6:78629:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.932626] [ip-0A0C048D:51323:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.932775] [ip-0A0C04B1:53514:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.932809] [ip-0A0C0473:63716:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.932601] [ip-0A0C04B6:19581:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.932828] [ip-0A0C04C6:78625:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.933802] [ip-0A0C040F:35463:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.934136] [ip-0A0C04D9:6668 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.933900] [ip-0A0C04C5:84750:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.934168] [ip-0A0C04BD:80621:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.934741] [ip-0A0C0489:65748:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.935074] [ip-0A0C04AA:25122:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.935262] [ip-0A0C04BA:17828:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.935363] [ip-0A0C0464:65561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.936242] [ip-0A0C04C9:83013:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.937482] [ip-0A0C04A6:50101:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.940683] [ip-0A0C04A2:41826:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.939881] [ip-0A0C048C:46226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.941185] [ip-0A0C04D9:6666 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.940838] [ip-0A0C0429:55918:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.942120] [ip-0A0C0435:5208 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.942262] [ip-0A0C04DB:76148:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.942192] [ip-0A0C0493:46845:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.942423] [ip-0A0C0493:46843:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.943421] [ip-0A0C046B:59745:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.943856] [ip-0A0C04A7:27295:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.945409] [ip-0A0C04A2:41823:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.944731] [ip-0A0C04BC:78550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.944923] [ip-0A0C048C:46242:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.944967] [ip-0A0C04BC:78553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.945765] [ip-0A0C04BA:17827:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.945758] [ip-0A0C0473:63717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.946032] [ip-0A0C048A:62135:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.946020] [ip-0A0C0461:29178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.948644] [ip-0A0C04A2:41825:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.947753] [ip-0A0C04D9:6669 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.947759] [ip-0A0C0464:65562:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.948988] [ip-0A0C048F:54834:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.949396] [ip-0A0C04AD:27331:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.950576] [ip-0A0C0472:67538:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.950887] [ip-0A0C0472:67548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.951144] [ip-0A0C04BD:80620:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.950509] [ip-0A0C0490:51522:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.950980] [ip-0A0C0449:62969:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.952474] [ip-0A0C04DB:76154:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.953054] [ip-0A0C0435:5184 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.953159] [ip-0A0C0491:47342:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.953579] [ip-0A0C0485:30548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.953166] [ip-0A0C04BC:78552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.953763] [ip-0A0C0435:5190 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.953458] [ip-0A0C04B5:51085:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.953740] [ip-0A0C0438:66264:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.954370] [ip-0A0C048D:51319:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.954809] [ip-0A0C04A5:53065:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.954801] [ip-0A0C0493:46840:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.955399] [ip-0A0C048D:51325:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.955505] [ip-0A0C04AA:25125:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.956889] [ip-0A0C04A8:55496:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.957601] [ip-0A0C04AE:55493:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.958842] [ip-0A0C04DB:76150:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.958230] [ip-0A0C049B:39224:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.960422] [ip-0A0C04AC:43866:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.960418] [ip-0A0C0464:65565:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.961318] [ip-0A0C04B4:60455:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.962181] [ip-0A0C040F:35461:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.963233] [ip-0A0C04AA:25128:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.963966] [ip-0A0C04AA:25127:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.965153] [ip-0A0C0472:67536:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.965282] [ip-0A0C04DB:76151:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.965735] [ip-0A0C0449:62962:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.966574] [ip-0A0C04C9:83014:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.965803] [ip-0A0C0449:62967:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.966720] [ip-0A0C04A1:68051:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.967169] [ip-0A0C0496:31966:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.966651] [ip-0A0C04A9:49550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.967385] [ip-0A0C04BA:17826:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.967312] [ip-0A0C0449:62968:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.968114] [ip-0A0C04D3:82380:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.968294] [ip-0A0C04D3:82379:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.968010] [ip-0A0C044D:62608:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.968595] [ip-0A0C04A6:50104:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.968491] [ip-0A0C0490:51518:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.969192] [ip-0A0C044D:62614:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.970099] [ip-0A0C04A6:50102:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.972458] [ip-0A0C04A7:27292:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.971966] [ip-0A0C04AD:27330:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.972616] [ip-0A0C04A7:27291:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.971911] [ip-0A0C048C:46229:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.974140] [ip-0A0C04B3:58190:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.974166] [ip-0A0C046C:60798:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.973962] [ip-0A0C0438:66268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.974365] [ip-0A0C04C9:83009:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.974719] [ip-0A0C0496:31971:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.974965] [ip-0A0C048C:46230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.975871] [ip-0A0C04B3:58185:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.976109] [ip-0A0C0496:31969:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.976052] [ip-0A0C04C9:83015:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.975635] [ip-0A0C04D3:82378:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.974898] [ip-0A0C049B:39229:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.975630] [ip-0A0C0498:60332:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.976319] [ip-0A0C048A:62131:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.976370] [ip-0A0C0441:58473:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.975259] [ip-0A0C049B:39223:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.976585] [ip-0A0C0489:65749:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.977320] [ip-0A0C0472:67535:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.975951] [ip-0A0C049B:39225:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.976475] [ip-0A0C0488:64081:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.977798] [ip-0A0C0464:65564:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.978875] [ip-0A0C04D8:83867:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.978407] [ip-0A0C04AF:41992:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.979634] [ip-0A0C048A:62132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.979877] [ip-0A0C048B:48245:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.980759] [ip-0A0C0441:58479:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.981224] [ip-0A0C0472:67537:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.981197] [ip-0A0C048A:62133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.980973] [ip-0A0C048F:54837:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.981528] [ip-0A0C0464:65566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.981113] [ip-0A0C0484:67479:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.983112] [ip-0A0C04AC:43865:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.983053] [ip-0A0C04B1:53508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.983553] [ip-0A0C0464:65563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.983652] [ip-0A0C0489:65754:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.983868] [ip-0A0C044D:62610:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.984569] [ip-0A0C0436:65856:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.984845] [ip-0A0C04B1:53515:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.984003] [ip-0A0C044D:62611:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.985076] [ip-0A0C04AB:40769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.985352] [ip-0A0C0473:63718:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.986835] [ip-0A0C04AB:40774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.986380] [ip-0A0C04A6:50105:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.987004] [ip-0A0C048F:54833:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.987696] [ip-0A0C04B4:60458:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.987482] [ip-0A0C04A9:49555:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.988534] [ip-0A0C0495:49531:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.988611] [ip-0A0C040F:35460:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.988803] [ip-0A0C048B:48223:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.989292] [ip-0A0C040F:35462:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.989799] [ip-0A0C0461:29171:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.990491] [ip-0A0C04A7:27305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.990563] [ip-0A0C04BD:80648:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.990732] [ip-0A0C040F:35464:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.990410] [ip-0A0C04A6:50108:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.991055] [ip-0A0C04A9:49553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.991874] [ip-0A0C0441:58472:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.991979] [ip-0A0C0489:65755:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.993665] [ip-0A0C04A7:27294:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.993281] [ip-0A0C0436:65852:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.993296] [ip-0A0C0438:66267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.994058] [ip-0A0C04AC:43870:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.995270] [ip-0A0C04BB:25419:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.995769] [ip-0A0C04AC:43867:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.995657] [ip-0A0C04C2:8007 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.995753] [ip-0A0C0438:66265:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.995071] [ip-0A0C0498:60328:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.996171] [ip-0A0C046B:59752:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.996619] [ip-0A0C04A9:49551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.997179] [ip-0A0C048F:54838:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.998066] [ip-0A0C0485:30547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.998394] [ip-0A0C04A5:53070:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.998174] [ip-0A0C04A8:55499:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.999254] [ip-0A0C0485:30552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.999119] [ip-0A0C046B:59750:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.998284] [ip-0A0C04A8:55498:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.998335] [ip-0A0C04A8:55495:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.999228] [ip-0A0C046B:59749:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624928.999132] [ip-0A0C04B6:19585:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.000121] [ip-0A0C0441:58476:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.001370] [ip-0A0C0438:66263:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.001775] [ip-0A0C0441:58477:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.003379] [ip-0A0C04BB:25413:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.003793] [ip-0A0C04C2:8009 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.004732] [ip-0A0C048F:54836:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.005535] [ip-0A0C0491:47343:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.005910] [ip-0A0C0489:65752:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.006335] [ip-0A0C0488:64085:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.008225] [ip-0A0C0484:67480:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.009276] [ip-0A0C0461:29172:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.013506] [ip-0A0C04B3:58184:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.015388] [ip-0A0C04B3:58186:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.018172] [ip-0A0C04BB:25416:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.017003] [ip-0A0C0490:51520:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.017114] [ip-0A0C0490:51516:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.018730] [ip-0A0C0485:30546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.019292] [ip-0A0C04B4:60456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.020330] [ip-0A0C04A1:68048:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.020239] [ip-0A0C0436:65854:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.020452] [ip-0A0C04B4:60459:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.020947] [ip-0A0C04BA:17821:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.021273] [ip-0A0C0436:65855:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.020597] [ip-0A0C0490:51521:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.021319] [ip-0A0C0436:65851:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.021999] [ip-0A0C04A5:53069:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.022550] [ip-0A0C04BD:80623:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.022687] [ip-0A0C0495:49534:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.022211] [ip-0A0C0429:55925:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.024703] [ip-0A0C046C:60801:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.024960] [ip-0A0C04B3:58188:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.024257] [ip-0A0C0490:51515:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.025297] [ip-0A0C048B:48221:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.026534] [ip-0A0C0491:47339:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.027623] [ip-0A0C04AE:55490:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.028362] [ip-0A0C048B:48225:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.029332] [ip-0A0C04BD:80618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.029404] [ip-0A0C04B3:58187:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.030782] [ip-0A0C04A1:68044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.031896] [ip-0A0C04BB:25414:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.033131] [ip-0A0C0495:49528:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.033475] [ip-0A0C04BB:25415:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.033396] [ip-0A0C0491:47341:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.033667] [ip-0A0C04A5:53067:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.033874] [ip-0A0C04A5:53063:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.033775] [ip-0A0C0491:47337:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.034006] [ip-0A0C04A5:53068:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.035941] [ip-0A0C04C2:8006 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.036560] [ip-0A0C04A1:68047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.037080] [ip-0A0C04A1:68046:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.037337] [ip-0A0C048B:48224:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.037169] [ip-0A0C0461:29175:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.037192] [ip-0A0C04B5:51087:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.037439] [ip-0A0C048B:48222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.037852] [ip-0A0C0495:49527:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.039318] [ip-0A0C04AB:40775:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.039702] [ip-0A0C04BA:17825:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.039264] [ip-0A0C0429:55924:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.041213] [ip-0A0C0473:63713:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.042573] [ip-0A0C04B4:60461:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.042492] [ip-0A0C0484:67473:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.044171] [ip-0A0C04B4:60466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.044859] [ip-0A0C046C:60804:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.045355] [ip-0A0C0495:49529:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.045139] [ip-0A0C0461:29173:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.047768] [ip-0A0C0473:63720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.048068] [ip-0A0C04BD:80624:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.047643] [ip-0A0C0484:67506:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.049349] [ip-0A0C046C:60803:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.049739] [ip-0A0C04BD:80619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.050138] [ip-0A0C0461:29177:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.050104] [ip-0A0C0484:67474:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.050069] [ip-0A0C0488:64083:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.052368] [ip-0A0C046C:60800:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.052258] [ip-0A0C0473:63719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.053302] [ip-0A0C0488:64079:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.053696] [ip-0A0C0488:64078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.060282] [ip-0A0C04B5:51089:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.061565] [ip-0A0C046C:60806:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.061588] [ip-0A0C0461:29174:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.062325] [ip-0A0C04BA:17823:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.061678] [ip-0A0C0498:60333:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.061751] [ip-0A0C0498:60330:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.061889] [ip-0A0C0498:60329:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.063394] [ip-0A0C04AB:40771:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.066464] [ip-0A0C04BA:17824:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.066965] [ip-0A0C04AE:55491:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.069198] [ip-0A0C04C2:8008 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.069366] [ip-0A0C04C2:8011 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.069347] [ip-0A0C04AF:41990:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.069703] [ip-0A0C04AF:41989:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.070522] [ip-0A0C04AF:41987:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.071400] [ip-0A0C04B5:51086:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.071628] [ip-0A0C04B5:51091:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.074331] [ip-0A0C04C2:8010 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.076974] [ip-0A0C04D8:83873:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.076580] [ip-0A0C04AF:41991:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.079333] [ip-0A0C04AB:40768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.078857] [ip-0A0C0429:55919:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.081537] [ip-0A0C04D8:83866:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.085712] [ip-0A0C04AB:40770:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.086870] [ip-0A0C0429:55923:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.088561] [ip-0A0C04AE:55489:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.090270] [ip-0A0C04AB:40772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.091126] [ip-0A0C04AD:27333:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.091896] [ip-0A0C0429:55921:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.094774] [ip-0A0C04C2:8004 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.094385] [ip-0A0C04B6:19583:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.097590] [ip-0A0C04B1:53506:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.101766] [ip-0A0C04D8:83871:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.105562] [ip-0A0C04D8:83868:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.108526] [ip-0A0C04D8:83874:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.109163] [ip-0A0C04B1:53512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.116262] [ip-0A0C04B6:19582:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.120358] [ip-0A0C04AD:27328:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.121477] [ip-0A0C04AD:27334:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.124283] [ip-0A0C04AE:55488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.126533] [ip-0A0C04B6:19580:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.131158] [ip-0A0C04AD:27332:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.133907] [ip-0A0C04AE:55494:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.135409] [ip-0A0C04AE:55492:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.136387] [ip-0A0C04B6:19587:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.137151] [ip-0A0C04B6:19584:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.143184] [ip-0A0C04B1:53507:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.146634] [ip-0A0C04B1:53511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.149576] [ip-0A0C04B1:53510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.150311] [ip-0A0C04AD:27329:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624929.150410] [ip-0A0C04AD:27336:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
:::MLLOG {"namespace": "", "time_ms": 1634624930067, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634624930108, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634624930108, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1634624930109, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634624930109, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1634624930109, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1634624930109, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "96xND96amsr_A100_v4", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:29:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[ip-0A0C0435:0:5184 - context.c:584] INFO job (ID: 867564248530176037) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:5184 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:5184 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:5190 - context.c:584] INFO job (ID: 867564315202680761) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:5190 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:5190 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:5185 - context.c:584] INFO job (ID: 867565036327184197) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:5185 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:5185 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:5191 - context.c:584] INFO job (ID: 867564895105176325) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:5191 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:5191 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:5187 - context.c:584] INFO job (ID: 867564898891874807) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:5187 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:5187 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:5188 - context.c:584] INFO job (ID: 867564181865289443) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:5188 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:5188 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:5186 - context.c:584] INFO job (ID: 867564892804245975) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:5186 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:5186 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:5208 - context.c:584] INFO job (ID: 867564252452349579) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:5208 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:5208 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625020041, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3032092177, "metadata": {"file": "main.py", "lineno": 72}}
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625020042, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 138}}
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625020042, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 139}}
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625020042, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1500, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 140}}
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625020042, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 142}}
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625020042, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 143}}
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625020042, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 144}}
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625020042, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 145}}
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625020042, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 146}}
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625020042, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 147}}
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625020043, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 148}}
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625020043, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 149}}
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:30:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625043980, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1634625044006, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625044012, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1634625044012, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 95}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634625046638, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 84, "metadata": {"file": "main.py", "lineno": 136}}
:::MLLOG {"namespace": "", "time_ms": 1634625046639, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1634625046639, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634625046639, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1, "epoch_count": 20}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634625048160, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2209.5580025261297, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625048161, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.02989933774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625048161, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2209.5580025261297, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634625048161, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625048161, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625048849, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4889.2717851932675, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625048849, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.04976556291390729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625048849, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4889.2717851932675, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625048849, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625048849, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625049516, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5038.417350087466, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625049517, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0696317880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625049517, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5038.417350087466, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634625049517, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625049517, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625050156, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5261.428099953557, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625050156, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.08949801324503312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625050157, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5261.428099953557, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 60}}
:::MLLOG {"namespace": "", "time_ms": 1634625050157, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625050157, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625050790, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5305.6497047096245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625050791, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.10936423841059603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625050791, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5305.6497047096245, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 80}}
:::MLLOG {"namespace": "", "time_ms": 1634625050791, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625050791, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625051409, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5439.060518778702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625051410, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.12923046357615892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625051410, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5439.060518778702, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 100}}
:::MLLOG {"namespace": "", "time_ms": 1634625051410, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625051410, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625052033, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5397.485428024841, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625052033, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.14909668874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625052033, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5397.485428024841, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634625052033, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625052034, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625052657, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5392.508055551835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625052657, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.16896291390728477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625052657, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5392.508055551835, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1634625052657, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625052658, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625053282, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5386.973525476855, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625053282, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.18882913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625053282, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5386.973525476855, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 160}}
:::MLLOG {"namespace": "", "time_ms": 1634625053282, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625053282, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625053903, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5416.040152802011, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625053903, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.20869536423841056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625053903, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5416.040152802011, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 180}}
:::MLLOG {"namespace": "", "time_ms": 1634625053904, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625053904, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625054523, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5426.8790613906085, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625054524, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.22856158940397348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625054524, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5426.8790613906085, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 200}}
:::MLLOG {"namespace": "", "time_ms": 1634625054524, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625054524, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625055135, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5502.468361374346, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625055135, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.24842781456953641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625055135, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5502.468361374346, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 220}}
:::MLLOG {"namespace": "", "time_ms": 1634625055135, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625055136, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625055754, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5430.561665784235, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625055755, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26829403973509935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625055755, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5430.561665784235, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 240}}
:::MLLOG {"namespace": "", "time_ms": 1634625055755, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625055755, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625056371, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5455.551102018221, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625056372, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.28816026490066227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625056372, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5455.551102018221, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 260}}
:::MLLOG {"namespace": "", "time_ms": 1634625056372, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625056372, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625056996, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5391.9056114553005, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625056996, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3080264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625056996, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5391.9056114553005, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1634625056996, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625056996, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625057615, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5433.95382732558, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625057615, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32789271523178803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625057615, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5433.95382732558, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 300}}
:::MLLOG {"namespace": "", "time_ms": 1634625057615, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625057616, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625058234, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5431.8991791364915, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625058235, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.347758940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625058235, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5431.8991791364915, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 320}}
:::MLLOG {"namespace": "", "time_ms": 1634625058235, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625058235, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625058853, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5443.562774054194, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625058853, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36762516556291386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625058853, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5443.562774054194, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 340}}
:::MLLOG {"namespace": "", "time_ms": 1634625058853, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625058854, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625059468, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5466.311411759686, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625059469, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3874913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625059469, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5466.311411759686, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 360}}
:::MLLOG {"namespace": "", "time_ms": 1634625059469, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625059469, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625060094, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5378.794616038149, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625060095, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.40735761589403974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625060095, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5378.794616038149, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 380}}
:::MLLOG {"namespace": "", "time_ms": 1634625060095, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625060095, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625060718, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5398.982500351494, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625060718, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625060718, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5398.982500351494, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 400}}
:::MLLOG {"namespace": "", "time_ms": 1634625060718, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625060719, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625061337, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5437.702691752962, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625061337, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.44709006622516556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625061337, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5437.702691752962, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1634625061338, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625061338, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625061956, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5431.520254801815, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625061957, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4669562913907285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625061957, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5431.520254801815, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 440}}
:::MLLOG {"namespace": "", "time_ms": 1634625061957, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625061957, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625062573, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5457.613117918209, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625062574, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4868225165562914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625062574, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5457.613117918209, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 460}}
:::MLLOG {"namespace": "", "time_ms": 1634625062574, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625062574, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625063184, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5512.605986593279, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625063184, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5066887417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625063185, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5512.605986593279, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 480}}
:::MLLOG {"namespace": "", "time_ms": 1634625063185, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625063185, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625063795, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5508.684262472839, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625063795, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5265549668874172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625063796, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5508.684262472839, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 500}}
:::MLLOG {"namespace": "", "time_ms": 1634625063796, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625063796, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625064410, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5470.601946812789, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625064411, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5464211920529801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625064411, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5470.601946812789, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 520}}
:::MLLOG {"namespace": "", "time_ms": 1634625064411, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625064411, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625065026, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5463.63695010297, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625065027, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.566287417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625065027, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5463.63695010297, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 540}}
:::MLLOG {"namespace": "", "time_ms": 1634625065027, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625065027, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625065650, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5394.194376631996, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625065650, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5861536423841059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625065650, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5394.194376631996, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1634625065650, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625065651, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625066264, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5481.51771038103, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625066264, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6060198675496689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625066264, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5481.51771038103, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634625066264, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625066264, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625066878, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5477.591111080017, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625066878, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6258860927152318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625066878, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5477.591111080017, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 600}}
:::MLLOG {"namespace": "", "time_ms": 1634625066879, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625066879, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625067491, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5487.575225649692, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625067491, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6457523178807947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625067492, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5487.575225649692, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 620}}
:::MLLOG {"namespace": "", "time_ms": 1634625067492, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625067492, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625068124, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5312.8423062177035, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625068125, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6656185430463576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625068125, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5312.8423062177035, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 640}}
:::MLLOG {"namespace": "", "time_ms": 1634625068125, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625068125, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625068741, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5455.365259127559, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625068742, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6854847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625068742, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5455.365259127559, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 660}}
:::MLLOG {"namespace": "", "time_ms": 1634625068742, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625068742, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625069365, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5395.18767344648, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625069365, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7053509933774835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625069365, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5395.18767344648, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 680}}
:::MLLOG {"namespace": "", "time_ms": 1634625069366, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625069366, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625069981, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5459.723226153622, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625069982, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7252172185430463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625069982, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5459.723226153622, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 700}}
:::MLLOG {"namespace": "", "time_ms": 1634625069982, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625069982, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625070595, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5479.294858012435, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625070596, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7450834437086092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625070596, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5479.294858012435, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 720}}
:::MLLOG {"namespace": "", "time_ms": 1634625070596, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625070596, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625071205, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5519.019889501032, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625071205, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7649496688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625071205, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5519.019889501032, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 740}}
:::MLLOG {"namespace": "", "time_ms": 1634625071205, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625071206, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625071822, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5452.8913763917235, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625071822, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7848158940397352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625071822, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5452.8913763917235, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 760}}
:::MLLOG {"namespace": "", "time_ms": 1634625071823, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625071823, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625072439, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5455.967182574802, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625072439, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8046821192052981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625072439, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5455.967182574802, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634625072439, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625072439, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625073048, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5522.376341911851, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625073048, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8245483443708609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625073048, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5522.376341911851, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 800}}
:::MLLOG {"namespace": "", "time_ms": 1634625073049, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625073049, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625073659, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5509.00080995969, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625073659, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625073659, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5509.00080995969, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 820}}
:::MLLOG {"namespace": "", "time_ms": 1634625073659, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625073659, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625074271, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5497.492864267583, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625074271, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8642807947019867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625074271, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5497.492864267583, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 840}}
:::MLLOG {"namespace": "", "time_ms": 1634625074271, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625074271, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625074883, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5497.231245238683, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625074883, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8841470198675497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625074883, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5497.231245238683, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 860}}
:::MLLOG {"namespace": "", "time_ms": 1634625074883, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625074883, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625075490, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5541.585476050977, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625075490, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9040132450331126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625075490, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5541.585476050977, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 880}}
:::MLLOG {"namespace": "", "time_ms": 1634625075490, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625075491, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625076102, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5499.221891277992, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625076102, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9238794701986754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625076102, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5499.221891277992, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 900}}
:::MLLOG {"namespace": "", "time_ms": 1634625076102, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625076102, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625076715, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5488.795603935084, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625076715, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9437456953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625076715, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5488.795603935084, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 920}}
:::MLLOG {"namespace": "", "time_ms": 1634625076715, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625076715, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625077329, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5475.643749009222, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625077329, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9636119205298014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625077329, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5475.643749009222, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 940}}
:::MLLOG {"namespace": "", "time_ms": 1634625077330, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625077330, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625077940, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5509.942053747192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625077940, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9834781456953643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625077940, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5509.942053747192, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 960}}
:::MLLOG {"namespace": "", "time_ms": 1634625077940, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625077940, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625078550, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5510.166104227735, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625078551, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0033443708609273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625078551, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5510.166104227735, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 980}}
:::MLLOG {"namespace": "", "time_ms": 1634625078621, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625078621, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625078639, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634625079068, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8865652084350586, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634625079068, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634625079218, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5628.180010878673, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625079219, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0232105960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625079219, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5628.180010878673, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634625079318, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625079318, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625079332, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625079820, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8669291734695435, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625079820, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625080053, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4576.411178983827, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625080053, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.043076821192053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625080053, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4576.411178983827, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625080097, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625080097, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625080112, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625080533, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8220592737197876, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625080533, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625080715, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5438.342695751197, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625080715, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.062943046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625080716, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5438.342695751197, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625080753, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625080754, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625080768, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625081191, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8870089650154114, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625081191, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625081376, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5402.182069087125, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625081376, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0828092715231787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625081376, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5402.182069087125, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625081412, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625081412, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625081427, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625081849, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8891701698303223, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625081850, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625082035, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5399.298976908412, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625082035, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1026754966887418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625082035, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5399.298976908412, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625082071, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625082071, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625082085, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625082504, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8730039596557617, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625082504, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625082686, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5465.675407127593, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625082687, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1225417218543046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625082687, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5465.675407127593, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625082730, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625082730, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625082745, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625083158, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8719033002853394, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625083158, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625083341, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5502.375981558875, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625083342, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1424079470198676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625083342, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5502.375981558875, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625083378, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625083378, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625083392, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625083816, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8933064937591553, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625083816, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625084002, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5382.543795423895, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625084003, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1622741721854304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625084003, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5382.543795423895, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625084038, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625084038, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625084053, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625084477, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8873904347419739, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625084477, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625084660, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5405.192625883967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625084661, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1821403973509934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625084661, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5405.192625883967, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625084697, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625084697, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625084713, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625085129, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8734784126281738, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625085129, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625085310, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5486.105508037128, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625085311, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2020066225165562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625085311, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5486.105508037128, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625085346, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625085346, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625085361, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625085785, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8391572833061218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625085786, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625085973, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5359.162664906247, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625085973, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2218728476821192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625085974, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5359.162664906247, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625086028, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625086029, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625086043, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625086458, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8985805511474609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625086458, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625086641, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5487.5389004644185, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625086642, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.241739072847682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625086642, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5487.5389004644185, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625086677, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625086677, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625086692, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625087110, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8727987408638, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625087110, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625087293, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5458.264159654151, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625087293, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625087293, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5458.264159654151, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625087329, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625087329, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625087343, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625087767, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8889588117599487, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625087768, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625087947, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5439.367015567172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625087947, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.281471523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625087948, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5439.367015567172, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625087983, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625087983, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625087998, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625088420, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8916553854942322, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625088420, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625088601, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5438.185303751085, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625088601, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3013377483443709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625088602, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5438.185303751085, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625088638, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625088638, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625088654, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625089076, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8960622549057007, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625089076, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625089257, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5428.469852109047, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625089258, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3212039735099337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625089258, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5428.469852109047, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625089293, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625089293, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625089307, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625089725, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8862497806549072, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625089725, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625089918, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5378.64681029712, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625089919, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3410701986754967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625089919, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5378.64681029712, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625089955, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625089956, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625089971, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625090392, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8760702013969421, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625090392, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625090578, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5406.793543857495, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625090578, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3609364238410595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625090578, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5406.793543857495, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625090613, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625090614, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625090628, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625091051, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8871647119522095, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625091051, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625091233, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5426.321146804357, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625091233, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3808026490066225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625091234, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5426.321146804357, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625091270, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625091271, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625091284, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625091709, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8740711212158203, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625091709, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625091890, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5427.154926713626, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625091890, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4006688741721853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625091890, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5427.154926713626, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625091927, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625091927, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625091942, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625092363, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3773888945579529, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625092363, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625092554, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5357.286365034249, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625092555, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4205350993377484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625092555, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5357.286365034249, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625092590, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625092591, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625092606, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625093028, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7638296484947205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625093028, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625093212, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5411.88877658545, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625093212, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4404013245033112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625093212, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5411.88877658545, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625093247, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625093247, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625093261, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625093685, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.870498538017273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625093685, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625093871, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5390.9877619970075, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625093871, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4602675496688742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625093871, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5390.9877619970075, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625093907, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625093907, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625093923, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625094343, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8687376976013184, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625094344, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625094543, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5289.600871987623, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625094543, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4801337748344372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625094543, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5289.600871987623, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625094622, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625094622, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625094636, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625095036, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8877345323562622, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625095037, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625095221, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5614.732808521506, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625095221, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625095221, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5614.732808521506, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625095256, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625095257, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625095272, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625095694, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8804421424865723, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625095694, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625095880, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5396.272250795683, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625095880, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625095880, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5396.272250795683, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625095919, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625095920, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625095934, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625096357, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8770955801010132, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625096357, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625096545, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5378.546224924137, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625096545, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625096545, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5378.546224924137, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625096581, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625096582, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625096597, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625097018, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8646961450576782, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625097018, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625097243, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5079.282874470595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625097244, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625097244, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5079.282874470595, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625097278, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625097279, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625097294, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625097711, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8846688866615295, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625097711, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625097926, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5188.963426892446, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625097927, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625097927, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5188.963426892446, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625097963, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625097963, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625097978, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625098398, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8793462514877319, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625098398, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625098603, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5251.893014313627, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625098604, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625098604, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5251.893014313627, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625098641, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625098641, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625098656, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625099078, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8866667747497559, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625099078, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625099261, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5422.70062611972, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625099261, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625099262, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5422.70062611972, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625099297, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625099297, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625099312, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625099734, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.890494704246521, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625099734, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625099928, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5325.337542355044, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625099929, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625099929, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5325.337542355044, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625099965, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625099966, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625099980, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625100403, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8930354118347168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625100403, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625100590, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5382.210780185723, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625100591, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625100591, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5382.210780185723, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625100626, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625100627, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625100641, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625101064, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8942931890487671, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625101064, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625101247, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5416.633429101286, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625101248, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625101248, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5416.633429101286, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625101283, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625101284, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625101299, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625101722, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8976545333862305, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625101722, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625101915, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5326.351940284405, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625101915, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625101915, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5326.351940284405, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625101951, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625101952, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625101967, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625102390, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8855452537536621, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625102390, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625102574, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5399.2307141207, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625102574, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625102575, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5399.2307141207, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625102610, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625102610, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625102623, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625103041, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.882194459438324, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625103041, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625103227, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5453.326043070594, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625103227, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625103227, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5453.326043070594, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625103263, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625103263, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625103278, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625103698, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8916064500808716, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625103698, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625103879, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5458.105612457911, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625103880, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625103880, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5458.105612457911, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625103915, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625103916, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625103930, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625104346, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8923676013946533, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625104347, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625104527, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5494.228699079543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625104528, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625104528, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5494.228699079543, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625104563, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625104563, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625104578, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625104996, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9016796946525574, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625104996, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625105179, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5455.306129953924, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625105180, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625105180, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5455.306129953924, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625105223, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625105224, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625105238, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625105657, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9052282571792603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625105657, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625105840, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5451.366371163834, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625105841, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625105841, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5451.366371163834, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625105880, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625105881, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625105895, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625106309, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8770332336425781, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625106309, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625106491, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5507.493766736021, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625106492, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625106492, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5507.493766736021, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625106528, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625106528, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625106543, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625106955, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8953585028648376, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625106955, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625107138, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5512.483078665819, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625107138, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625107138, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5512.483078665819, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625107174, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625107175, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625107189, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625107608, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.886993944644928, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625107608, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625107794, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5428.331849094511, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625107794, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625107795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5428.331849094511, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625107830, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625107831, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625107845, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625108258, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9010109901428223, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625108258, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625108441, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5511.034471970994, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625108441, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625108441, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5511.034471970994, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625108476, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625108477, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625108492, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625108907, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.888319194316864, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625108907, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625109088, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5501.05722201881, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625109088, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625109088, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5501.05722201881, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625109123, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625109124, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625109138, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625109556, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8830982446670532, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625109556, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625109738, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5472.90701481113, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625109738, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625109738, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5472.90701481113, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625109774, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625109775, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625109789, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625110208, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8912919759750366, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625110208, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625110394, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5426.352487279154, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625110394, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625110395, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5426.352487279154, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625110430, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625110430, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625110445, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625110866, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8894757032394409, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625110866, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625111051, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5419.316243457475, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625111051, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625111051, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5419.316243457475, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625111086, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625111087, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625111102, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625111520, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.893389105796814, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625111521, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625111697, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5504.849823111065, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625111698, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625111698, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5504.849823111065, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625111734, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625111734, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625111749, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625112166, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.883519172668457, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625112166, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625112353, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5428.879720606216, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625112354, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625112354, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5428.879720606216, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625112389, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625112389, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625112403, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625112823, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8862138986587524, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625112823, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625113001, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5493.577616014133, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625113002, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625113002, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5493.577616014133, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625113036, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625113037, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625113051, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625113471, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.893984854221344, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625113471, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625113656, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5427.836350646375, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625113656, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625113656, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5427.836350646375, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625113691, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625113692, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625113705, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625114125, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8981174230575562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625114125, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625114308, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5455.599676679086, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625114308, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625114308, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5455.599676679086, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625114344, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625114344, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625114359, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625114778, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9062035083770752, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625114778, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625114959, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5466.2902092206, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625114959, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625114959, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5466.2902092206, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625114996, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625114997, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625115010, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625115431, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9013654589653015, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625115431, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625115615, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5434.178026702656, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625115616, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625115616, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5434.178026702656, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625115651, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625115651, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625115666, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625116102, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8915004134178162, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625116102, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625116306, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5133.0334657549765, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625116306, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625116306, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5133.0334657549765, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625116341, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625116342, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625116356, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625116774, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9058526754379272, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625116774, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625116955, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5478.721854845294, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625116955, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625116955, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5478.721854845294, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625116990, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625116991, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625117004, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625117425, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8989088535308838, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625117425, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625117620, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5346.33597687392, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625117620, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625117620, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5346.33597687392, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625117656, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625117656, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625117670, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625118079, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9013755321502686, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625118079, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625118262, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5546.97079988869, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625118262, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625118263, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5546.97079988869, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625118299, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625118299, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625118316, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625118729, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8916085958480835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625118729, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625118906, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5541.783777470793, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625118906, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625118906, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5541.783777470793, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625118941, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625118942, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625118957, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625119373, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9003419876098633, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625119374, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625119557, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5465.811075696778, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625119557, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625119557, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5465.811075696778, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625119593, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625119593, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625119608, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625120027, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8907668590545654, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625120028, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625120211, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5440.595448586196, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625120211, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625120211, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5440.595448586196, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625120246, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625120247, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625120261, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625120676, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9011739492416382, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625120677, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625120860, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5476.473602850141, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625120861, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625120861, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5476.473602850141, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625120896, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625120897, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625120913, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625121327, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.904995858669281, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625121327, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625121515, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5440.116608712301, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625121515, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625121515, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5440.116608712301, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625121550, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625121551, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625121566, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625121985, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9058711528778076, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625121985, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625122166, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5458.782144691492, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625122167, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625122167, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5458.782144691492, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625122202, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625122203, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625122216, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625122639, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8986412286758423, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625122639, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625122830, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5352.423479493063, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625122831, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625122831, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5352.423479493063, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625122867, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625122868, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625122882, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625123301, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9011996984481812, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625123301, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625123475, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5532.289977596616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625123476, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625123476, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5532.289977596616, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625123512, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625123513, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625123527, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625123949, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8910698890686035, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625123949, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625124130, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5446.708054273599, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625124130, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625124130, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5446.708054273599, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625124166, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625124166, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625124181, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625124608, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9023334980010986, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625124608, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625124796, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5334.305390377489, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625124797, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625124797, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5334.305390377489, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625124833, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625124833, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625124848, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634625125268, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8892916440963745, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634625125269, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634625125449, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5457.655388640545, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625125449, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625125450, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5457.655388640545, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634625125485, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625125485, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625125500, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634625125920, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.897818386554718, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634625125920, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634625126099, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5471.22423000099, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625126100, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625126100, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5471.22423000099, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634625126136, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625126136, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625126152, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634625126572, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9011168479919434, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634625126572, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634625126762, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5371.639477231008, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625126762, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625126762, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5371.639477231008, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634625126798, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625126798, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625126814, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634625127231, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8955814242362976, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634625127231, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634625127410, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5494.7942385387205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625127410, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625127411, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5494.7942385387205, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634625127446, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625127446, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625127461, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634625127880, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8957664966583252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634625127881, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634625128065, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5426.446510875718, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625128066, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625128066, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5426.446510875718, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634625128101, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625128102, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625128117, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2500}}
:::MLLOG {"namespace": "", "time_ms": 1634625128536, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8969593048095703, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2500}}
:::MLLOG {"namespace": "", "time_ms": 1634625128536, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2500}}
:::MLLOG {"namespace": "", "time_ms": 1634625128713, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5497.951829931264, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625128714, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625128714, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5497.951829931264, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2500}}
:::MLLOG {"namespace": "", "time_ms": 1634625128750, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625128750, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625128765, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1634625129188, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.900439977645874, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1634625129189, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1634625129373, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5398.078781392705, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625129373, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625129373, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5398.078781392705, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1634625129409, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625129409, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625129423, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2540}}
:::MLLOG {"namespace": "", "time_ms": 1634625129849, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9043539762496948, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2540}}
:::MLLOG {"namespace": "", "time_ms": 1634625129849, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2540}}
:::MLLOG {"namespace": "", "time_ms": 1634625130033, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5391.2476157467445, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625130033, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625130033, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5391.2476157467445, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2540}}
:::MLLOG {"namespace": "", "time_ms": 1634625130068, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625130069, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625130083, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2560}}
:::MLLOG {"namespace": "", "time_ms": 1634625130504, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8998885154724121, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2560}}
:::MLLOG {"namespace": "", "time_ms": 1634625130504, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2560}}
:::MLLOG {"namespace": "", "time_ms": 1634625130692, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5387.692268874216, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625130693, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625130693, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5387.692268874216, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2560}}
:::MLLOG {"namespace": "", "time_ms": 1634625130728, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625130728, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625130743, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2580}}
:::MLLOG {"namespace": "", "time_ms": 1634625131161, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9016305804252625, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2580}}
:::MLLOG {"namespace": "", "time_ms": 1634625131162, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2580}}
:::MLLOG {"namespace": "", "time_ms": 1634625131335, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5530.902574624552, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625131336, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625131336, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5530.902574624552, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2580}}
:::MLLOG {"namespace": "", "time_ms": 1634625131375, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625131375, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625131390, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2600}}
:::MLLOG {"namespace": "", "time_ms": 1634625131808, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9057559967041016, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2600}}
:::MLLOG {"namespace": "", "time_ms": 1634625131808, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2600}}
:::MLLOG {"namespace": "", "time_ms": 1634625131993, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5439.927616174265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625131993, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625131994, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5439.927616174265, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2600}}
:::MLLOG {"namespace": "", "time_ms": 1634625132029, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625132029, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625132044, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2620}}
:::MLLOG {"namespace": "", "time_ms": 1634625132465, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8940742015838623, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2620}}
:::MLLOG {"namespace": "", "time_ms": 1634625132466, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2620}}
:::MLLOG {"namespace": "", "time_ms": 1634625132651, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5402.784740634646, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625132651, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625132651, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5402.784740634646, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2620}}
:::MLLOG {"namespace": "", "time_ms": 1634625132687, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625132688, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625132703, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2640}}
:::MLLOG {"namespace": "", "time_ms": 1634625133125, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9014557003974915, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2640}}
:::MLLOG {"namespace": "", "time_ms": 1634625133125, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2640}}
:::MLLOG {"namespace": "", "time_ms": 1634625133305, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5438.838015354555, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625133306, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625133306, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5438.838015354555, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2640}}
:::MLLOG {"namespace": "", "time_ms": 1634625133342, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625133342, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625133356, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1634625133780, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9017530679702759, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1634625133781, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1634625133959, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5447.337546528752, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625133959, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625133960, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5447.337546528752, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1634625133994, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625133995, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625134009, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2680}}
:::MLLOG {"namespace": "", "time_ms": 1634625134433, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9036852717399597, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2680}}
:::MLLOG {"namespace": "", "time_ms": 1634625134433, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2680}}
:::MLLOG {"namespace": "", "time_ms": 1634625134625, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5334.74155037222, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625134625, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625134625, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5334.74155037222, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2680}}
:::MLLOG {"namespace": "", "time_ms": 1634625134661, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625134662, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625134677, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2700}}
:::MLLOG {"namespace": "", "time_ms": 1634625135100, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9066847562789917, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2700}}
:::MLLOG {"namespace": "", "time_ms": 1634625135100, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2700}}
:::MLLOG {"namespace": "", "time_ms": 1634625135284, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5402.942161535489, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625135284, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625135284, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5402.942161535489, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2700}}
:::MLLOG {"namespace": "", "time_ms": 1634625135319, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625135320, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625135336, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2720}}
:::MLLOG {"namespace": "", "time_ms": 1634625135756, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8993933200836182, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2720}}
:::MLLOG {"namespace": "", "time_ms": 1634625135757, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2720}}
:::MLLOG {"namespace": "", "time_ms": 1634625135939, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5431.6102707121445, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625135939, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625135939, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5431.6102707121445, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2720}}
:::MLLOG {"namespace": "", "time_ms": 1634625135975, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625135976, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625135990, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2740}}
:::MLLOG {"namespace": "", "time_ms": 1634625136413, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9012743234634399, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2740}}
:::MLLOG {"namespace": "", "time_ms": 1634625136413, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2740}}
:::MLLOG {"namespace": "", "time_ms": 1634625136593, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5444.401861306043, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625136594, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625136594, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5444.401861306043, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2740}}
:::MLLOG {"namespace": "", "time_ms": 1634625136629, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625136629, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625136645, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2760}}
:::MLLOG {"namespace": "", "time_ms": 1634625137067, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9047232270240784, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2760}}
:::MLLOG {"namespace": "", "time_ms": 1634625137067, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2760}}
:::MLLOG {"namespace": "", "time_ms": 1634625137257, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5350.96023969257, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625137258, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625137258, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5350.96023969257, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2760}}
:::MLLOG {"namespace": "", "time_ms": 1634625137294, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625137294, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625137310, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2780}}
:::MLLOG {"namespace": "", "time_ms": 1634625137732, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9021536707878113, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2780}}
:::MLLOG {"namespace": "", "time_ms": 1634625137732, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2780}}
:::MLLOG {"namespace": "", "time_ms": 1634625137908, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5481.385524923766, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625137908, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625137908, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5481.385524923766, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2780}}
:::MLLOG {"namespace": "", "time_ms": 1634625137943, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625137944, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625137962, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2800}}
:::MLLOG {"namespace": "", "time_ms": 1634625138379, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9058407545089722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2800}}
:::MLLOG {"namespace": "", "time_ms": 1634625138379, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2800}}
:::MLLOG {"namespace": "", "time_ms": 1634625138556, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5490.735219518581, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625138556, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625138556, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5490.735219518581, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2800}}
:::MLLOG {"namespace": "", "time_ms": 1634625138591, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625138592, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625138605, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2820}}
:::MLLOG {"namespace": "", "time_ms": 1634625139030, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9062169790267944, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2820}}
:::MLLOG {"namespace": "", "time_ms": 1634625139030, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2820}}
:::MLLOG {"namespace": "", "time_ms": 1634625139210, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5429.720562942689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625139211, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625139211, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5429.720562942689, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2820}}
:::MLLOG {"namespace": "", "time_ms": 1634625139247, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625139247, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625139261, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2840}}
:::MLLOG {"namespace": "", "time_ms": 1634625139687, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9000831246376038, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2840}}
:::MLLOG {"namespace": "", "time_ms": 1634625139688, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2840}}
:::MLLOG {"namespace": "", "time_ms": 1634625139874, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5359.032238928563, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625139875, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625139875, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5359.032238928563, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2840}}
:::MLLOG {"namespace": "", "time_ms": 1634625139910, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625139910, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625139925, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2860}}
:::MLLOG {"namespace": "", "time_ms": 1634625140350, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9006221890449524, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2860}}
:::MLLOG {"namespace": "", "time_ms": 1634625140351, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2860}}
:::MLLOG {"namespace": "", "time_ms": 1634625140536, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5373.214432367863, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625140536, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625140536, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5373.214432367863, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2860}}
:::MLLOG {"namespace": "", "time_ms": 1634625140571, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625140571, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625140586, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2880}}
:::MLLOG {"namespace": "", "time_ms": 1634625141012, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8863779902458191, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2880}}
:::MLLOG {"namespace": "", "time_ms": 1634625141012, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2880}}
:::MLLOG {"namespace": "", "time_ms": 1634625141192, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5416.09635235218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625141193, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625141193, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5416.09635235218, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2880}}
:::MLLOG {"namespace": "", "time_ms": 1634625141228, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625141229, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625141242, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2900}}
:::MLLOG {"namespace": "", "time_ms": 1634625141666, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.898614227771759, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2900}}
:::MLLOG {"namespace": "", "time_ms": 1634625141666, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2900}}
:::MLLOG {"namespace": "", "time_ms": 1634625141843, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5473.7041490720285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625141843, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625141843, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5473.7041490720285, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2900}}
:::MLLOG {"namespace": "", "time_ms": 1634625141880, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625141881, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625141894, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2920}}
:::MLLOG {"namespace": "", "time_ms": 1634625142319, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9025533199310303, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2920}}
:::MLLOG {"namespace": "", "time_ms": 1634625142320, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2920}}
:::MLLOG {"namespace": "", "time_ms": 1634625142505, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5382.854235625656, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625142506, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625142506, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5382.854235625656, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2920}}
:::MLLOG {"namespace": "", "time_ms": 1634625142541, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625142542, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625142556, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2940}}
:::MLLOG {"namespace": "", "time_ms": 1634625142981, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9067151546478271, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2940}}
:::MLLOG {"namespace": "", "time_ms": 1634625142981, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2940}}
:::MLLOG {"namespace": "", "time_ms": 1634625143162, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5418.916152281769, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625143162, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625143162, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5418.916152281769, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2940}}
:::MLLOG {"namespace": "", "time_ms": 1634625143198, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625143198, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625143213, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2960}}
:::MLLOG {"namespace": "", "time_ms": 1634625143633, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.90165114402771, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2960}}
:::MLLOG {"namespace": "", "time_ms": 1634625143634, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2960}}
:::MLLOG {"namespace": "", "time_ms": 1634625143818, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5428.175036003949, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625143818, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625143818, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5428.175036003949, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2960}}
:::MLLOG {"namespace": "", "time_ms": 1634625143853, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625143853, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625143868, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2980}}
:::MLLOG {"namespace": "", "time_ms": 1634625144283, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9044530391693115, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2980}}
:::MLLOG {"namespace": "", "time_ms": 1634625144283, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2980}}
:::MLLOG {"namespace": "", "time_ms": 1634625144462, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5523.218257643244, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625144462, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625144462, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5523.218257643244, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2980}}
:::MLLOG {"namespace": "", "time_ms": 1634625144499, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 3000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625144499, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 3000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625144514, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 3000}}
:::MLLOG {"namespace": "", "time_ms": 1634625144930, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8967165946960449, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 3000}}
:::MLLOG {"namespace": "", "time_ms": 1634625144930, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 3000}}
:::MLLOG {"namespace": "", "time_ms": 1634625145115, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5458.371977009001, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625145115, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625145115, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5458.371977009001, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 3000}}
:::MLLOG {"namespace": "", "time_ms": 1634625145152, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 3020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625145152, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 3020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625145167, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 3020}}
:::MLLOG {"namespace": "", "time_ms": 1634625145588, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8952561616897583, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 3020}}
:::MLLOG {"namespace": "", "time_ms": 1634625145588, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 3020}}
:::MLLOG {"namespace": "", "time_ms": 1634625145770, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5444.910907430968, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625145770, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625145770, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5444.910907430968, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 3020}}
:::MLLOG {"namespace": "", "time_ms": 1634625145806, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 3040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625145806, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 3040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625145821, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 3040}}
:::MLLOG {"namespace": "", "time_ms": 1634625146240, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9078149795532227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 3040}}
:::MLLOG {"namespace": "", "time_ms": 1634625146241, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 3040}}
:::MLLOG {"namespace": "", "time_ms": 1634625146417, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5502.232047097977, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625146418, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625146418, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5502.232047097977, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 3040}}
:::MLLOG {"namespace": "", "time_ms": 1634625146452, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 3060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625146452, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 3060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625146467, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 3060}}
:::MLLOG {"namespace": "", "time_ms": 1634625146886, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.909378170967102, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 3060}}
:::MLLOG {"namespace": "", "time_ms": 1634625146886, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 3060}}
:::MLLOG {"namespace": "", "time_ms": 1634625146886, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 165, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1634625147062, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5511.754368811291, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625147063, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625147063, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5511.754368811291, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 3060}}
ENDING TIMING RUN AT 2021-10-19 06:32:33 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:33 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:33 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:33 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:33 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:33 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:33 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:33 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:33 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:33 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:33 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:33 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:34 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:36 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:37 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:38 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:39 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:39 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:39 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:40 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:41 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:42 AM
RESULT,image_segmentation,,239,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:43 AM
RESULT,image_segmentation,,240,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:44 AM
RESULT,image_segmentation,,241,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:45 AM
RESULT,image_segmentation,,242,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
ENDING TIMING RUN AT 2021-10-19 06:32:46 AM
RESULT,image_segmentation,,243,nvidia,2021-10-19 06:28:43 AM
