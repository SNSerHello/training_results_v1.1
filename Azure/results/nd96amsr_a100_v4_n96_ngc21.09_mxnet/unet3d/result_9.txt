+ : DGXA100_96x8x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019060826242307828
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data
+ : /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ LOGBASE=unet3d_96x8x1_211019060826242307828
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019060826242307828
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019060826242307828
+ readonly _cont_name=image_segmentation
+ _cont_name=image_segmentation
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07368/slurm_script: line 39: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ srun --ntasks=96 mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ srun --ntasks=96 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh --container-name=image_segmentation true
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019060826242307828_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=96 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C041F
Clearing cache on ip-0A0C0411
Clearing cache on ip-0A0C0418
Clearing cache on ip-0A0C0420
Clearing cache on ip-0A0C0410
Clearing cache on ip-0A0C0439
Clearing cache on ip-0A0C0423
Clearing cache on ip-0A0C0413
Clearing cache on ip-0A0C0427
Clearing cache on ip-0A0C043A
Clearing cache on ip-0A0C0412
Clearing cache on ip-0A0C0416
Clearing cache on ip-0A0C045C
Clearing cache on ip-0A0C041E
Clearing cache on ip-0A0C045A
Clearing cache on ip-0A0C041C
Clearing cache on ip-0A0C0421
Clearing cache on ip-0A0C0408
Clearing cache on ip-0A0C042E
Clearing cache on ip-0A0C0431
Clearing cache on ip-0A0C0409
Clearing cache on ip-0A0C040C
Clearing cache on ip-0A0C0414
Clearing cache on ip-0A0C040B
Clearing cache on ip-0A0C040A
Clearing cache on ip-0A0C0459
Clearing cache on ip-0A0C042B
Clearing cache on ip-0A0C0447
Clearing cache on ip-0A0C041A
Clearing cache on ip-0A0C043B
Clearing cache on ip-0A0C041B
Clearing cache on ip-0A0C0417
Clearing cache on ip-0A0C0425
Clearing cache on ip-0A0C042A
Clearing cache on ip-0A0C0434
Clearing cache on ip-0A0C043F
Clearing cache on ip-0A0C0428
Clearing cache on ip-0A0C0433
Clearing cache on ip-0A0C0426
Clearing cache on ip-0A0C046D
Clearing cache on ip-0A0C0407
Clearing cache on ip-0A0C047A
Clearing cache on ip-0A0C0471
Clearing cache on ip-0A0C0456
Clearing cache on ip-0A0C045E
Clearing cache on ip-0A0C043E
Clearing cache on ip-0A0C0452
Clearing cache on ip-0A0C0430
Clearing cache on ip-0A0C0457
Clearing cache on ip-0A0C0455
Clearing cache on ip-0A0C0518
Clearing cache on ip-0A0C045B
Clearing cache on ip-0A0C0467
Clearing cache on ip-0A0C0453
Clearing cache on ip-0A0C0480
Clearing cache on ip-0A0C0445
Clearing cache on ip-0A0C0424
Clearing cache on ip-0A0C0470
Clearing cache on ip-0A0C044A
Clearing cache on ip-0A0C0440
Clearing cache on ip-0A0C0454
Clearing cache on ip-0A0C043C
Clearing cache on ip-0A0C0446
Clearing cache on ip-0A0C0465
Clearing cache on ip-0A0C042F
Clearing cache on ip-0A0C045D
Clearing cache on ip-0A0C0474
Clearing cache on ip-0A0C041D
Clearing cache on ip-0A0C0479
Clearing cache on ip-0A0C0481
Clearing cache on ip-0A0C0469
Clearing cache on ip-0A0C0458
Clearing cache on ip-0A0C040E
Clearing cache on ip-0A0C047C
Clearing cache on ip-0A0C0442
Clearing cache on ip-0A0C044B
Clearing cache on ip-0A0C0448
Clearing cache on ip-0A0C044E
Clearing cache on ip-0A0C0475
Clearing cache on ip-0A0C047D
Clearing cache on ip-0A0C0451
Clearing cache on ip-0A0C0463
Clearing cache on ip-0A0C0422
Clearing cache on ip-0A0C0432
Clearing cache on ip-0A0C047B
Clearing cache on ip-0A0C044C
Clearing cache on ip-0A0C044F
Clearing cache on ip-0A0C043D
Clearing cache on ip-0A0C0462
Clearing cache on ip-0A0C047F
Clearing cache on ip-0A0C0477
Clearing cache on ip-0A0C046A
Clearing cache on ip-0A0C0419
Clearing cache on ip-0A0C042C
Clearing cache on ip-0A0C0450
Clearing cache on ip-0A0C0476
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=768 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:08:35 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
[1634623720.616303] [ip-0A0C040E:57653:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.634733] [ip-0A0C040E:57654:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.650713] [ip-0A0C0410:86271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.652040] [ip-0A0C0410:86274:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.677747] [ip-0A0C045B:57670:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.680562] [ip-0A0C0474:35713:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.680562] [ip-0A0C0474:35719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.689703] [ip-0A0C040E:57650:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.696193] [ip-0A0C0412:49129:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.733110] [ip-0A0C0412:49128:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.737281] [ip-0A0C044C:51757:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.739428] [ip-0A0C045A:53785:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.744065] [ip-0A0C045B:57663:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.743490] [ip-0A0C0465:41782:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.744538] [ip-0A0C0474:35716:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.749893] [ip-0A0C044F:47609:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.750800] [ip-0A0C045B:57666:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.750317] [ip-0A0C0477:43431:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.750548] [ip-0A0C0409:35263:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.769156] [ip-0A0C045B:57665:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.768179] [ip-0A0C041F:73521:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.769391] [ip-0A0C0410:86270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.770259] [ip-0A0C0453:55423:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.772585] [ip-0A0C0477:43429:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.772445] [ip-0A0C046A:44885:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.773004] [ip-0A0C0412:49133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.777672] [ip-0A0C0416:56728:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.779156] [ip-0A0C041B:87647:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.780035] [ip-0A0C044C:51760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.784445] [ip-0A0C0412:49131:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.789496] [ip-0A0C040E:57649:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.794954] [ip-0A0C0428:58489:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.795195] [ip-0A0C040E:57655:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.797465] [ip-0A0C0410:86272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.800913] [ip-0A0C047B:45228:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.800448] [ip-0A0C041F:73525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.800901] [ip-0A0C047B:45213:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.802045] [ip-0A0C0459:49888:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.803457] [ip-0A0C044E:46938:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.804526] [ip-0A0C040E:57648:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.804713] [ip-0A0C0450:25354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.805058] [ip-0A0C040E:57652:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.805877] [ip-0A0C040E:57651:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.806098] [ip-0A0C040A:71165:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.806084] [ip-0A0C040A:71170:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.810546] [ip-0A0C0474:35740:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.811328] [ip-0A0C0409:35259:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.812081] [ip-0A0C043B:55127:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.812545] [ip-0A0C046A:44884:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.821172] [ip-0A0C0410:86275:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.821308] [ip-0A0C0410:86277:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.822004] [ip-0A0C0445:60230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.823757] [ip-0A0C043A:55050:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.825511] [ip-0A0C045A:53789:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.825515] [ip-0A0C0416:56723:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.825734] [ip-0A0C0416:56724:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.826659] [ip-0A0C0450:25358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.826484] [ip-0A0C041B:87645:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.827884] [ip-0A0C0477:43432:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.828622] [ip-0A0C047B:45209:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.829097] [ip-0A0C0457:49862:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.831124] [ip-0A0C044C:51755:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.830888] [ip-0A0C0459:49887:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.832557] [ip-0A0C0465:41784:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.832564] [ip-0A0C041B:87642:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.834649] [ip-0A0C041F:73528:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.838205] [ip-0A0C044F:47613:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.837998] [ip-0A0C0410:86273:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.838914] [ip-0A0C0428:58488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.839526] [ip-0A0C044F:47610:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.841327] [ip-0A0C044F:47608:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.841174] [ip-0A0C0408:94022:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.841211] [ip-0A0C040B:15836:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.841540] [ip-0A0C0410:86276:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.844780] [ip-0A0C0428:58492:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.846469] [ip-0A0C0457:49859:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.847046] [ip-0A0C0465:41783:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.848641] [ip-0A0C0445:60226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.849574] [ip-0A0C043B:55130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.849594] [ip-0A0C0422:97033:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.850811] [ip-0A0C044C:51759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.850943] [ip-0A0C047F:41929:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.851004] [ip-0A0C047F:41954:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.851999] [ip-0A0C045B:57667:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.851748] [ip-0A0C0409:35258:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.854769] [ip-0A0C040B:15814:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.855776] [ip-0A0C0475:36020:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.859567] [ip-0A0C047A:43598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.862516] [ip-0A0C045D:41181:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.863842] [ip-0A0C0474:35712:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.867260] [ip-0A0C0474:35714:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.867516] [ip-0A0C0447:56643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.868201] [ip-0A0C0417:2564 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.868506] [ip-0A0C0421:71603:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.869050] [ip-0A0C042C:62962:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.869040] [ip-0A0C042C:62955:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.869310] [ip-0A0C040B:15817:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.871134] [ip-0A0C045A:53782:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.871657] [ip-0A0C047A:43600:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.870466] [ip-0A0C0412:49134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.871565] [ip-0A0C0453:55427:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.871436] [ip-0A0C0434:58368:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.871932] [ip-0A0C044B:53044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.872675] [ip-0A0C0474:35726:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.873920] [ip-0A0C040C:82194:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.874424] [ip-0A0C045B:57664:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.874490] [ip-0A0C045B:57668:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.874312] [ip-0A0C0465:41785:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.873848] [ip-0A0C046A:44886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.875029] [ip-0A0C0470:34716:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.875533] [ip-0A0C045B:57676:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.875681] [ip-0A0C0417:2561 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.876600] [ip-0A0C0422:97034:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.876730] [ip-0A0C043A:55055:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.877668] [ip-0A0C0448:61950:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.878773] [ip-0A0C043A:55052:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.880292] [ip-0A0C043B:55125:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.880312] [ip-0A0C0476:29927:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.880291] [ip-0A0C0476:29922:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.882220] [ip-0A0C0474:35715:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.885973] [ip-0A0C0453:55429:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.886023] [ip-0A0C0477:43428:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.887731] [ip-0A0C0409:35269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.887050] [ip-0A0C0412:49130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.888154] [ip-0A0C0459:49885:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.888926] [ip-0A0C044E:46942:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.889971] [ip-0A0C0412:49127:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.890824] [ip-0A0C044E:46941:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.890949] [ip-0A0C046A:44880:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.893055] [ip-0A0C044A:48799:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.893594] [ip-0A0C0455:48593:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.895744] [ip-0A0C0433:63729:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.896628] [ip-0A0C0412:49132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.897793] [ip-0A0C0470:34715:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.897805] [ip-0A0C0462:81226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.898736] [ip-0A0C0432:92558:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.899456] [ip-0A0C043C:55896:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.899509] [ip-0A0C043C:55900:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.900255] [ip-0A0C0422:97038:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.900760] [ip-0A0C0425:72733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.901684] [ip-0A0C047B:45210:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.903009] [ip-0A0C0467:39943:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.905436] [ip-0A0C045A:53786:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.905362] [ip-0A0C0431:60157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.904953] [ip-0A0C042F:64826:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.907403] [ip-0A0C0411:69420:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.907503] [ip-0A0C041A:93130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.909268] [ip-0A0C045A:53784:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.910118] [ip-0A0C044F:47607:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.910416] [ip-0A0C041E:69557:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.910861] [ip-0A0C0433:63725:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.912019] [ip-0A0C041F:73524:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.912994] [ip-0A0C0409:35261:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.913289] [ip-0A0C041B:87646:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.914021] [ip-0A0C040C:82199:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.913677] [ip-0A0C0459:49886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.914323] [ip-0A0C0408:94016:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.914676] [ip-0A0C047C:48655:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.914728] [ip-0A0C047C:48652:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.915125] [ip-0A0C0475:36019:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.915392] [ip-0A0C041A:93132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.915874] [ip-0A0C041C:75570:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.916206] [ip-0A0C0445:60228:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.916714] [ip-0A0C0477:43456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.917967] [ip-0A0C0450:25351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.917715] [ip-0A0C044C:51756:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.917577] [ip-0A0C0418:66373:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.918142] [ip-0A0C0475:36023:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.920415] [ip-0A0C047B:45208:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.920875] [ip-0A0C0463:44285:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.921135] [ip-0A0C0428:58494:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.920869] [ip-0A0C0447:56647:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.920776] [ip-0A0C0434:58371:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.921317] [ip-0A0C040A:71168:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.923256] [ip-0A0C043D:45971:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.924740] [ip-0A0C0455:48595:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.925004] [ip-0A0C0420:70772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.926253] [ip-0A0C0447:56645:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.927645] [ip-0A0C045A:53783:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.927349] [ip-0A0C041B:87670:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.927712] [ip-0A0C0477:43430:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.928544] [ip-0A0C0479:39266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.927443] [ip-0A0C0442:49353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.928836] [ip-0A0C043F:50650:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.929151] [ip-0A0C0453:55425:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.929588] [ip-0A0C042F:64824:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.930330] [ip-0A0C0409:35281:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.930760] [ip-0A0C045D:41182:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.932304] [ip-0A0C0408:94023:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.932713] [ip-0A0C0426:68150:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.932430] [ip-0A0C0408:94019:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.930962] [ip-0A0C042E:68757:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.934222] [ip-0A0C0420:70783:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.934795] [ip-0A0C041C:75573:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.934903] [ip-0A0C0407:74393:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.937290] [ip-0A0C0425:72734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.937256] [ip-0A0C0469:39347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.937215] [ip-0A0C0457:49857:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.937124] [ip-0A0C041F:73526:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.937808] [ip-0A0C0409:35260:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.938311] [ip-0A0C0431:60154:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.937988] [ip-0A0C0451:52340:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.938692] [ip-0A0C045E:51127:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.938642] [ip-0A0C0418:66369:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.939203] [ip-0A0C044B:53051:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.938930] [ip-0A0C0413:4076 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.940199] [ip-0A0C044C:51754:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.939905] [ip-0A0C047D:39073:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.940468] [ip-0A0C0475:36016:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.940526] [ip-0A0C044C:51761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.939919] [ip-0A0C047D:39074:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.940623] [ip-0A0C0409:35280:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.941219] [ip-0A0C0465:41779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.941415] [ip-0A0C044C:51758:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.942518] [ip-0A0C045D:41188:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.942678] [ip-0A0C0416:56722:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.942842] [ip-0A0C0465:41778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.943061] [ip-0A0C0477:43433:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.943341] [ip-0A0C0416:56730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.943425] [ip-0A0C045D:41185:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.943978] [ip-0A0C0424:58462:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.944576] [ip-0A0C040C:82192:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.945183] [ip-0A0C0458:57775:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.947384] [ip-0A0C0450:25357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.947592] [ip-0A0C047F:41928:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.947761] [ip-0A0C043F:50645:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.947819] [ip-0A0C040A:71167:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.950129] [ip-0A0C0448:61952:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.951777] [ip-0A0C040A:71162:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.952534] [ip-0A0C0463:44283:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.953829] [ip-0A0C0421:71606:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.955751] [ip-0A0C0469:39349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.956335] [ip-0A0C045A:53790:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.956080] [ip-0A0C0457:49886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.956901] [ip-0A0C0465:41781:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.958468] [ip-0A0C043D:45970:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.958427] [ip-0A0C047D:39076:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.958955] [ip-0A0C0426:68157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.961362] [ip-0A0C045A:53787:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.961113] [ip-0A0C0453:55424:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.961187] [ip-0A0C0476:29926:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.961430] [ip-0A0C0477:43427:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.962651] [ip-0A0C044F:47611:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.963360] [ip-0A0C046A:44879:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.964549] [ip-0A0C0518:68363:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.964037] [ip-0A0C041F:73527:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.964805] [ip-0A0C0465:41780:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.964871] [ip-0A0C0445:60227:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.965111] [ip-0A0C0453:55426:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.965828] [ip-0A0C0467:39945:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.966202] [ip-0A0C0416:56729:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.966267] [ip-0A0C043D:45973:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.967165] [ip-0A0C044F:47612:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.967456] [ip-0A0C0452:53442:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.968616] [ip-0A0C047F:41926:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.968608] [ip-0A0C044F:47606:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.968543] [ip-0A0C0419:73966:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.968769] [ip-0A0C043A:55056:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.968971] [ip-0A0C041F:73523:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.969643] [ip-0A0C047B:45206:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.969540] [ip-0A0C041B:87644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.970103] [ip-0A0C0427:66540:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.970288] [ip-0A0C0453:55422:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.970088] [ip-0A0C044E:46943:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.970324] [ip-0A0C0458:57776:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.970564] [ip-0A0C0451:52342:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.971984] [ip-0A0C0416:56725:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.971512] [ip-0A0C041F:73522:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.972547] [ip-0A0C0416:56726:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.973198] [ip-0A0C0471:39205:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.974146] [ip-0A0C0417:2558 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.975078] [ip-0A0C0458:57769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.975508] [ip-0A0C0407:74389:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.976471] [ip-0A0C047B:45207:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.976656] [ip-0A0C047B:45212:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.976743] [ip-0A0C0457:49856:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.976797] [ip-0A0C040B:15809:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.978168] [ip-0A0C0432:92564:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.978383] [ip-0A0C0411:69416:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.978686] [ip-0A0C0450:25353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.978833] [ip-0A0C0411:69421:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.979349] [ip-0A0C041B:87643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.979437] [ip-0A0C041B:87641:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.980513] [ip-0A0C0459:49881:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.981529] [ip-0A0C0430:2583 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.981697] [ip-0A0C0434:58365:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.982120] [ip-0A0C0459:49882:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.983017] [ip-0A0C045E:51126:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.982209] [ip-0A0C046A:44881:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.982960] [ip-0A0C040A:71163:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.984580] [ip-0A0C0423:63357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.984373] [ip-0A0C040A:71166:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.985450] [ip-0A0C0453:55428:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.985727] [ip-0A0C046D:38508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.986253] [ip-0A0C0456:57394:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.987179] [ip-0A0C0428:58493:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.987283] [ip-0A0C0428:58491:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.987063] [ip-0A0C042B:67642:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.987163] [ip-0A0C043B:55128:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.987623] [ip-0A0C040A:71164:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.987911] [ip-0A0C0467:39942:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.987504] [ip-0A0C046A:44883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.987643] [ip-0A0C046A:44882:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.988096] [ip-0A0C0481:36726:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.988795] [ip-0A0C0481:36722:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.989492] [ip-0A0C0424:58464:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.990241] [ip-0A0C0459:49883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.990311] [ip-0A0C0459:49884:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.991171] [ip-0A0C043A:55057:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.993094] [ip-0A0C0476:29921:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.996862] [ip-0A0C0450:25352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.996521] [ip-0A0C040B:15811:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.996700] [ip-0A0C043B:55132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.998637] [ip-0A0C044A:48803:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.998760] [ip-0A0C044A:48806:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.998690] [ip-0A0C0467:39949:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.998524] [ip-0A0C0440:48933:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.999815] [ip-0A0C045C:50508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623720.999576] [ip-0A0C0442:49350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.000682] [ip-0A0C0442:49348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.002360] [ip-0A0C0408:94020:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.002943] [ip-0A0C0433:63752:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.002587] [ip-0A0C0434:58369:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.003016] [ip-0A0C042A:60139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.003073] [ip-0A0C044E:46940:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.003456] [ip-0A0C0452:53440:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.003427] [ip-0A0C044E:46945:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.004392] [ip-0A0C044A:48801:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.004361] [ip-0A0C0470:34714:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.004320] [ip-0A0C0442:49346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.005405] [ip-0A0C0445:60225:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.006010] [ip-0A0C0428:58495:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.006227] [ip-0A0C042C:62957:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.006321] [ip-0A0C047F:41930:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.005685] [ip-0A0C0417:2557 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.005997] [ip-0A0C0481:36724:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.006028] [ip-0A0C041D:66290:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.007056] [ip-0A0C0428:58490:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.007592] [ip-0A0C045D:41187:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.007802] [ip-0A0C047A:43593:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.007481] [ip-0A0C0421:71607:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.007853] [ip-0A0C044B:53043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.007572] [ip-0A0C0462:81223:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.007658] [ip-0A0C0462:81225:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.009431] [ip-0A0C0446:57616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.008646] [ip-0A0C043B:55126:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.008785] [ip-0A0C043B:55149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.008988] [ip-0A0C0457:49858:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.009413] [ip-0A0C0454:54239:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.009818] [ip-0A0C041E:69562:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.010428] [ip-0A0C0451:52344:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.010540] [ip-0A0C043B:55129:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.011463] [ip-0A0C0439:46866:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.011160] [ip-0A0C044E:46939:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.013375] [ip-0A0C0423:63358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.012952] [ip-0A0C0425:72729:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.013548] [ip-0A0C044B:53045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.013702] [ip-0A0C0480:37856:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.013654] [ip-0A0C0445:60224:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.014275] [ip-0A0C047F:41931:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.014961] [ip-0A0C0470:34713:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.016063] [ip-0A0C040B:15812:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.016215] [ip-0A0C044E:46944:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.016645] [ip-0A0C0424:58461:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.018435] [ip-0A0C0448:61947:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.018530] [ip-0A0C0445:60223:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.018668] [ip-0A0C0445:60229:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.019679] [ip-0A0C0450:25356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.019830] [ip-0A0C0450:25355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.019993] [ip-0A0C047F:41925:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.019848] [ip-0A0C0457:49860:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.020155] [ip-0A0C0421:71605:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.021830] [ip-0A0C0414:86276:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.020397] [ip-0A0C0413:4081 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.022136] [ip-0A0C042C:62960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.023698] [ip-0A0C0432:92559:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.023411] [ip-0A0C0457:49861:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.023741] [ip-0A0C0475:36022:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.024610] [ip-0A0C040C:82198:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.024929] [ip-0A0C0422:97037:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.025770] [ip-0A0C0407:74387:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.025858] [ip-0A0C040B:15813:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.026691] [ip-0A0C047F:41927:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.027265] [ip-0A0C047A:43595:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.027762] [ip-0A0C0418:66370:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.028248] [ip-0A0C046D:38488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.028901] [ip-0A0C0454:54237:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.028561] [ip-0A0C040B:15810:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.030454] [ip-0A0C043A:55051:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.030785] [ip-0A0C042F:64825:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.031991] [ip-0A0C042A:60144:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.032579] [ip-0A0C0470:34717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.032352] [ip-0A0C0427:66561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.032635] [ip-0A0C041A:93129:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.033372] [ip-0A0C042C:62956:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.032769] [ip-0A0C043A:55054:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.032977] [ip-0A0C0417:2560 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.032989] [ip-0A0C043A:55053:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.034796] [ip-0A0C0411:69418:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.034582] [ip-0A0C0434:58370:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.035208] [ip-0A0C0432:92561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.035302] [ip-0A0C0471:39206:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.035869] [ip-0A0C0448:61951:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.036204] [ip-0A0C043E:43488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.036507] [ip-0A0C0413:4079 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.037280] [ip-0A0C0455:48594:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.037145] [ip-0A0C0422:97031:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.038327] [ip-0A0C0408:94018:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.038460] [ip-0A0C0408:94021:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.038336] [ip-0A0C045C:50505:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.039534] [ip-0A0C0447:56650:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.037798] [ip-0A0C042E:68728:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.040260] [ip-0A0C0433:63727:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.041082] [ip-0A0C0408:94017:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.041463] [ip-0A0C0447:56648:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.041665] [ip-0A0C043C:55897:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.042315] [ip-0A0C041E:69563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.041633] [ip-0A0C0417:2559 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.042661] [ip-0A0C041E:69558:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.043441] [ip-0A0C042C:62959:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.044179] [ip-0A0C0446:57618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.043472] [ip-0A0C043C:55894:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.044232] [ip-0A0C040C:82193:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.044701] [ip-0A0C044A:48802:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.045749] [ip-0A0C047C:48657:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.045782] [ip-0A0C0419:73986:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.046931] [ip-0A0C0423:63364:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.046406] [ip-0A0C0455:48597:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.045995] [ip-0A0C0417:2565 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.046227] [ip-0A0C0417:2562 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.047690] [ip-0A0C0446:57621:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.046977] [ip-0A0C041C:75566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.047600] [ip-0A0C047A:43597:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.048364] [ip-0A0C0456:57398:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.048863] [ip-0A0C047D:39072:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.050138] [ip-0A0C0475:36018:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.051330] [ip-0A0C045D:41183:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.052421] [ip-0A0C044B:53042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.052186] [ip-0A0C0462:81220:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.052821] [ip-0A0C044B:53046:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.052742] [ip-0A0C0462:81222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.052907] [ip-0A0C0420:70767:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.053159] [ip-0A0C0425:72730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.053834] [ip-0A0C0439:46859:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.054038] [ip-0A0C0476:29920:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.055940] [ip-0A0C0452:53439:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.056319] [ip-0A0C042C:62958:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.056413] [ip-0A0C0425:72759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.056616] [ip-0A0C042C:62961:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.057389] [ip-0A0C040C:82197:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.057856] [ip-0A0C0479:39268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.055561] [ip-0A0C042E:68730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.057213] [ip-0A0C0422:97043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.058246] [ip-0A0C0479:39272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.058860] [ip-0A0C045D:41186:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.058387] [ip-0A0C0422:97032:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.059087] [ip-0A0C0448:61949:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.058985] [ip-0A0C0421:71604:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.058737] [ip-0A0C042F:64821:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.059937] [ip-0A0C0475:36021:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.060928] [ip-0A0C0475:36017:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.061175] [ip-0A0C047A:43594:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.061524] [ip-0A0C0469:39343:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.062625] [ip-0A0C045E:51131:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.062737] [ip-0A0C0422:97035:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.063403] [ip-0A0C041A:93146:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.064316] [ip-0A0C041E:69561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.064149] [ip-0A0C0421:71602:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.064820] [ip-0A0C045D:41184:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.064451] [ip-0A0C043C:55899:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.064958] [ip-0A0C043F:50643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.065242] [ip-0A0C047A:43599:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.065821] [ip-0A0C0447:56646:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.066879] [ip-0A0C043C:55895:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.067355] [ip-0A0C0420:70771:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.068847] [ip-0A0C0421:71608:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.069746] [ip-0A0C0407:74386:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.069916] [ip-0A0C041C:75571:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.070571] [ip-0A0C0433:63724:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.070342] [ip-0A0C0447:56668:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.070428] [ip-0A0C0447:56644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.070390] [ip-0A0C0440:48932:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.070884] [ip-0A0C047C:48651:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.070587] [ip-0A0C0462:81221:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.071505] [ip-0A0C044A:48805:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.071466] [ip-0A0C047A:43596:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.069801] [ip-0A0C042E:68732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.071631] [ip-0A0C047D:39078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.072454] [ip-0A0C0430:2586 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.072995] [ip-0A0C0463:44286:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.072695] [ip-0A0C047D:39079:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.072935] [ip-0A0C047D:39075:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.074068] [ip-0A0C0433:63726:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.074714] [ip-0A0C0411:69423:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.074578] [ip-0A0C0471:39207:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.075113] [ip-0A0C0469:39342:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.075897] [ip-0A0C0431:60158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.076401] [ip-0A0C0434:58372:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.076398] [ip-0A0C047D:39077:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.076931] [ip-0A0C040C:82195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.077316] [ip-0A0C044B:53048:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.077814] [ip-0A0C0448:61946:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.077823] [ip-0A0C0424:58460:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.078110] [ip-0A0C044B:53049:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.078907] [ip-0A0C045E:51132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.079076] [ip-0A0C0434:58366:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.079682] [ip-0A0C043F:50649:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.080194] [ip-0A0C040C:82196:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.080266] [ip-0A0C0420:70770:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.080496] [ip-0A0C043C:55898:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.081182] [ip-0A0C045E:51128:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.081090] [ip-0A0C042B:67638:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.081186] [ip-0A0C0432:92565:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.081071] [ip-0A0C0413:4085 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.082081] [ip-0A0C046D:38484:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.082348] [ip-0A0C0431:60159:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.083969] [ip-0A0C0426:68153:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.083480] [ip-0A0C043C:55893:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.084961] [ip-0A0C0455:48592:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.084950] [ip-0A0C041D:66292:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.085904] [ip-0A0C0518:68359:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.086152] [ip-0A0C0518:68358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.086616] [ip-0A0C0471:39211:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.087097] [ip-0A0C047C:48658:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.086809] [ip-0A0C0421:71609:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.087110] [ip-0A0C0455:48591:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.087163] [ip-0A0C047C:48654:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.087562] [ip-0A0C0432:92563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.087528] [ip-0A0C0470:34711:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.087641] [ip-0A0C0470:34710:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.088895] [ip-0A0C042F:64827:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.089809] [ip-0A0C0418:66398:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.090497] [ip-0A0C0426:68151:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.090474] [ip-0A0C0448:61948:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.091198] [ip-0A0C0418:66375:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.092275] [ip-0A0C0414:86274:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.091588] [ip-0A0C0479:39267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.091834] [ip-0A0C044A:48804:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.092446] [ip-0A0C0463:44282:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.092500] [ip-0A0C0470:34712:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.092452] [ip-0A0C0467:39941:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.093125] [ip-0A0C0451:52348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.094033] [ip-0A0C044A:48800:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.093478] [ip-0A0C0476:29923:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.094270] [ip-0A0C043D:45972:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.094580] [ip-0A0C0476:29924:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.094397] [ip-0A0C042F:64822:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.095448] [ip-0A0C0434:58367:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.096338] [ip-0A0C0448:61954:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.096333] [ip-0A0C041C:75568:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.096176] [ip-0A0C042F:64823:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.096907] [ip-0A0C041E:69556:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.096810] [ip-0A0C042B:67643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.096918] [ip-0A0C0476:29925:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.097261] [ip-0A0C041A:93127:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.097386] [ip-0A0C0425:72736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.098174] [ip-0A0C0411:69419:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.098774] [ip-0A0C041E:69560:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.098857] [ip-0A0C041E:69559:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.099368] [ip-0A0C0418:66372:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.099606] [ip-0A0C042A:60161:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.099541] [ip-0A0C045C:50506:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.100544] [ip-0A0C0467:39947:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.100627] [ip-0A0C0425:72731:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.100769] [ip-0A0C0430:2588 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.100958] [ip-0A0C0439:46860:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.101710] [ip-0A0C0433:63730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.099428] [ip-0A0C042E:68734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.101771] [ip-0A0C0433:63728:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.102370] [ip-0A0C0411:69417:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.102338] [ip-0A0C0452:53436:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.103082] [ip-0A0C041A:93126:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.104274] [ip-0A0C0467:39948:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.105931] [ip-0A0C0455:48599:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.105683] [ip-0A0C0462:81224:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.106372] [ip-0A0C0455:48596:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.106495] [ip-0A0C0427:66546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.107161] [ip-0A0C043D:45969:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.107341] [ip-0A0C0456:57396:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.107441] [ip-0A0C0462:81219:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.107927] [ip-0A0C0456:57400:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.107975] [ip-0A0C0456:57399:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.108750] [ip-0A0C041A:93128:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.110672] [ip-0A0C0432:92562:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.110502] [ip-0A0C0458:57771:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.110721] [ip-0A0C0425:72732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.111241] [ip-0A0C0432:92560:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.111110] [ip-0A0C0411:69422:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.111452] [ip-0A0C0458:57770:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.111348] [ip-0A0C041A:93125:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.111997] [ip-0A0C0469:39344:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.112390] [ip-0A0C0463:44284:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.112952] [ip-0A0C0419:73965:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.114562] [ip-0A0C0426:68156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.114434] [ip-0A0C0427:66536:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.115393] [ip-0A0C045E:51130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.115536] [ip-0A0C0431:60153:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.115447] [ip-0A0C046D:38490:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.116013] [ip-0A0C0431:60152:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.115780] [ip-0A0C043F:50647:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.116065] [ip-0A0C0467:39944:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.115228] [ip-0A0C0442:49349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.116336] [ip-0A0C0469:39346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.116626] [ip-0A0C042F:64828:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.117966] [ip-0A0C047C:48653:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.118030] [ip-0A0C047C:48656:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.117964] [ip-0A0C041C:75572:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.117987] [ip-0A0C0442:49352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.119733] [ip-0A0C0454:54244:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.119628] [ip-0A0C0451:52341:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.120640] [ip-0A0C0479:39270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.120529] [ip-0A0C0469:39348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.120501] [ip-0A0C043D:45968:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.123187] [ip-0A0C0418:66371:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.123153] [ip-0A0C041C:75567:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.123891] [ip-0A0C041C:75569:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.124450] [ip-0A0C0518:68360:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.124147] [ip-0A0C0413:4080 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.125218] [ip-0A0C0479:39271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.125274] [ip-0A0C0420:70773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.125916] [ip-0A0C0424:58463:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.126143] [ip-0A0C0430:2585 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.126578] [ip-0A0C0418:66374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.127307] [ip-0A0C0419:73968:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.126838] [ip-0A0C0442:49351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.127449] [ip-0A0C041D:66286:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.128375] [ip-0A0C0413:4077 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.128826] [ip-0A0C0420:70768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.129234] [ip-0A0C0480:37857:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.128746] [ip-0A0C0413:4082 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.128999] [ip-0A0C0413:4078 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.130489] [ip-0A0C045E:51133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.130763] [ip-0A0C0463:44288:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.128603] [ip-0A0C042E:68729:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.128870] [ip-0A0C042E:68731:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.131654] [ip-0A0C0452:53437:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.132080] [ip-0A0C0463:44289:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.132117] [ip-0A0C0431:60151:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.132220] [ip-0A0C0463:44287:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.132733] [ip-0A0C0518:68364:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.133223] [ip-0A0C0479:39269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.133453] [ip-0A0C045E:51129:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.133570] [ip-0A0C0426:68152:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.134583] [ip-0A0C043F:50646:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.134956] [ip-0A0C042B:67644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.134891] [ip-0A0C0420:70769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.133169] [ip-0A0C042E:68727:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.135088] [ip-0A0C043D:45967:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.135119] [ip-0A0C0481:36725:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.135814] [ip-0A0C0458:57774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.135970] [ip-0A0C0458:57772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.136071] [ip-0A0C0469:39345:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.136618] [ip-0A0C0479:39265:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.137417] [ip-0A0C0407:74388:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.137271] [ip-0A0C0442:49347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.138098] [ip-0A0C043D:45966:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.138544] [ip-0A0C0451:52346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.139275] [ip-0A0C0407:74391:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.139461] [ip-0A0C0458:57777:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.139839] [ip-0A0C0431:60156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.141142] [ip-0A0C0480:37862:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.141349] [ip-0A0C0454:54257:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.143166] [ip-0A0C0414:86269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.142250] [ip-0A0C0481:36721:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.143154] [ip-0A0C043F:50644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.143257] [ip-0A0C043F:50648:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.145999] [ip-0A0C0440:48937:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.148106] [ip-0A0C0451:52347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.149132] [ip-0A0C0424:58465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.149117] [ip-0A0C0452:53441:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.150858] [ip-0A0C0424:58459:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.151832] [ip-0A0C0439:46863:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.151790] [ip-0A0C0456:57403:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.151606] [ip-0A0C0427:66538:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.152173] [ip-0A0C0471:39208:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.154494] [ip-0A0C0427:66535:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.154752] [ip-0A0C041D:66293:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.155225] [ip-0A0C0424:58466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.155287] [ip-0A0C0407:74392:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.157076] [ip-0A0C0518:68362:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.158068] [ip-0A0C0426:68155:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.158659] [ip-0A0C0423:63363:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.158199] [ip-0A0C0452:53443:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.158220] [ip-0A0C0419:73969:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.159320] [ip-0A0C042A:60142:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.159800] [ip-0A0C0451:52343:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.160633] [ip-0A0C0440:48931:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.161059] [ip-0A0C0407:74390:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.161907] [ip-0A0C0518:68357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.162226] [ip-0A0C0426:68154:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.162309] [ip-0A0C0452:53438:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.162163] [ip-0A0C043E:43482:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.162861] [ip-0A0C0430:2582 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.163965] [ip-0A0C042A:60157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.165592] [ip-0A0C0427:66534:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.166537] [ip-0A0C0430:2587 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.166957] [ip-0A0C0419:73970:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.166814] [ip-0A0C0481:36728:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.169334] [ip-0A0C0480:37860:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.169865] [ip-0A0C042B:67641:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.170344] [ip-0A0C0518:68361:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.170036] [ip-0A0C042B:67645:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.169979] [ip-0A0C043E:43485:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.171937] [ip-0A0C0414:86272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.171325] [ip-0A0C0427:66537:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.173953] [ip-0A0C0423:63362:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.174073] [ip-0A0C0423:63361:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.176345] [ip-0A0C0419:73967:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.176568] [ip-0A0C0419:73971:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.176665] [ip-0A0C045C:50507:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.178257] [ip-0A0C0471:39209:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.179916] [ip-0A0C0456:57397:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.179995] [ip-0A0C0471:39210:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.180734] [ip-0A0C0456:57395:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.181480] [ip-0A0C0471:39212:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.182785] [ip-0A0C046D:38487:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.183483] [ip-0A0C042A:60141:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.184930] [ip-0A0C0481:36723:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.185876] [ip-0A0C046D:38485:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.186103] [ip-0A0C046D:38486:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.186318] [ip-0A0C042B:67640:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.186510] [ip-0A0C0481:36727:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.190030] [ip-0A0C0446:57619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.190120] [ip-0A0C0446:57620:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.189831] [ip-0A0C0430:2584 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.189857] [ip-0A0C0430:2589 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.191389] [ip-0A0C0446:57644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.191067] [ip-0A0C045C:50512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.191302] [ip-0A0C041D:66291:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.194212] [ip-0A0C046D:38483:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.195019] [ip-0A0C0440:48935:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.196699] [ip-0A0C0454:54243:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.197514] [ip-0A0C0423:63359:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.196992] [ip-0A0C0480:37858:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.197597] [ip-0A0C0423:63360:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.201111] [ip-0A0C0439:46861:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.202643] [ip-0A0C041D:66287:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.204056] [ip-0A0C042A:60143:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.205268] [ip-0A0C0454:54238:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.205074] [ip-0A0C042B:67639:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.206874] [ip-0A0C0440:48941:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.208984] [ip-0A0C0446:57617:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.209418] [ip-0A0C0446:57615:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.209061] [ip-0A0C043E:43481:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.209622] [ip-0A0C041D:66289:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.210225] [ip-0A0C041D:66288:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.211236] [ip-0A0C0454:54241:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.211671] [ip-0A0C042A:60140:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.213732] [ip-0A0C043E:43486:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.214360] [ip-0A0C0480:37861:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.216231] [ip-0A0C0414:86277:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.215685] [ip-0A0C045C:50509:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.216457] [ip-0A0C0454:54242:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.218458] [ip-0A0C0440:48930:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.218613] [ip-0A0C0440:48934:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.218540] [ip-0A0C045C:50511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.220111] [ip-0A0C045C:50510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.221799] [ip-0A0C0480:37855:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.224819] [ip-0A0C0439:46865:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.225104] [ip-0A0C0480:37859:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.227077] [ip-0A0C0439:46864:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.229764] [ip-0A0C0439:46862:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.234915] [ip-0A0C043E:43483:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.240826] [ip-0A0C0414:86271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.241538] [ip-0A0C0414:86275:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.240441] [ip-0A0C043E:43480:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.248319] [ip-0A0C0414:86270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634623721.247484] [ip-0A0C043E:43484:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
:::MLLOG {"namespace": "", "time_ms": 1634623722150, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634623722190, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634623722190, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1634623722191, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634623722191, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1634623722191, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1634623722191, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "96xND96amsr_A100_v4", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:08:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[ip-0A0C0409:0:35263 - context.c:584] INFO job (ID: 867537996681131499) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:35263 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:35263 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:35258 - context.c:584] INFO job (ID: 867537892972698862) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:35258 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:35258 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:35261 - context.c:584] INFO job (ID: 867538167889086529) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:35261 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:35261 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:35269 - context.c:584] INFO job (ID: 867538819548415611) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:35269 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:35269 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:35281 - context.c:584] INFO job (ID: 867538679410481308) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:35281 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:35281 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:35259 - context.c:584] INFO job (ID: 867538817556710607) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:35259 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:35259 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:35280 - context.c:584] INFO job (ID: 867538537464483791) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:35280 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:35280 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:35260 - context.c:584] INFO job (ID: 867538105279762298) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:35260 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:35260 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634623816032, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2569020377, "metadata": {"file": "main.py", "lineno": 72}}
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634623816032, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 138}}
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634623816032, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 139}}
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634623816033, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1500, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 140}}
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634623816033, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 142}}
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634623816033, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 143}}
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634623816033, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 144}}
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634623816033, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 145}}
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634623816033, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 146}}
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634623816033, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 147}}
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634623816033, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 148}}
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634623816033, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 149}}
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:10:17] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634623840089, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1634623840104, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623840109, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1634623840110, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 95}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634623842650, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 84, "metadata": {"file": "main.py", "lineno": 136}}
:::MLLOG {"namespace": "", "time_ms": 1634623842650, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1634623842651, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634623842651, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1, "epoch_count": 20}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634623844112, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2299.8018459628397, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623844113, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.02989933774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623844113, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2299.8018459628397, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634623844113, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623844113, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623844796, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4918.850709510965, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623844797, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.04976556291390729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623844797, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4918.850709510965, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623844797, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623844797, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623845472, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4980.7178411328705, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623845472, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0696317880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623845472, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4980.7178411328705, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634623845473, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623845473, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623846120, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5193.88588891395, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623846120, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.08949801324503312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623846121, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5193.88588891395, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 60}}
:::MLLOG {"namespace": "", "time_ms": 1634623846121, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623846121, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623846764, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5228.422090254145, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623846764, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.10936423841059603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623846764, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5228.422090254145, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 80}}
:::MLLOG {"namespace": "", "time_ms": 1634623846765, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623846765, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623847392, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5360.785368674112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623847392, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.12923046357615892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623847392, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5360.785368674112, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 100}}
:::MLLOG {"namespace": "", "time_ms": 1634623847392, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623847392, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623848010, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5438.332202667753, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623848011, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.14909668874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623848011, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5438.332202667753, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634623848011, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623848011, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623848639, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5351.242663944884, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623848640, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.16896291390728477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623848640, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5351.242663944884, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1634623848640, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623848640, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623849263, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5397.9299139340965, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623849263, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.18882913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623849263, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5397.9299139340965, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 160}}
:::MLLOG {"namespace": "", "time_ms": 1634623849264, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623849264, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623849887, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5391.717890977038, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623849887, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.20869536423841056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623849887, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5391.717890977038, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 180}}
:::MLLOG {"namespace": "", "time_ms": 1634623849888, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623849888, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623850512, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5381.244858021639, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623850513, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.22856158940397348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623850513, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5381.244858021639, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 200}}
:::MLLOG {"namespace": "", "time_ms": 1634623850513, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623850513, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623851150, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5274.394901979424, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623851150, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.24842781456953641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623851151, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5274.394901979424, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 220}}
:::MLLOG {"namespace": "", "time_ms": 1634623851151, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623851151, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623851778, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5356.113581281048, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623851779, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26829403973509935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623851779, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5356.113581281048, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 240}}
:::MLLOG {"namespace": "", "time_ms": 1634623851779, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623851779, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623852409, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5336.284836895814, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623852409, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.28816026490066227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623852409, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5336.284836895814, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 260}}
:::MLLOG {"namespace": "", "time_ms": 1634623852410, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623852410, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623853040, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5335.773675859069, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623853040, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3080264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623853040, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5335.773675859069, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1634623853040, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623853040, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623853670, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5338.245532163122, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623853670, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32789271523178803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623853670, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5338.245532163122, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 300}}
:::MLLOG {"namespace": "", "time_ms": 1634623853671, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623853671, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623854298, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5354.088887943322, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623854299, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.347758940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623854299, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5354.088887943322, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 320}}
:::MLLOG {"namespace": "", "time_ms": 1634623854299, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623854299, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623854916, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5444.269356648155, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623854917, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36762516556291386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623854917, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5444.269356648155, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 340}}
:::MLLOG {"namespace": "", "time_ms": 1634623854917, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623854917, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623855548, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5327.5117255176065, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623855548, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3874913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623855549, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5327.5117255176065, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 360}}
:::MLLOG {"namespace": "", "time_ms": 1634623855549, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623855549, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623856173, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5385.41313284863, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623856173, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.40735761589403974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623856173, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5385.41313284863, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 380}}
:::MLLOG {"namespace": "", "time_ms": 1634623856173, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623856174, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623856804, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5333.110354426567, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623856804, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623856804, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5333.110354426567, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 400}}
:::MLLOG {"namespace": "", "time_ms": 1634623856804, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623856804, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623857434, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5340.5415778494, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623857434, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.44709006622516556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623857434, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5340.5415778494, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1634623857434, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623857434, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623858067, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5307.935782874554, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623858068, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4669562913907285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623858068, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5307.935782874554, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 440}}
:::MLLOG {"namespace": "", "time_ms": 1634623858068, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623858068, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623858698, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5338.696493654529, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623858698, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4868225165562914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623858698, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5338.696493654529, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 460}}
:::MLLOG {"namespace": "", "time_ms": 1634623858698, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623858698, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623859329, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5329.594968734223, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623859329, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5066887417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623859329, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5329.594968734223, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 480}}
:::MLLOG {"namespace": "", "time_ms": 1634623859329, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623859329, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623859956, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5359.751698779982, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623859957, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5265549668874172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623859957, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5359.751698779982, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 500}}
:::MLLOG {"namespace": "", "time_ms": 1634623859957, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623859957, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623860577, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5423.875617182151, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623860577, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5464211920529801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623860577, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5423.875617182151, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 520}}
:::MLLOG {"namespace": "", "time_ms": 1634623860577, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623860577, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623861204, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5357.954429756044, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623861205, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.566287417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623861205, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5357.954429756044, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 540}}
:::MLLOG {"namespace": "", "time_ms": 1634623861205, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623861205, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623861825, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5418.139060656996, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623861826, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5861536423841059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623861826, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5418.139060656996, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1634623861826, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623861826, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623862459, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5313.892022070232, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623862459, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6060198675496689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623862459, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5313.892022070232, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634623862459, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623862459, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623863082, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5393.0363364801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623863083, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6258860927152318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623863083, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5393.0363364801, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 600}}
:::MLLOG {"namespace": "", "time_ms": 1634623863083, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623863083, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623863707, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5385.791825806348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623863708, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6457523178807947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623863708, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5385.791825806348, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 620}}
:::MLLOG {"namespace": "", "time_ms": 1634623863708, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623863708, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623864338, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5335.937317549133, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623864338, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6656185430463576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623864338, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5335.937317549133, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 640}}
:::MLLOG {"namespace": "", "time_ms": 1634623864338, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623864338, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623864960, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5410.043916491103, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623864960, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6854847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623864960, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5410.043916491103, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 660}}
:::MLLOG {"namespace": "", "time_ms": 1634623864960, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623864961, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623865592, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5323.802591625232, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623865592, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7053509933774835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623865592, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5323.802591625232, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 680}}
:::MLLOG {"namespace": "", "time_ms": 1634623865592, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623865592, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623866208, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5462.167323104733, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623866208, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7252172185430463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623866208, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5462.167323104733, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 700}}
:::MLLOG {"namespace": "", "time_ms": 1634623866208, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623866208, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623866830, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5410.876856323739, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623866830, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7450834437086092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623866830, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5410.876856323739, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 720}}
:::MLLOG {"namespace": "", "time_ms": 1634623866830, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623866830, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623867448, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5443.003526226551, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623867448, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7649496688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623867448, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5443.003526226551, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 740}}
:::MLLOG {"namespace": "", "time_ms": 1634623867448, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623867448, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623868062, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5475.165101569138, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623868063, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7848158940397352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623868063, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5475.165101569138, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 760}}
:::MLLOG {"namespace": "", "time_ms": 1634623868063, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623868063, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623868686, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5395.220720791424, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623868686, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8046821192052981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623868686, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5395.220720791424, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634623868686, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623868687, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623869310, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5391.029006951447, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623869310, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8245483443708609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623869310, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5391.029006951447, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 800}}
:::MLLOG {"namespace": "", "time_ms": 1634623869311, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623869311, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623869928, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5446.192358020045, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623869928, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623869928, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5446.192358020045, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 820}}
:::MLLOG {"namespace": "", "time_ms": 1634623869928, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623869928, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623870552, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5389.812546037399, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623870552, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8642807947019867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623870553, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5389.812546037399, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 840}}
:::MLLOG {"namespace": "", "time_ms": 1634623870553, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623870553, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623871170, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5444.702649783917, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623871170, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8841470198675497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623871170, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5444.702649783917, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 860}}
:::MLLOG {"namespace": "", "time_ms": 1634623871170, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623871171, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623871786, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5461.578847015382, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623871786, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9040132450331126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623871787, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5461.578847015382, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 880}}
:::MLLOG {"namespace": "", "time_ms": 1634623871787, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623871787, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623872409, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5401.765869304575, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623872409, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9238794701986754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623872409, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5401.765869304575, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 900}}
:::MLLOG {"namespace": "", "time_ms": 1634623872410, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623872410, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623873029, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5426.682628938407, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623873029, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9437456953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623873029, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5426.682628938407, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 920}}
:::MLLOG {"namespace": "", "time_ms": 1634623873030, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623873030, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623873649, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5427.524881053889, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623873649, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9636119205298014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623873649, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5427.524881053889, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 940}}
:::MLLOG {"namespace": "", "time_ms": 1634623873650, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623873650, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623874276, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5368.42075911351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623874276, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9834781456953643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623874276, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5368.42075911351, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 960}}
:::MLLOG {"namespace": "", "time_ms": 1634623874276, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623874276, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623874904, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5356.879090252878, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623874904, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0033443708609273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623874904, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5356.879090252878, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 980}}
:::MLLOG {"namespace": "", "time_ms": 1634623874980, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623874980, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623874995, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634623875424, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8768377304077148, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634623875425, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634623875586, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5545.037074168404, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623875586, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0232105960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623875586, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5545.037074168404, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634623875716, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623875716, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623875730, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634623876144, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8868423700332642, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634623876144, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634623876372, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5124.606074534243, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623876372, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.043076821192053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623876373, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5124.606074534243, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634623876486, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623876487, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623876501, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634623876911, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8865096569061279, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634623876911, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634623877140, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5143.562177201164, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623877141, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.062943046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623877141, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5143.562177201164, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634623877177, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623877177, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623877193, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634623877595, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8852066993713379, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634623877595, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634623877792, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5467.490531794626, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623877792, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0828092715231787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623877792, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5467.490531794626, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634623877829, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623877829, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623877844, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634623878248, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8817827701568604, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634623878248, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634623878441, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5492.776824174847, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623878441, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1026754966887418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623878441, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5492.776824174847, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634623878477, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623878477, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623878493, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634623878892, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8788454532623291, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634623878893, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634623879088, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5502.247084674454, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623879089, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1225417218543046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623879089, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5502.247084674454, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634623879124, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623879124, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623879140, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634623879540, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8894742727279663, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634623879540, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634623879740, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5456.56501344505, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623879740, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1424079470198676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623879740, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5456.56501344505, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634623879776, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623879776, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623879793, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634623880192, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8869049549102783, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634623880192, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634623880397, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5413.360580298908, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623880398, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1622741721854304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623880398, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5413.360580298908, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634623880454, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623880454, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623880469, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634623880869, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8943272829055786, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634623880869, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634623881064, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5513.833210089557, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623881064, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1821403973509934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623881064, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5513.833210089557, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634623881102, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623881103, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623881118, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634623881517, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8944780826568604, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634623881517, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634623881709, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5537.4374767928675, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623881710, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2020066225165562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623881710, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5537.4374767928675, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634623881745, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623881745, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623881761, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634623882165, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8877973556518555, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634623882165, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634623882365, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5421.227910769858, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623882365, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2218728476821192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623882366, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5421.227910769858, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634623882401, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623882402, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623882418, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634623882816, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8836110830307007, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634623882816, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634623883018, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5449.654657174567, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623883019, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.241739072847682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623883019, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5449.654657174567, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634623883054, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623883054, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623883073, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634623883470, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8830538988113403, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634623883470, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634623883664, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5506.5533591556095, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623883664, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623883664, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5506.5533591556095, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634623883700, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623883700, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623883716, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634623884115, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8858251571655273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634623884115, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634623884311, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5498.533153441524, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623884312, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.281471523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623884312, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5498.533153441524, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634623884347, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623884347, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623884362, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634623884763, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.873473048210144, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634623884763, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634623884957, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5507.403370362352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623884958, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3013377483443709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623884958, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5507.403370362352, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634623884993, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623884993, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623885009, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634623885408, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8913801312446594, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634623885408, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634623885608, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5460.0574410044155, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623885609, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3212039735099337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623885609, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5460.0574410044155, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634623885653, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623885654, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623885669, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634623886071, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8983371257781982, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634623886071, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634623886265, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5495.882801184593, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623886265, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3410701986754967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623886265, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5495.882801184593, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634623886302, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623886302, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623886318, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634623886717, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9002694487571716, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634623886717, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634623886909, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5533.9866378805955, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623886909, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3609364238410595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623886910, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5533.9866378805955, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634623886944, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623886945, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623886959, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634623887361, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8843020796775818, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634623887361, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634623887577, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5313.29098895746, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623887577, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3808026490066225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623887577, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5313.29098895746, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634623887613, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623887613, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623887629, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634623888028, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8802036046981812, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634623888029, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634623888221, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5528.049622313566, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623888221, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4006688741721853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623888221, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5528.049622313566, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634623888259, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623888259, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623888275, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634623888677, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.891747236251831, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634623888677, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634623888868, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5523.088382432072, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623888868, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4205350993377484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623888868, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5523.088382432072, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634623888911, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623888911, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623888927, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634623889327, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8704349994659424, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634623889327, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634623889521, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5505.346578901108, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623889522, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4404013245033112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623889522, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5505.346578901108, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634623889559, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623889559, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623889575, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634623889975, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8959219455718994, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634623889975, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634623890168, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5525.435736625495, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623890168, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4602675496688742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623890168, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5525.435736625495, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634623890203, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623890203, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623890219, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634623890619, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.880020022392273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634623890619, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634623890832, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5347.104779697725, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623890832, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4801337748344372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623890832, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5347.104779697725, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634623890900, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623890900, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623890914, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634623891315, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8914687633514404, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634623891315, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634623891514, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5471.355925820527, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623891515, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623891515, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5471.355925820527, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634623891552, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623891552, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623891566, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634623891966, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8714531660079956, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634623891966, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634623892168, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5460.048979364121, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623892168, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623892168, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5460.048979364121, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634623892203, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623892204, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623892218, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634623892619, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8824126720428467, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634623892619, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634623892816, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5492.053314710648, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623892816, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623892816, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5492.053314710648, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634623892851, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623892851, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623892865, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634623893268, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8966917991638184, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634623893268, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634623893508, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5116.646543098178, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623893508, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623893508, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5116.646543098178, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634623893543, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623893543, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623893558, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634623893960, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.891014575958252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634623893960, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634623894172, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5341.6265645911835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623894173, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623894173, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5341.6265645911835, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634623894209, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623894210, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623894224, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634623894626, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8954975008964539, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634623894626, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634623894843, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5304.816894876791, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623894844, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623894844, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5304.816894876791, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634623894879, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623894879, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623894894, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634623895296, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8876049518585205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634623895296, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634623895510, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5329.975931100316, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623895510, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623895510, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5329.975931100316, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634623895547, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623895548, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623895563, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634623895963, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8942367434501648, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634623895963, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634623896155, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5531.006768514906, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623896156, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623896156, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5531.006768514906, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634623896194, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623896194, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623896215, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634623896609, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8936113119125366, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634623896609, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634623896803, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5513.14943469418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623896804, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623896804, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5513.14943469418, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634623896839, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623896839, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623896854, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634623897259, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8837175369262695, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634623897259, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634623897450, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5500.357290611247, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623897450, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623897450, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5500.357290611247, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634623897485, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623897485, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623897500, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634623897903, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9031760692596436, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634623897903, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634623898094, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5526.246080161746, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623898094, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623898094, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5526.246080161746, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634623898131, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623898132, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623898147, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634623898547, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8908822536468506, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634623898547, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634623898750, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5434.393862271293, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623898750, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623898751, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5434.393862271293, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634623898786, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623898786, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623898800, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634623899202, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8910060524940491, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634623899202, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634623899392, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5547.898855845329, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623899392, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623899392, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5547.898855845329, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634623899428, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623899428, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623899443, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634623899846, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8905946016311646, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634623899846, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634623900044, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5455.760190405696, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623900044, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623900044, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5455.760190405696, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634623900079, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623900079, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623900095, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634623900495, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8844727277755737, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634623900495, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634623900687, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5526.599325648645, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623900688, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623900688, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5526.599325648645, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634623900723, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623900723, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623900739, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634623901145, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8871517181396484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634623901145, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634623901336, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5486.483543307362, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623901336, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623901336, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5486.483543307362, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634623901373, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623901373, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623901389, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634623901789, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8896893262863159, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634623901789, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634623901979, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5547.309231383287, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623901980, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623901980, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5547.309231383287, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634623902015, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623902015, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623902030, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634623902434, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9047069549560547, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634623902434, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634623902625, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5504.819719580719, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623902626, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623902626, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5504.819719580719, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634623902661, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623902661, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623902676, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634623903082, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8951992988586426, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634623903082, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634623903276, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5464.995046051364, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623903276, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623903277, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5464.995046051364, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634623903312, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623903312, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623903327, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634623903733, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9029413461685181, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634623903733, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634623903921, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5513.399629358819, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623903922, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623903922, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5513.399629358819, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634623903959, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623903959, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623903974, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634623904377, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9035083055496216, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634623904377, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634623904569, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5510.586247994069, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623904569, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623904569, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5510.586247994069, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634623904605, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623904605, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623904620, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634623905024, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8966186046600342, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634623905024, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634623905214, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5521.707753701125, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623905214, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623905214, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5521.707753701125, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634623905250, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623905250, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623905265, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634623905668, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8967325687408447, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634623905668, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634623905858, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5536.045316431331, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623905858, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623905858, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5536.045316431331, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634623905902, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623905902, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623905917, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634623906319, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8959091901779175, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634623906319, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634623906510, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5530.520563943618, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623906510, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623906511, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5530.520563943618, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634623906546, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623906546, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623906562, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634623906967, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8922824859619141, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634623906967, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634623907164, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5437.2306541986845, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623907165, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623907165, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5437.2306541986845, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634623907201, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623907201, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623907216, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634623907621, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9003530740737915, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634623907621, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634623907810, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5514.530102086135, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623907811, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623907811, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5514.530102086135, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634623907848, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623907848, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623907864, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634623908266, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9018003344535828, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634623908266, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634623908457, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5523.242068761179, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623908457, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623908457, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5523.242068761179, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634623908492, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623908493, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623908508, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634623908914, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9005552530288696, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634623908914, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634623909111, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5435.202874326137, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623909111, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623909111, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5435.202874326137, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634623909148, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623909148, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623909163, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634623909568, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8875477313995361, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634623909568, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634623909758, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5509.216169178734, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623909758, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623909758, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5509.216169178734, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634623909794, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623909795, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623909810, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634623910214, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8859226703643799, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634623910214, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634623910412, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5444.759445744079, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623910412, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623910412, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5444.759445744079, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634623910448, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623910448, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623910463, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634623910867, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8896200656890869, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634623910867, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634623911059, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5500.138330248834, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623911060, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623911060, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5500.138330248834, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634623911094, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623911095, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623911110, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634623911515, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9020383954048157, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634623911516, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634623911705, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5504.892828725566, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623911706, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623911706, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5504.892828725566, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634623911742, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623911742, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623911757, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634623912158, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8918087482452393, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634623912158, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634623912357, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5468.317915988924, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623912357, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623912357, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5468.317915988924, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634623912393, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623912393, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623912408, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634623912812, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8989225625991821, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634623912813, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634623913004, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5499.380690205793, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623913005, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623913005, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5499.380690205793, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634623913042, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623913042, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623913057, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634623913460, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8776330351829529, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634623913460, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634623913648, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5550.247678250243, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623913648, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623913648, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5550.247678250243, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634623913684, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623913685, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623913699, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634623914103, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8933256268501282, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634623914103, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634623914294, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5521.56064275312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623914294, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623914294, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5521.56064275312, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634623914330, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623914330, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623914346, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634623914747, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8985345959663391, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634623914748, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634623914943, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5487.5047124940575, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623914943, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623914943, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5487.5047124940575, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634623914978, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623914978, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623914994, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634623915398, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8995513916015625, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634623915399, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634623915589, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5501.907685100236, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623915589, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623915590, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5501.907685100236, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634623915625, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623915625, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623915640, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634623916043, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8994899988174438, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634623916043, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634623916232, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5539.152536310636, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623916232, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623916233, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5539.152536310636, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634623916268, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623916269, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623916283, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634623916687, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8955256342887878, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634623916688, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634623916876, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5529.249022278859, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623916877, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623916877, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5529.249022278859, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634623916913, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623916913, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623916928, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634623917332, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8988692760467529, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634623917332, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634623917524, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5503.860879400096, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623917525, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623917525, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5503.860879400096, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634623917560, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623917560, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634623917575, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634623917977, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9099670648574829, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634623917977, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634623917977, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 165, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1634623918172, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5496.81527936991, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634623918172, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634623918172, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5496.81527936991, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2300}}
ENDING TIMING RUN AT 2021-10-19 06:12:04 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:04 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:04 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:04 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:04 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:04 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:04 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:04 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:04 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:04 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:04 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:05 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:05 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:07 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:08 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:10 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:10 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:10 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:11 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:12 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:13 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:14 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:15 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:16 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
ENDING TIMING RUN AT 2021-10-19 06:12:17 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:08:35 AM
