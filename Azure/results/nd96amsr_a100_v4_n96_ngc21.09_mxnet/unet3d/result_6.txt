+ : DGXA100_96x8x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019053509643409700
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data
+ : /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ LOGBASE=unet3d_96x8x1_211019053509643409700
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019053509643409700
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019053509643409700
+ readonly _cont_name=image_segmentation
+ _cont_name=image_segmentation
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07360/slurm_script: line 39: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ srun --ntasks=96 mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ srun --ntasks=96 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh --container-name=image_segmentation true
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019053509643409700_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=96 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C040C
Clearing cache on ip-0A0C041D
Clearing cache on ip-0A0C0416
Clearing cache on ip-0A0C041B
Clearing cache on ip-0A0C040E
Clearing cache on ip-0A0C042E
Clearing cache on ip-0A0C0409
Clearing cache on ip-0A0C040A
Clearing cache on ip-0A0C0413
Clearing cache on ip-0A0C0423
Clearing cache on ip-0A0C0424
Clearing cache on ip-0A0C041A
Clearing cache on ip-0A0C0418
Clearing cache on ip-0A0C0419
Clearing cache on ip-0A0C0420
Clearing cache on ip-0A0C0414
Clearing cache on ip-0A0C0434
Clearing cache on ip-0A0C0408
Clearing cache on ip-0A0C042C
Clearing cache on ip-0A0C0421
Clearing cache on ip-0A0C0427
Clearing cache on ip-0A0C0412
Clearing cache on ip-0A0C0410
Clearing cache on ip-0A0C0428
Clearing cache on ip-0A0C0426
Clearing cache on ip-0A0C043C
Clearing cache on ip-0A0C043F
Clearing cache on ip-0A0C041C
Clearing cache on ip-0A0C040B
Clearing cache on ip-0A0C0425
Clearing cache on ip-0A0C0411
Clearing cache on ip-0A0C0440
Clearing cache on ip-0A0C045A
Clearing cache on ip-0A0C043E
Clearing cache on ip-0A0C0471
Clearing cache on ip-0A0C0465
Clearing cache on ip-0A0C043A
Clearing cache on ip-0A0C0448
Clearing cache on ip-0A0C047A
Clearing cache on ip-0A0C041E
Clearing cache on ip-0A0C0442
Clearing cache on ip-0A0C045E
Clearing cache on ip-0A0C042A
Clearing cache on ip-0A0C0469
Clearing cache on ip-0A0C0452
Clearing cache on ip-0A0C0455
Clearing cache on ip-0A0C045B
Clearing cache on ip-0A0C044A
Clearing cache on ip-0A0C0474
Clearing cache on ip-0A0C0459
Clearing cache on ip-0A0C046A
Clearing cache on ip-0A0C0463
Clearing cache on ip-0A0C043D
Clearing cache on ip-0A0C0457
Clearing cache on ip-0A0C043B
Clearing cache on ip-0A0C0467
Clearing cache on ip-0A0C0479
Clearing cache on ip-0A0C041F
Clearing cache on ip-0A0C042F
Clearing cache on ip-0A0C0447
Clearing cache on ip-0A0C0439
Clearing cache on ip-0A0C042B
Clearing cache on ip-0A0C0462
Clearing cache on ip-0A0C0433
Clearing cache on ip-0A0C044E
Clearing cache on ip-0A0C0456
Clearing cache on ip-0A0C0477
Clearing cache on ip-0A0C0475
Clearing cache on ip-0A0C047D
Clearing cache on ip-0A0C0451
Clearing cache on ip-0A0C0422
Clearing cache on ip-0A0C0445
Clearing cache on ip-0A0C0476
Clearing cache on ip-0A0C047B
Clearing cache on ip-0A0C0518
Clearing cache on ip-0A0C044F
Clearing cache on ip-0A0C0480
Clearing cache on ip-0A0C045D
Clearing cache on ip-0A0C0430
Clearing cache on ip-0A0C047F
Clearing cache on ip-0A0C0481
Clearing cache on ip-0A0C045C
Clearing cache on ip-0A0C0454
Clearing cache on ip-0A0C0446
Clearing cache on ip-0A0C046D
Clearing cache on ip-0A0C0407
Clearing cache on ip-0A0C044B
Clearing cache on ip-0A0C0458
Clearing cache on ip-0A0C0431
Clearing cache on ip-0A0C0450
Clearing cache on ip-0A0C0417
Clearing cache on ip-0A0C0432
Clearing cache on ip-0A0C0453
Clearing cache on ip-0A0C047C
Clearing cache on ip-0A0C044C
Clearing cache on ip-0A0C0470
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=768 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:35:12 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
[1634621717.029509] [ip-0A0C0410:67933:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.085253] [ip-0A0C0410:67929:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.086836] [ip-0A0C040E:39197:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.087641] [ip-0A0C040B:94845:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.100065] [ip-0A0C0410:67931:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.143739] [ip-0A0C040B:94849:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.148208] [ip-0A0C040A:52814:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.149934] [ip-0A0C0410:67932:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.157253] [ip-0A0C040B:94847:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.165562] [ip-0A0C040E:39202:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.165826] [ip-0A0C040A:52813:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.177549] [ip-0A0C041F:54973:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.213749] [ip-0A0C045E:32727:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.216132] [ip-0A0C045E:32726:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.225219] [ip-0A0C0410:67935:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.226486] [ip-0A0C041F:54965:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.226793] [ip-0A0C040B:94848:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.229905] [ip-0A0C040A:52812:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.230931] [ip-0A0C040E:39201:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.231284] [ip-0A0C0463:25826:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.231761] [ip-0A0C0463:25823:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.231605] [ip-0A0C0410:67930:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.232197] [ip-0A0C0410:67934:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.234717] [ip-0A0C040E:39198:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.236479] [ip-0A0C0410:67928:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.241174] [ip-0A0C0428:40157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.244649] [ip-0A0C046D:20185:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.246279] [ip-0A0C043F:32451:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.247645] [ip-0A0C041D:48028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.248658] [ip-0A0C040B:94844:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.249540] [ip-0A0C0456:38936:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.254986] [ip-0A0C045A:35327:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.255290] [ip-0A0C040E:39200:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.256807] [ip-0A0C040C:63612:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.259731] [ip-0A0C0423:45175:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.259474] [ip-0A0C0430:77477:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.260807] [ip-0A0C041F:54967:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.264785] [ip-0A0C0423:45178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.265385] [ip-0A0C041E:51039:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.265152] [ip-0A0C043A:36617:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.268204] [ip-0A0C040C:63615:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.269243] [ip-0A0C040E:39204:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.273031] [ip-0A0C0518:49869:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.272669] [ip-0A0C040A:52816:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.273182] [ip-0A0C0458:39354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.273622] [ip-0A0C0458:39351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.275804] [ip-0A0C0445:41847:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.275849] [ip-0A0C041C:57045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.276517] [ip-0A0C041D:48030:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.281843] [ip-0A0C0409:12599:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.285671] [ip-0A0C0430:77475:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.288839] [ip-0A0C0421:53178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.288871] [ip-0A0C0421:53177:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.289341] [ip-0A0C0457:31708:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.290374] [ip-0A0C040B:94846:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.290723] [ip-0A0C040B:94850:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.292774] [ip-0A0C040B:94843:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.293776] [ip-0A0C040E:39199:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.293889] [ip-0A0C043A:36619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.295557] [ip-0A0C045D:22860:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.295988] [ip-0A0C040E:39203:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.296707] [ip-0A0C046A:26397:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.298379] [ip-0A0C0470:16453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.298404] [ip-0A0C0445:41845:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.304871] [ip-0A0C0457:31705:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.306586] [ip-0A0C046D:20189:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.307443] [ip-0A0C0455:30404:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.307382] [ip-0A0C0417:81843:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.310210] [ip-0A0C046D:20190:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.311672] [ip-0A0C043C:37413:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.312296] [ip-0A0C0480:14876:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.314680] [ip-0A0C0456:38934:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.314410] [ip-0A0C047B:22285:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.316247] [ip-0A0C0417:81845:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.317689] [ip-0A0C041F:54970:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.318158] [ip-0A0C045E:32734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.321440] [ip-0A0C047A:20633:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.324459] [ip-0A0C0428:40156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.324918] [ip-0A0C0411:50823:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.325487] [ip-0A0C040C:63613:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.325581] [ip-0A0C0476:11703:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.325907] [ip-0A0C0459:31668:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.328148] [ip-0A0C041E:51036:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.327283] [ip-0A0C042E:50301:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.328691] [ip-0A0C0455:30402:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.328851] [ip-0A0C0409:12582:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.328695] [ip-0A0C0421:53182:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.329159] [ip-0A0C0450:7119 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.330429] [ip-0A0C0434:39970:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.330816] [ip-0A0C0409:12603:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.334248] [ip-0A0C041E:51035:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.336248] [ip-0A0C0451:33843:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.336789] [ip-0A0C040A:52819:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.337509] [ip-0A0C040A:52815:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.339909] [ip-0A0C0456:38938:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.339801] [ip-0A0C047A:20631:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.340548] [ip-0A0C0518:49868:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.339952] [ip-0A0C0412:30721:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.340885] [ip-0A0C040A:52811:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.343236] [ip-0A0C045A:35328:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.343432] [ip-0A0C0471:20741:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.343083] [ip-0A0C042E:50304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.344544] [ip-0A0C0463:25831:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.344776] [ip-0A0C0451:33841:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.346954] [ip-0A0C0411:50824:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.348087] [ip-0A0C0428:40152:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.347620] [ip-0A0C040A:52818:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.349641] [ip-0A0C0463:25828:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.349921] [ip-0A0C047B:22289:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.349968] [ip-0A0C0470:16450:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.351489] [ip-0A0C0471:20740:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.354551] [ip-0A0C045D:22856:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.355347] [ip-0A0C0430:77473:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.355191] [ip-0A0C046A:26400:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.356004] [ip-0A0C043F:32454:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.359323] [ip-0A0C041D:48026:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.359936] [ip-0A0C0456:38933:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.359882] [ip-0A0C0518:49866:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.359940] [ip-0A0C0459:31666:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.362148] [ip-0A0C0476:11706:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.362662] [ip-0A0C0407:56003:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.363197] [ip-0A0C043A:36621:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.364695] [ip-0A0C043F:32449:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.365278] [ip-0A0C041F:54969:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.365348] [ip-0A0C041F:54966:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.365284] [ip-0A0C0462:62680:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.365626] [ip-0A0C0452:35060:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.367166] [ip-0A0C047B:22287:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.367482] [ip-0A0C041C:57068:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.368193] [ip-0A0C0475:17586:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.370111] [ip-0A0C0467:21500:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.370661] [ip-0A0C045E:32733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.374313] [ip-0A0C0445:41842:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.374859] [ip-0A0C0419:54960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.375784] [ip-0A0C043A:36620:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.376641] [ip-0A0C041F:54968:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.376800] [ip-0A0C041F:54974:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.377177] [ip-0A0C0440:30720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.379445] [ip-0A0C0408:75456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.379719] [ip-0A0C044A:30628:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.380467] [ip-0A0C0462:62705:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.381777] [ip-0A0C0452:35058:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.382066] [ip-0A0C0470:16457:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.382420] [ip-0A0C044F:29300:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.382402] [ip-0A0C044F:29305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.384023] [ip-0A0C0518:49870:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.384321] [ip-0A0C041C:57041:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.385773] [ip-0A0C0428:40153:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.386285] [ip-0A0C0434:39969:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.386747] [ip-0A0C0407:56006:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.387513] [ip-0A0C044B:34767:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.388031] [ip-0A0C047A:20637:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.389124] [ip-0A0C0475:17589:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.389375] [ip-0A0C0409:12590:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.390399] [ip-0A0C042E:50300:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.392275] [ip-0A0C045E:32728:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.392208] [ip-0A0C0480:14873:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.392569] [ip-0A0C045D:22863:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.392479] [ip-0A0C0465:23350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.393641] [ip-0A0C0446:39215:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.395825] [ip-0A0C0423:45177:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.396022] [ip-0A0C043F:32456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.396862] [ip-0A0C0418:47799:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.397004] [ip-0A0C0458:39357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.397568] [ip-0A0C045E:32729:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.396716] [ip-0A0C046A:26399:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.397091] [ip-0A0C0458:39350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.399717] [ip-0A0C044B:34763:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.401498] [ip-0A0C043F:32455:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.402049] [ip-0A0C0477:20429:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.402042] [ip-0A0C0421:53183:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.402265] [ip-0A0C0467:21497:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.402092] [ip-0A0C0477:20430:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.403265] [ip-0A0C0414:67989:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.403435] [ip-0A0C045E:32730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.403319] [ip-0A0C045A:35322:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.403135] [ip-0A0C046D:20191:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.404067] [ip-0A0C0452:35061:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.403731] [ip-0A0C0481:13783:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.403723] [ip-0A0C0481:13785:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.406296] [ip-0A0C0420:52437:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.407209] [ip-0A0C045A:35324:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.410298] [ip-0A0C0434:39976:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.410271] [ip-0A0C0408:75458:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.410738] [ip-0A0C0459:31667:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.411171] [ip-0A0C043D:27645:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.412299] [ip-0A0C041B:69295:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.412421] [ip-0A0C040C:63616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.414401] [ip-0A0C0479:16241:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.415075] [ip-0A0C0474:17491:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.415061] [ip-0A0C0413:83147:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.415530] [ip-0A0C0450:7116 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.415092] [ip-0A0C0474:17492:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.415734] [ip-0A0C0450:7121 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.415497] [ip-0A0C040C:63614:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.417241] [ip-0A0C0428:40158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.418288] [ip-0A0C0457:31704:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.419574] [ip-0A0C045E:32731:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.420333] [ip-0A0C047B:22288:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.420293] [ip-0A0C046A:26398:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.421409] [ip-0A0C0459:31669:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.422105] [ip-0A0C041E:51041:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.422002] [ip-0A0C0455:30408:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.422521] [ip-0A0C0476:11702:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.422818] [ip-0A0C0430:77471:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.422446] [ip-0A0C0412:30719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.423366] [ip-0A0C0463:25824:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.423543] [ip-0A0C0463:25827:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.423191] [ip-0A0C044E:28294:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.424009] [ip-0A0C0411:50826:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.424552] [ip-0A0C041D:48031:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.425017] [ip-0A0C043A:36618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.426118] [ip-0A0C0428:40154:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.427857] [ip-0A0C0430:77478:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.427787] [ip-0A0C041D:48027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.428937] [ip-0A0C0418:47793:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.429414] [ip-0A0C0456:38935:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.429807] [ip-0A0C0518:49865:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.430579] [ip-0A0C041A:74660:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.430753] [ip-0A0C0453:36941:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.431539] [ip-0A0C0467:21494:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.431746] [ip-0A0C043F:32452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.432627] [ip-0A0C043F:32450:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.432680] [ip-0A0C0445:41844:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.432980] [ip-0A0C043E:25028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.433988] [ip-0A0C0450:7120 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.434582] [ip-0A0C0423:45174:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.435027] [ip-0A0C0457:31702:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.435919] [ip-0A0C046D:20187:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.437947] [ip-0A0C041B:69264:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.438114] [ip-0A0C0431:41799:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.438706] [ip-0A0C0428:40155:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.438241] [ip-0A0C0462:62679:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.439308] [ip-0A0C0423:45200:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.439368] [ip-0A0C0446:39218:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.439394] [ip-0A0C0480:14877:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.439853] [ip-0A0C0420:52442:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.439885] [ip-0A0C041A:74661:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.440082] [ip-0A0C043C:37414:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.440576] [ip-0A0C0419:54981:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.441589] [ip-0A0C0456:38931:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.441065] [ip-0A0C0442:31191:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.441969] [ip-0A0C0419:54962:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.441567] [ip-0A0C042F:46367:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.441925] [ip-0A0C043C:37415:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.442310] [ip-0A0C043A:36622:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.442548] [ip-0A0C0447:38426:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.443343] [ip-0A0C0428:40159:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.444403] [ip-0A0C0417:81848:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.445843] [ip-0A0C0463:25825:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.446002] [ip-0A0C0430:77472:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.446012] [ip-0A0C041C:57044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.447707] [ip-0A0C0456:38932:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.447470] [ip-0A0C040C:63618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.447418] [ip-0A0C043C:37416:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.447759] [ip-0A0C043F:32453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.448799] [ip-0A0C0463:25830:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.449477] [ip-0A0C045B:39234:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.450256] [ip-0A0C0430:77476:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.450202] [ip-0A0C0445:41846:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.450962] [ip-0A0C0456:38937:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.451185] [ip-0A0C0424:40167:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.451292] [ip-0A0C040C:63617:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.451446] [ip-0A0C042B:49083:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.451584] [ip-0A0C040C:63619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.452855] [ip-0A0C045D:22858:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.453425] [ip-0A0C046D:20192:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.453783] [ip-0A0C047B:22283:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.453888] [ip-0A0C046D:20186:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.454190] [ip-0A0C045A:35326:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.455034] [ip-0A0C0408:75457:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.455693] [ip-0A0C0425:54463:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.456159] [ip-0A0C0470:16456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.456379] [ip-0A0C046D:20188:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.457105] [ip-0A0C041B:69269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.457225] [ip-0A0C043A:36616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.458999] [ip-0A0C0409:12598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.459230] [ip-0A0C0420:52440:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.460271] [ip-0A0C042A:41894:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.460584] [ip-0A0C0409:12584:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.460216] [ip-0A0C0417:81849:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.460760] [ip-0A0C0440:30715:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.461437] [ip-0A0C0448:43002:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.461557] [ip-0A0C0409:12588:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.461705] [ip-0A0C0416:38330:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.461558] [ip-0A0C0458:39353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.462310] [ip-0A0C0423:45173:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.463099] [ip-0A0C0423:45176:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.462706] [ip-0A0C0457:31703:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.463010] [ip-0A0C0421:53179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.464449] [ip-0A0C0423:45179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.464605] [ip-0A0C0414:67992:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.464647] [ip-0A0C0455:30401:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.464852] [ip-0A0C043A:36624:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.465505] [ip-0A0C0411:50829:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.466009] [ip-0A0C0409:12583:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.466092] [ip-0A0C045A:35329:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.465931] [ip-0A0C044E:28299:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.466215] [ip-0A0C041C:57040:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.466942] [ip-0A0C045A:35325:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.466922] [ip-0A0C041D:48025:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.467690] [ip-0A0C0445:41843:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.467507] [ip-0A0C042F:46365:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.467921] [ip-0A0C0451:33837:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.468042] [ip-0A0C0445:41849:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.469124] [ip-0A0C0416:38336:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.469026] [ip-0A0C0445:41848:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.470081] [ip-0A0C0458:39352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.470936] [ip-0A0C0471:20739:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.471011] [ip-0A0C0430:77474:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.472081] [ip-0A0C041E:51037:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.472224] [ip-0A0C0458:39355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.472559] [ip-0A0C0518:49871:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.472561] [ip-0A0C044F:29303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.473213] [ip-0A0C0518:49867:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.473294] [ip-0A0C045D:22861:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.473392] [ip-0A0C045D:22859:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.473523] [ip-0A0C041E:51034:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.473403] [ip-0A0C0454:35880:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.473915] [ip-0A0C0418:47794:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.474129] [ip-0A0C0470:16452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.475758] [ip-0A0C041E:51038:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.475716] [ip-0A0C044C:33551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.475763] [ip-0A0C044C:33546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.475925] [ip-0A0C0421:53180:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.477010] [ip-0A0C041D:48032:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.477429] [ip-0A0C045A:35323:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.477196] [ip-0A0C041D:48029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.477659] [ip-0A0C0479:16237:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.478385] [ip-0A0C0480:14879:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.478397] [ip-0A0C043E:25022:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.479109] [ip-0A0C0459:31664:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.479607] [ip-0A0C044A:30615:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.480010] [ip-0A0C0480:14878:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.480387] [ip-0A0C042A:41887:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.481011] [ip-0A0C043D:27648:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.481391] [ip-0A0C041E:51040:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.481464] [ip-0A0C0518:49872:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.481635] [ip-0A0C0465:23351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.482122] [ip-0A0C0446:39221:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.482471] [ip-0A0C0414:67997:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.482114] [ip-0A0C041C:57039:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.482947] [ip-0A0C0447:38429:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.482953] [ip-0A0C0465:23353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.484717] [ip-0A0C0414:67993:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.484286] [ip-0A0C0425:54460:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.484300] [ip-0A0C0476:11704:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.484871] [ip-0A0C0421:53176:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.485246] [ip-0A0C0442:31192:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.485905] [ip-0A0C0432:69629:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.486024] [ip-0A0C0453:36944:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.486097] [ip-0A0C0421:53181:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.486330] [ip-0A0C042C:44456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.486761] [ip-0A0C0424:40172:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.486878] [ip-0A0C041C:57043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.487269] [ip-0A0C0457:31701:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.487281] [ip-0A0C0457:31706:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.487663] [ip-0A0C047A:20638:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.487958] [ip-0A0C0458:39356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.487679] [ip-0A0C044E:28300:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.488235] [ip-0A0C0434:39972:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.488193] [ip-0A0C042E:50302:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.488878] [ip-0A0C0453:36945:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.489471] [ip-0A0C0411:50828:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.491181] [ip-0A0C0470:16451:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.491868] [ip-0A0C0451:33840:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.492431] [ip-0A0C0471:20734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.492418] [ip-0A0C041A:74675:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.493105] [ip-0A0C045D:22857:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.493151] [ip-0A0C045D:22862:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.494216] [ip-0A0C0462:62686:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.494873] [ip-0A0C0439:28629:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.494532] [ip-0A0C0422:73999:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.495144] [ip-0A0C0413:83146:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.495265] [ip-0A0C0413:83145:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.495892] [ip-0A0C047B:22286:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.497194] [ip-0A0C047B:22291:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.497681] [ip-0A0C0450:7117 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.497698] [ip-0A0C0457:31707:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.498056] [ip-0A0C0411:50827:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.498833] [ip-0A0C0417:81846:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.498937] [ip-0A0C0417:81844:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.499669] [ip-0A0C044F:29301:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.500416] [ip-0A0C047B:22290:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.500054] [ip-0A0C0481:13787:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.500689] [ip-0A0C0440:30716:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.500961] [ip-0A0C043C:37418:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.501425] [ip-0A0C041C:57042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.502969] [ip-0A0C0476:11701:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.503815] [ip-0A0C0455:30403:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.504072] [ip-0A0C0427:48082:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.504200] [ip-0A0C043E:25024:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.504730] [ip-0A0C0432:69631:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.504827] [ip-0A0C0412:30723:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.505527] [ip-0A0C0459:31671:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.506383] [ip-0A0C0413:83170:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.506459] [ip-0A0C042E:50305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.507380] [ip-0A0C046A:26396:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.508103] [ip-0A0C0434:39971:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.507687] [ip-0A0C046A:26394:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.508467] [ip-0A0C0459:31665:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.508798] [ip-0A0C047A:20636:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.509086] [ip-0A0C0455:30405:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.508697] [ip-0A0C046A:26393:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.509850] [ip-0A0C0451:33844:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.510336] [ip-0A0C042A:41915:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.510680] [ip-0A0C0455:30407:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.511271] [ip-0A0C0459:31670:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.511221] [ip-0A0C0412:30726:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.512908] [ip-0A0C0454:35885:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.513039] [ip-0A0C0455:30406:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.513282] [ip-0A0C046A:26395:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.513837] [ip-0A0C043B:36672:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.514393] [ip-0A0C0450:7122 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.515072] [ip-0A0C0470:16458:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.515157] [ip-0A0C0433:45208:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.515155] [ip-0A0C0433:45213:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.515824] [ip-0A0C0407:55999:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.515317] [ip-0A0C045C:32214:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.515963] [ip-0A0C042F:46371:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.517010] [ip-0A0C044A:30618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.518733] [ip-0A0C0407:56005:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.518055] [ip-0A0C042E:50303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.519042] [ip-0A0C0475:17591:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.519189] [ip-0A0C0470:16454:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.519655] [ip-0A0C044F:29306:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.519885] [ip-0A0C0451:33838:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.520111] [ip-0A0C0465:23356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.520247] [ip-0A0C042B:49084:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.520933] [ip-0A0C0451:33839:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.521201] [ip-0A0C0411:50825:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.521158] [ip-0A0C044B:34764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.520805] [ip-0A0C0412:30724:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.521517] [ip-0A0C0477:20426:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.522175] [ip-0A0C0448:43005:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.522829] [ip-0A0C0469:20993:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.523207] [ip-0A0C0427:48076:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.523536] [ip-0A0C0411:50830:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.524643] [ip-0A0C047C:25617:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.525766] [ip-0A0C045B:39235:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.525874] [ip-0A0C0408:75459:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.526713] [ip-0A0C045B:39232:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.526726] [ip-0A0C044A:30616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.526778] [ip-0A0C0417:81850:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.527475] [ip-0A0C0450:7118 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.527593] [ip-0A0C0450:7115 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.527421] [ip-0A0C0417:81847:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.527941] [ip-0A0C0476:11707:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.528128] [ip-0A0C043C:37419:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.528670] [ip-0A0C0424:40169:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.528789] [ip-0A0C043D:27644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.528547] [ip-0A0C0476:11705:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.528903] [ip-0A0C042C:44461:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.528955] [ip-0A0C0476:11708:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.529684] [ip-0A0C0433:45214:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.530403] [ip-0A0C0420:52441:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.530172] [ip-0A0C0462:62683:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.530895] [ip-0A0C0419:54955:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.531228] [ip-0A0C0471:20736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.531196] [ip-0A0C0480:14875:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.531470] [ip-0A0C047A:20632:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.531967] [ip-0A0C0452:35063:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.532078] [ip-0A0C0431:41794:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.533121] [ip-0A0C0480:14874:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.534391] [ip-0A0C043C:37417:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.535359] [ip-0A0C0480:14872:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.536059] [ip-0A0C0475:17585:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.536627] [ip-0A0C047A:20635:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.536653] [ip-0A0C043C:37412:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.537726] [ip-0A0C042C:44457:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.538335] [ip-0A0C0475:17588:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.538572] [ip-0A0C047A:20634:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.538570] [ip-0A0C041B:69268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.538725] [ip-0A0C042B:49089:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.538881] [ip-0A0C0451:33842:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.539367] [ip-0A0C0434:39973:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.539522] [ip-0A0C044F:29302:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.539497] [ip-0A0C0434:39974:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.539859] [ip-0A0C0471:20735:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.539702] [ip-0A0C0434:39975:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.541562] [ip-0A0C0418:47792:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.541735] [ip-0A0C0479:16240:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.541885] [ip-0A0C044F:29304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.541541] [ip-0A0C042E:50299:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.542633] [ip-0A0C044B:34769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.542810] [ip-0A0C0407:56002:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.543090] [ip-0A0C0471:20737:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.544952] [ip-0A0C0481:13782:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.544786] [ip-0A0C042E:50306:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.546137] [ip-0A0C0440:30717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.546263] [ip-0A0C0467:21498:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.546060] [ip-0A0C0412:30722:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.547344] [ip-0A0C044A:30617:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.548231] [ip-0A0C0471:20738:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.548125] [ip-0A0C044F:29307:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.548179] [ip-0A0C0465:23349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.547948] [ip-0A0C0442:31194:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.548553] [ip-0A0C0422:74001:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.550336] [ip-0A0C043B:36678:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.551124] [ip-0A0C0431:41797:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.552152] [ip-0A0C0426:49730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.552274] [ip-0A0C0452:35059:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.553545] [ip-0A0C041B:69266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.554012] [ip-0A0C0419:54959:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.554389] [ip-0A0C0465:23352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.555110] [ip-0A0C0479:16235:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.554904] [ip-0A0C0422:73997:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.555643] [ip-0A0C0454:35882:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.555617] [ip-0A0C0462:62682:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.557091] [ip-0A0C0477:20427:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.557000] [ip-0A0C044B:34770:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.558046] [ip-0A0C044E:28298:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.559507] [ip-0A0C042B:49085:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.559966] [ip-0A0C0452:35062:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.560944] [ip-0A0C045B:39229:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.560964] [ip-0A0C0407:55998:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.561995] [ip-0A0C0467:21493:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.562284] [ip-0A0C0425:54464:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.562521] [ip-0A0C0440:30713:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.562808] [ip-0A0C0474:17486:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.563215] [ip-0A0C0474:17489:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.564160] [ip-0A0C043D:27641:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.563965] [ip-0A0C0412:30720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.564050] [ip-0A0C047D:16303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.564056] [ip-0A0C0412:30725:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.565182] [ip-0A0C0469:20989:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.566922] [ip-0A0C0407:56001:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.567283] [ip-0A0C0467:21499:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.567832] [ip-0A0C0447:38433:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.567946] [ip-0A0C0413:83143:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.568717] [ip-0A0C0462:62681:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.569590] [ip-0A0C0407:56000:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.569602] [ip-0A0C0422:74000:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.570173] [ip-0A0C0408:75453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.570336] [ip-0A0C0408:75460:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.570356] [ip-0A0C0462:62684:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.570750] [ip-0A0C0467:21495:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.570613] [ip-0A0C0481:13780:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.571319] [ip-0A0C0440:30719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.572184] [ip-0A0C0439:28630:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.572628] [ip-0A0C0467:21496:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.573084] [ip-0A0C0432:69632:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.574312] [ip-0A0C043B:36676:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.577000] [ip-0A0C0452:35056:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.578002] [ip-0A0C0408:75455:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.577571] [ip-0A0C045C:32215:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.579410] [ip-0A0C0465:23355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.579403] [ip-0A0C0413:83149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.579864] [ip-0A0C0440:30714:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.580064] [ip-0A0C0452:35057:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.580254] [ip-0A0C0475:17590:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.580126] [ip-0A0C045C:32218:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.580945] [ip-0A0C044A:30619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.581105] [ip-0A0C0446:39216:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.580803] [ip-0A0C041A:74659:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.581145] [ip-0A0C0446:39220:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.581274] [ip-0A0C0419:54958:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.581627] [ip-0A0C0419:54957:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.581953] [ip-0A0C0440:30718:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.582490] [ip-0A0C043D:27642:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.582566] [ip-0A0C045C:32213:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.583422] [ip-0A0C0453:36939:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.583825] [ip-0A0C044A:30621:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.584120] [ip-0A0C0477:20431:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.584358] [ip-0A0C0431:41796:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.584319] [ip-0A0C0408:75454:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.584313] [ip-0A0C047C:25619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.584670] [ip-0A0C0426:49732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.584741] [ip-0A0C0475:17587:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.584609] [ip-0A0C044B:34766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.585292] [ip-0A0C044A:30614:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.585480] [ip-0A0C0474:17493:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.585737] [ip-0A0C0479:16236:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.585822] [ip-0A0C044B:34765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.586775] [ip-0A0C043E:25023:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.587040] [ip-0A0C047F:18933:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.587444] [ip-0A0C044B:34768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.588856] [ip-0A0C0475:17592:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.589302] [ip-0A0C043B:36674:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.589102] [ip-0A0C044E:28295:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.589512] [ip-0A0C047C:25621:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.590060] [ip-0A0C0414:67991:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.591023] [ip-0A0C0439:28631:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.591242] [ip-0A0C0465:23354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.591460] [ip-0A0C0416:38329:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.591636] [ip-0A0C0424:40168:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.592020] [ip-0A0C0432:69634:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.592763] [ip-0A0C0419:54956:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.593458] [ip-0A0C0481:13784:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.593919] [ip-0A0C041B:69267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.594499] [ip-0A0C0448:43006:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.594517] [ip-0A0C0477:20432:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.594547] [ip-0A0C0418:47815:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.594737] [ip-0A0C0418:47796:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.597197] [ip-0A0C0477:20433:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.597409] [ip-0A0C042F:46366:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.598459] [ip-0A0C0439:28634:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.599192] [ip-0A0C0418:47795:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.599563] [ip-0A0C0447:38432:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.600007] [ip-0A0C0420:52436:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.600599] [ip-0A0C0477:20428:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.600892] [ip-0A0C0474:17488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.601869] [ip-0A0C0413:83148:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.602855] [ip-0A0C0418:47798:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.602853] [ip-0A0C0413:83144:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.605639] [ip-0A0C0446:39219:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.605738] [ip-0A0C0446:39217:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.606022] [ip-0A0C0453:36943:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.607079] [ip-0A0C0431:41804:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.607301] [ip-0A0C0414:67995:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.607419] [ip-0A0C041B:69265:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.607687] [ip-0A0C0420:52439:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.608242] [ip-0A0C0414:67996:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.608126] [ip-0A0C043D:27643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.608146] [ip-0A0C047C:25618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.608021] [ip-0A0C0481:13781:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.608444] [ip-0A0C0427:48078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.608298] [ip-0A0C041A:74656:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.608473] [ip-0A0C041B:69270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.608760] [ip-0A0C044C:33550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.608479] [ip-0A0C044E:28301:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.608733] [ip-0A0C044E:28297:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.609403] [ip-0A0C0446:39242:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.609781] [ip-0A0C044E:28296:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.611194] [ip-0A0C0414:67994:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.610535] [ip-0A0C042F:46368:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.611918] [ip-0A0C0420:52435:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.612023] [ip-0A0C0420:52438:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.612113] [ip-0A0C0481:13786:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.613540] [ip-0A0C044C:33552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.613987] [ip-0A0C0442:31195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.614964] [ip-0A0C045B:39236:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.614972] [ip-0A0C0479:16234:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.616775] [ip-0A0C0479:16242:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.617172] [ip-0A0C0469:20996:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.617448] [ip-0A0C044C:33547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.617922] [ip-0A0C0474:17490:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.618597] [ip-0A0C0474:17487:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.619359] [ip-0A0C043D:27646:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.620059] [ip-0A0C0469:20994:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.620539] [ip-0A0C042A:41891:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.620650] [ip-0A0C043E:25026:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.622634] [ip-0A0C045B:39231:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.622315] [ip-0A0C041A:74658:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.623213] [ip-0A0C0479:16238:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.623491] [ip-0A0C041A:74655:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.624459] [ip-0A0C0425:54466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.625553] [ip-0A0C042B:49088:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.625787] [ip-0A0C0447:38456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.625974] [ip-0A0C043D:27647:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.626165] [ip-0A0C041A:74657:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.627982] [ip-0A0C0454:35884:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.628083] [ip-0A0C0453:36942:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.629032] [ip-0A0C042C:44455:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.629105] [ip-0A0C0454:35886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.629739] [ip-0A0C0453:36938:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.630285] [ip-0A0C043E:25029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.630464] [ip-0A0C0442:31193:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.631802] [ip-0A0C0453:36940:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.632831] [ip-0A0C044C:33553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.634295] [ip-0A0C0431:41801:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.635139] [ip-0A0C042A:41888:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.636171] [ip-0A0C042B:49086:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.636072] [ip-0A0C0427:48080:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.636570] [ip-0A0C042B:49087:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.637268] [ip-0A0C0448:43004:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.637923] [ip-0A0C0416:38332:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.637638] [ip-0A0C0442:31196:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.638128] [ip-0A0C0424:40170:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.638661] [ip-0A0C0448:42999:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.640309] [ip-0A0C0431:41793:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.640356] [ip-0A0C0431:41795:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.640443] [ip-0A0C0447:38427:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.641122] [ip-0A0C0424:40174:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.640783] [ip-0A0C042F:46364:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.640949] [ip-0A0C042F:46369:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.644355] [ip-0A0C042F:46370:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.645346] [ip-0A0C045B:39233:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.645404] [ip-0A0C045B:39230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.644952] [ip-0A0C0442:31190:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.645047] [ip-0A0C0442:31189:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.646638] [ip-0A0C043B:36670:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.646522] [ip-0A0C0425:54465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.647781] [ip-0A0C0432:69633:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.649569] [ip-0A0C044C:33549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.650108] [ip-0A0C047F:18934:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.650737] [ip-0A0C0447:38430:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.651004] [ip-0A0C044C:33548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.650972] [ip-0A0C0416:38333:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.651945] [ip-0A0C0425:54467:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.653194] [ip-0A0C047D:16301:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.653831] [ip-0A0C043E:25027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.654644] [ip-0A0C0447:38428:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.654877] [ip-0A0C042B:49082:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.654898] [ip-0A0C042A:41892:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.655681] [ip-0A0C043E:25025:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.656019] [ip-0A0C0432:69627:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.656662] [ip-0A0C042A:41890:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.657485] [ip-0A0C0426:49743:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.657731] [ip-0A0C0433:45215:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.657658] [ip-0A0C0425:54461:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.660486] [ip-0A0C0454:35881:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.661017] [ip-0A0C0448:43029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.661329] [ip-0A0C0448:43001:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.662126] [ip-0A0C0416:38331:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.662335] [ip-0A0C0424:40195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.663286] [ip-0A0C0425:54462:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.663595] [ip-0A0C0424:40196:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.664130] [ip-0A0C0416:38355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.664291] [ip-0A0C0416:38334:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.664848] [ip-0A0C0427:48079:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.666263] [ip-0A0C0448:43003:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.666450] [ip-0A0C042C:44458:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.667715] [ip-0A0C0432:69628:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.669318] [ip-0A0C042A:41889:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.670224] [ip-0A0C0433:45211:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.673191] [ip-0A0C0432:69630:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.674533] [ip-0A0C0469:20991:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.676478] [ip-0A0C0439:28632:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.676584] [ip-0A0C0454:35883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.676652] [ip-0A0C0454:35879:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.677505] [ip-0A0C043B:36673:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.678470] [ip-0A0C042C:44462:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.678880] [ip-0A0C043B:36677:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.685026] [ip-0A0C0439:28633:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.686625] [ip-0A0C0422:73996:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.688264] [ip-0A0C0433:45210:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.688178] [ip-0A0C043B:36671:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.688233] [ip-0A0C0422:73998:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.691724] [ip-0A0C0439:28636:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.693905] [ip-0A0C0433:45209:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.694616] [ip-0A0C0433:45207:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.695909] [ip-0A0C0427:48081:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.696167] [ip-0A0C0422:73994:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.698065] [ip-0A0C045C:32217:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.698129] [ip-0A0C045C:32216:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.700537] [ip-0A0C042C:44460:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.701438] [ip-0A0C0427:48077:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.702494] [ip-0A0C0427:48083:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.702333] [ip-0A0C0422:73995:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.704443] [ip-0A0C042C:44459:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.708965] [ip-0A0C045C:32211:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.711080] [ip-0A0C045C:32212:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.714413] [ip-0A0C0439:28635:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.720637] [ip-0A0C047D:16307:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.721127] [ip-0A0C047C:25615:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.721488] [ip-0A0C047F:18932:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.722054] [ip-0A0C047C:25620:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.722130] [ip-0A0C047C:25616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.726130] [ip-0A0C0469:20988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.726685] [ip-0A0C0469:20992:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.727338] [ip-0A0C047F:18937:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.728130] [ip-0A0C0469:20990:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.729070] [ip-0A0C047D:16306:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.732695] [ip-0A0C0426:49729:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.733699] [ip-0A0C0426:49733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.735109] [ip-0A0C047C:25614:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.743613] [ip-0A0C0426:49728:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.747093] [ip-0A0C0426:49727:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.751316] [ip-0A0C0426:49731:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.758309] [ip-0A0C047F:18935:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.763321] [ip-0A0C047D:16300:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.768142] [ip-0A0C047D:16304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.769896] [ip-0A0C047D:16305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.774928] [ip-0A0C047F:18938:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.779792] [ip-0A0C047D:16302:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.793855] [ip-0A0C047F:18936:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621717.796143] [ip-0A0C047F:18939:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
:::MLLOG {"namespace": "", "time_ms": 1634621718698, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634621718737, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634621718738, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1634621718738, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634621718738, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1634621718738, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1634621718738, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "96xND96amsr_A100_v4", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:29] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:35:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[ip-0A0C0409:0:12584 - context.c:584] INFO job (ID: 867538852360264545) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:12584 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:12584 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:12588 - context.c:584] INFO job (ID: 867538640555708572) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:12588 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:12588 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:12590 - context.c:584] INFO job (ID: 867537956503023855) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:12590 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:12590 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:12598 - context.c:584] INFO job (ID: 867537853050692782) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:12598 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:12598 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:12582 - context.c:584] INFO job (ID: 867538743608995692) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:12582 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:12582 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:12603 - context.c:584] INFO job (ID: 867537829516581937) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:12603 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:12603 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:12583 - context.c:584] INFO job (ID: 867538446759272916) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:12583 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:12583 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:12599 - context.c:584] INFO job (ID: 867538607035121455) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:12599 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:12599 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621813815, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1970562482, "metadata": {"file": "main.py", "lineno": 72}}
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621813816, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 138}}
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621813816, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 139}}
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621813816, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1500, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 140}}
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621813816, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 142}}
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621813816, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 143}}
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621813816, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 144}}
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621813816, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 145}}
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621813817, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 146}}
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621813817, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 147}}
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621813817, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 148}}
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621813817, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 149}}
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:53] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:36:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621837693, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1634621837724, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621837728, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1634621837728, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 95}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621840211, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 84, "metadata": {"file": "main.py", "lineno": 136}}
:::MLLOG {"namespace": "", "time_ms": 1634621840211, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1634621840211, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634621840212, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1, "epoch_count": 20}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621841749, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2186.323751919238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621841749, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.02989933774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621841749, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2186.323751919238, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634621841749, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621841749, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621842421, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4998.986018450991, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621842422, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.04976556291390729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621842422, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4998.986018450991, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621842422, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621842422, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621843082, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5096.204854044531, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621843082, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0696317880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621843082, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5096.204854044531, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634621843082, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621843082, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621843736, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5138.120077803563, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621843737, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.08949801324503312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621843737, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5138.120077803563, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 60}}
:::MLLOG {"namespace": "", "time_ms": 1634621843737, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621843737, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621844366, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5339.924384745088, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621844367, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.10936423841059603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621844367, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5339.924384745088, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 80}}
:::MLLOG {"namespace": "", "time_ms": 1634621844367, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621844367, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621844991, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5384.871941343178, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621844991, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.12923046357615892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621844992, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5384.871941343178, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 100}}
:::MLLOG {"namespace": "", "time_ms": 1634621844992, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621844992, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621845625, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5309.34758014112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621845625, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.14909668874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621845625, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5309.34758014112, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634621845625, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621845625, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621846249, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5392.140796214254, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621846249, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.16896291390728477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621846249, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5392.140796214254, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1634621846249, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621846249, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621846871, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5403.650669126765, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621846871, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.18882913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621846871, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5403.650669126765, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 160}}
:::MLLOG {"namespace": "", "time_ms": 1634621846872, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621846872, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621847496, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5381.577753737222, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621847496, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.20869536423841056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621847497, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5381.577753737222, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 180}}
:::MLLOG {"namespace": "", "time_ms": 1634621847497, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621847497, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621848133, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5283.207699245955, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621848133, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.22856158940397348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621848133, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5283.207699245955, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 200}}
:::MLLOG {"namespace": "", "time_ms": 1634621848133, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621848134, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621848755, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5407.953349851935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621848756, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.24842781456953641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621848756, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5407.953349851935, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 220}}
:::MLLOG {"namespace": "", "time_ms": 1634621848756, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621848756, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621849386, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5333.75827198612, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621849386, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26829403973509935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621849386, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5333.75827198612, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 240}}
:::MLLOG {"namespace": "", "time_ms": 1634621849387, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621849387, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621850005, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5431.051382960521, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621850006, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.28816026490066227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621850006, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5431.051382960521, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 260}}
:::MLLOG {"namespace": "", "time_ms": 1634621850006, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621850006, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621850636, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5334.931383014968, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621850636, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3080264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621850637, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5334.931383014968, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1634621850637, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621850637, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621851262, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5378.5995962862, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621851262, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32789271523178803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621851262, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5378.5995962862, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 300}}
:::MLLOG {"namespace": "", "time_ms": 1634621851262, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621851262, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621851900, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5273.459394187949, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621851900, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.347758940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621851900, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5273.459394187949, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 320}}
:::MLLOG {"namespace": "", "time_ms": 1634621851900, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621851900, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621852527, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5360.879173047822, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621852528, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36762516556291386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621852528, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5360.879173047822, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 340}}
:::MLLOG {"namespace": "", "time_ms": 1634621852528, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621852528, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621853154, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5364.719812162537, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621853155, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3874913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621853155, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5364.719812162537, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 360}}
:::MLLOG {"namespace": "", "time_ms": 1634621853155, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621853155, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621853794, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5258.626534589625, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621853795, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.40735761589403974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621853795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5258.626534589625, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 380}}
:::MLLOG {"namespace": "", "time_ms": 1634621853795, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621853795, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621854417, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5402.737101906982, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621854418, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621854418, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5402.737101906982, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 400}}
:::MLLOG {"namespace": "", "time_ms": 1634621854418, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621854418, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621855044, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5369.959041895085, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621855044, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.44709006622516556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621855044, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5369.959041895085, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1634621855045, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621855045, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621855673, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5350.430012817164, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621855673, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4669562913907285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621855673, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5350.430012817164, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 440}}
:::MLLOG {"namespace": "", "time_ms": 1634621855674, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621855674, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621856302, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5348.413672915842, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621856302, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4868225165562914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621856302, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5348.413672915842, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 460}}
:::MLLOG {"namespace": "", "time_ms": 1634621856303, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621856303, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621856925, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5396.392097518164, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621856926, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5066887417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621856926, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5396.392097518164, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 480}}
:::MLLOG {"namespace": "", "time_ms": 1634621856926, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621856926, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621857551, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5376.873774806239, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621857552, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5265549668874172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621857552, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5376.873774806239, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 500}}
:::MLLOG {"namespace": "", "time_ms": 1634621857552, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621857552, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621858170, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5436.152618023301, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621858171, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5464211920529801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621858171, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5436.152618023301, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 520}}
:::MLLOG {"namespace": "", "time_ms": 1634621858171, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621858171, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621858795, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5386.734673283857, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621858795, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.566287417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621858795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5386.734673283857, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 540}}
:::MLLOG {"namespace": "", "time_ms": 1634621858796, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621858796, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621859415, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5422.47737277561, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621859416, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5861536423841059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621859416, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5422.47737277561, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1634621859416, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621859416, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621860052, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5286.687919163485, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621860052, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6060198675496689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621860052, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5286.687919163485, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634621860053, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621860053, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621860671, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5438.77084808688, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621860671, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6258860927152318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621860671, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5438.77084808688, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 600}}
:::MLLOG {"namespace": "", "time_ms": 1634621860671, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621860671, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621861293, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5405.385432356457, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621861293, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6457523178807947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621861293, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5405.385432356457, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 620}}
:::MLLOG {"namespace": "", "time_ms": 1634621861294, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621861294, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621861916, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5401.743094052888, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621861916, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6656185430463576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621861916, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5401.743094052888, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 640}}
:::MLLOG {"namespace": "", "time_ms": 1634621861916, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621861916, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621862536, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5425.201484717435, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621862536, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6854847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621862536, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5425.201484717435, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 660}}
:::MLLOG {"namespace": "", "time_ms": 1634621862536, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621862537, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621863156, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5427.72973622507, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621863156, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7053509933774835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621863156, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5427.72973622507, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 680}}
:::MLLOG {"namespace": "", "time_ms": 1634621863156, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621863156, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621863779, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5399.969285049759, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621863779, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7252172185430463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621863779, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5399.969285049759, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 700}}
:::MLLOG {"namespace": "", "time_ms": 1634621863779, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621863779, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621864403, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5391.7220165613535, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621864403, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7450834437086092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621864403, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5391.7220165613535, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 720}}
:::MLLOG {"namespace": "", "time_ms": 1634621864403, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621864403, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621865026, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5394.194376631996, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621865027, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7649496688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621865027, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5394.194376631996, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 740}}
:::MLLOG {"namespace": "", "time_ms": 1634621865027, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621865027, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621865642, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5467.013308640433, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621865642, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7848158940397352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621865642, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5467.013308640433, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 760}}
:::MLLOG {"namespace": "", "time_ms": 1634621865643, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621865643, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621866261, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5434.242985118827, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621866262, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8046821192052981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621866262, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5434.242985118827, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634621866262, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621866262, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621866876, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5474.814146626855, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621866876, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8245483443708609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621866876, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5474.814146626855, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 800}}
:::MLLOG {"namespace": "", "time_ms": 1634621866876, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621866876, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621867491, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5466.292329467108, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621867492, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621867492, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5466.292329467108, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 820}}
:::MLLOG {"namespace": "", "time_ms": 1634621867492, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621867492, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621868108, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5455.783423438072, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621868108, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8642807947019867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621868108, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5455.783423438072, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 840}}
:::MLLOG {"namespace": "", "time_ms": 1634621868109, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621868109, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621868724, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5463.34041989012, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621868724, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8841470198675497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621868724, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5463.34041989012, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 860}}
:::MLLOG {"namespace": "", "time_ms": 1634621868725, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621868725, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621869340, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5466.451352642914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621869340, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9040132450331126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621869340, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5466.451352642914, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 880}}
:::MLLOG {"namespace": "", "time_ms": 1634621869340, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621869341, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621869957, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5452.992651756076, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621869957, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9238794701986754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621869957, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5452.992651756076, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 900}}
:::MLLOG {"namespace": "", "time_ms": 1634621869958, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621869958, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621870577, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5423.130492738945, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621870578, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9437456953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621870578, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5423.130492738945, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 920}}
:::MLLOG {"namespace": "", "time_ms": 1634621870578, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621870578, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621871198, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5418.430704306797, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621871199, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9636119205298014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621871199, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5418.430704306797, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 940}}
:::MLLOG {"namespace": "", "time_ms": 1634621871199, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621871199, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621871821, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5402.0453993999545, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621871822, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9834781456953643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621871822, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5402.0453993999545, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 960}}
:::MLLOG {"namespace": "", "time_ms": 1634621871822, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621871822, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621872453, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5323.309905200864, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621872454, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0033443708609273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621872454, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5323.309905200864, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 980}}
:::MLLOG {"namespace": "", "time_ms": 1634621872528, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621872529, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621872545, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621872973, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8768070340156555, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621872973, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621873136, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5530.657300339268, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621873137, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0232105960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621873137, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5530.657300339268, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621873312, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621873312, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621873326, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621873732, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8933862447738647, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621873732, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621873966, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5136.0546490625775, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621873967, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.043076821192053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621873967, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5136.0546490625775, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621874018, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621874018, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621874033, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621874450, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.884596049785614, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621874450, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621874646, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5353.029332367021, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621874647, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.062943046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621874647, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5353.029332367021, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621874699, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621874700, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621874715, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621875148, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8731311559677124, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621875148, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621875353, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5141.995126859992, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621875354, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0828092715231787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621875354, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5141.995126859992, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621875396, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621875396, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621875411, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621875830, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8717796802520752, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621875830, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621876026, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5331.712115737842, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621876027, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1026754966887418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621876027, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5331.712115737842, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621876079, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621876079, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621876094, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621876503, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8850336074829102, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621876504, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621876707, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5349.284593999997, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621876708, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1225417218543046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621876708, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5349.284593999997, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621876749, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621876749, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621876764, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621877188, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8809170722961426, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621877188, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621877382, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5309.667638589414, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621877383, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1424079470198676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621877383, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5309.667638589414, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621877440, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621877440, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621877454, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621877890, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.884346604347229, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621877890, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621878089, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5182.835844114005, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621878089, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1622741721854304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621878089, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5182.835844114005, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621878139, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621878139, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621878154, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621878568, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8823009729385376, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621878568, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621878757, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5436.188266080752, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621878758, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1821403973509934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621878758, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5436.188266080752, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621878803, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621878803, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621878818, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621879263, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8885583877563477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621879263, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621879459, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5126.274420792225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621879459, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2020066225165562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621879459, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5126.274420792225, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621879508, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621879508, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621879523, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621879967, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8944904804229736, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621879967, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621880176, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5027.63619576901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621880177, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2218728476821192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621880177, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5027.63619576901, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621880213, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621880214, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621880230, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621880671, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8843847513198853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621880671, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621880875, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5082.081650919259, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621880876, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.241739072847682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621880876, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5082.081650919259, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621880919, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621880919, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621880934, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621881373, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8711022138595581, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621881373, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621881581, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5076.710282447695, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621881581, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621881581, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5076.710282447695, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621881623, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621881623, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621881638, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621882071, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8758147954940796, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621882071, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621882270, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5197.713263980632, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621882270, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.281471523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621882270, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5197.713263980632, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621882317, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621882317, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621882331, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621882747, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8821942210197449, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621882747, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621882945, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5348.821691539268, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621882946, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3013377483443709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621882946, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5348.821691539268, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621882986, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621882986, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621883001, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621883457, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8865622282028198, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621883457, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621883661, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4978.13331411719, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621883661, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3212039735099337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621883661, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4978.13331411719, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621883701, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621883702, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621883717, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621884133, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8871347904205322, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621884133, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621884325, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5391.573499503418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621884325, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3410701986754967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621884326, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5391.573499503418, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621884367, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621884367, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621884382, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621884803, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8636705875396729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621884803, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621885000, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5314.2747506682035, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621885000, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3609364238410595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621885000, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5314.2747506682035, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621885039, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621885039, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621885054, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621885482, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8613643646240234, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621885482, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621885675, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5284.848143028679, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621885675, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3808026490066225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621885676, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5284.848143028679, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621885716, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621885716, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621885731, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621886174, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8487973213195801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621886174, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621886375, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5102.149505709699, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621886375, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4006688741721853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621886375, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5102.149505709699, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621886421, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621886421, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621886436, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621886877, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8674104809761047, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621886877, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621887080, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5102.6353580298055, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621887080, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4205350993377484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621887080, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5102.6353580298055, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621887129, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621887129, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621887144, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621887559, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8812421560287476, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621887560, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621887751, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5401.326961904806, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621887752, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4404013245033112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621887752, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5401.326961904806, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621887791, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621887791, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621887806, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621888249, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8803962469100952, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621888249, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621888447, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5125.95371574374, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621888447, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4602675496688742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621888447, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5125.95371574374, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621888483, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621888483, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621888498, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621888928, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8840926885604858, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621888928, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621889127, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5224.756625455451, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621889127, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4801337748344372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621889127, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5224.756625455451, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621889200, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621889201, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621889215, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621889672, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8951224088668823, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621889672, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621889889, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4884.134167545505, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621889889, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621889889, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4884.134167545505, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621889926, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621889926, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621889941, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621890370, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8870936036109924, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621890370, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621890561, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5295.1877080400245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621890561, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621890561, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5295.1877080400245, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621890601, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621890602, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621890616, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621891054, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8732243776321411, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621891055, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621891249, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5186.71566485972, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621891250, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621891250, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5186.71566485972, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621891291, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621891291, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621891306, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621891761, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8841328620910645, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621891761, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621891998, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4754.923649879244, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621891998, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621891998, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4754.923649879244, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621892041, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621892041, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621892056, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621892490, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8703579902648926, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621892490, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621892702, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5085.0835025611495, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621892702, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621892703, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5085.0835025611495, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621892743, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621892744, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621892759, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621893183, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9006926417350769, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621893183, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621893391, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5194.303216423197, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621893391, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621893391, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5194.303216423197, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621893427, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621893427, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621893442, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621893886, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8781841397285461, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621893887, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621894081, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5143.920762474304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621894081, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621894081, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5143.920762474304, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621894121, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621894121, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621894136, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621894576, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8888221383094788, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621894576, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621894773, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5158.803781232064, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621894773, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621894773, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5158.803781232064, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621894813, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621894813, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621894828, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621895266, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8989427089691162, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621895266, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621895460, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5196.549896477278, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621895460, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621895461, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5196.549896477278, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621895496, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621895496, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621895511, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621895954, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9009323120117188, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621895954, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621896150, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5137.280972626294, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621896151, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621896151, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5137.280972626294, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621896186, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621896186, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621896201, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621896630, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8888604640960693, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621896630, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621896824, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5272.960197795011, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621896824, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621896824, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5272.960197795011, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621896870, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621896870, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621896885, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621897302, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8979401588439941, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621897302, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621897494, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5389.763074501309, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621897494, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621897494, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5389.763074501309, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621897535, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621897536, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621897551, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621897972, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8918007612228394, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621897972, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621898165, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5342.809216275389, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621898165, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621898165, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5342.809216275389, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621898201, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621898202, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621898216, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621898648, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.889877200126648, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621898648, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621898848, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5200.300604167735, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621898848, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621898848, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5200.300604167735, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621898895, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621898895, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621898910, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621899339, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8772639036178589, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621899339, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621899534, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5259.2702182359235, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621899534, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621899535, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5259.2702182359235, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621899579, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621899580, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621899594, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621900003, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8853647708892822, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621900003, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621900197, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5441.866463091827, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621900198, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621900198, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5441.866463091827, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621900240, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621900241, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621900255, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621900680, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9066466093063354, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621900680, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621900873, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5313.419197945946, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621900874, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621900874, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5313.419197945946, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621900912, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621900913, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621900927, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621901351, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9015147686004639, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621901352, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621901548, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5292.600516458936, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621901548, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621901548, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5292.600516458936, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621901603, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621901603, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621901617, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621902046, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9005908966064453, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621902046, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621902251, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5189.381874580911, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621902251, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621902251, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5189.381874580911, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621902294, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621902294, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621902309, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621902729, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8945916891098022, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621902729, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621902923, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5348.864323942524, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621902923, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621902923, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5348.864323942524, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621902966, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621902967, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621902981, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621903454, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9072222709655762, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621903455, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621903656, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4875.867570785194, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621903656, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621903656, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4875.867570785194, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621903695, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621903695, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621903710, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621904151, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8954660296440125, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621904151, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621904354, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5096.848096664937, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621904355, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621904355, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5096.848096664937, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621904407, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621904407, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621904422, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621904850, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8984525203704834, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621904850, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621905047, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5255.134159565535, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621905047, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621905047, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5255.134159565535, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621905088, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621905089, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621905104, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621905537, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9040163159370422, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621905537, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621905735, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5196.371700015266, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621905736, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621905736, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5196.371700015266, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621905778, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621905778, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621905793, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621906224, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8850145936012268, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621906224, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621906422, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5220.309154392726, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621906422, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621906422, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5220.309154392726, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621906460, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621906461, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621906475, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621906920, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.90061354637146, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621906920, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621907118, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5109.230290677566, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621907119, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621907119, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5109.230290677566, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621907159, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621907159, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621907174, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621907599, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8931178450584412, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621907599, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621907795, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5287.846366159852, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621907795, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621907795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5287.846366159852, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621907833, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621907834, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621907848, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621908276, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8958026170730591, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621908276, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621908472, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5261.298459264016, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621908473, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621908473, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5261.298459264016, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621908544, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621908544, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621908559, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621908973, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.891838788986206, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621908974, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621909189, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5211.205640715029, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621909190, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621909190, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5211.205640715029, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621909232, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621909233, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621909247, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634621909657, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8921262621879578, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634621909657, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634621909856, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5393.78147105134, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621909856, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621909856, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5393.78147105134, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634621909897, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621909897, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621909912, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634621910333, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8990738987922668, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634621910334, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634621910527, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5335.365625490979, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621910528, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621910528, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5335.365625490979, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634621910579, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621910579, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621910594, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634621911010, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8941530585289001, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634621911010, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634621911208, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5341.699452634356, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621911209, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621911209, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5341.699452634356, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634621911251, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621911252, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621911266, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634621911691, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8939983248710632, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634621911691, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634621911881, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5338.330460791125, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621911882, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621911882, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5338.330460791125, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634621911930, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621911930, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621911945, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634621912357, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8985686302185059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634621912358, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634621912544, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5475.616091545835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621912544, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621912544, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5475.616091545835, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634621912598, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621912598, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621912613, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634621913024, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8889079093933105, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634621913024, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634621913222, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5385.015974086863, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621913222, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621913222, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5385.015974086863, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634621913262, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621913262, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621913277, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634621913703, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9029904007911682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634621913703, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634621913896, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5304.259837140722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621913896, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621913896, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5304.259837140722, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634621913939, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621913939, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621913953, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634621914378, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9074633121490479, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634621914378, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634621914568, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5344.900388479053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621914568, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621914568, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5344.900388479053, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634621914607, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621914607, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621914622, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634621915049, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9056800603866577, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634621915049, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634621915260, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5144.463428977562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621915261, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621915261, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5144.463428977562, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634621915298, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621915298, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621915313, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634621915741, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8950536251068115, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634621915741, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634621915933, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5293.731728783076, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621915934, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621915934, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5293.731728783076, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634621915975, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621915976, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621915991, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634621916428, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.902350664138794, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634621916428, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634621916628, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5151.402362730573, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621916628, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621916628, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5151.402362730573, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634621916671, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621916672, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621916686, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634621917141, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8942086100578308, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634621917141, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634621917341, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5018.362423124078, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621917342, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621917342, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5018.362423124078, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634621917377, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621917378, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621917392, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634621917822, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8953226804733276, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634621917822, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634621918019, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5241.423399077712, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621918019, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621918019, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5241.423399077712, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634621918054, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621918055, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621918069, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634621918503, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8921135663986206, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634621918503, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634621918699, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5218.16167684847, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621918699, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621918699, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5218.16167684847, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634621918750, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621918750, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621918765, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634621919184, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.901016354560852, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634621919184, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634621919378, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5356.243865229452, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621919378, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621919378, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5356.243865229452, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634621919424, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621919425, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621919439, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634621919861, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.904742419719696, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634621919861, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634621920053, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5352.366560767789, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621920053, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621920053, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5352.366560767789, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634621920097, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621920097, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621920112, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634621920539, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9002001285552979, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634621920539, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634621920742, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5210.958998929918, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621920743, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621920743, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5210.958998929918, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634621920785, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621920785, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621920800, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634621921257, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8918469548225403, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634621921257, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634621921471, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4903.590912696922, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621921471, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621921471, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4903.590912696922, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634621921512, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621921512, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621921527, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634621921966, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9008734226226807, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634621921967, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634621922161, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5182.342222549091, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621922161, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621922161, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5182.342222549091, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634621922201, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621922202, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621922216, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634621922660, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9070397019386292, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634621922660, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634621922858, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5121.7025749046825, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621922858, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621922858, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5121.7025749046825, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634621922898, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621922898, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621922913, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634621923341, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9003338813781738, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634621923341, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634621923539, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5247.448090972051, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621923539, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621923539, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5247.448090972051, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634621923581, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621923581, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621923596, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634621924013, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9053536653518677, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634621924013, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634621924204, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5394.76635528329, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621924205, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621924205, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5394.76635528329, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634621924252, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621924253, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621924267, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2500}}
:::MLLOG {"namespace": "", "time_ms": 1634621924680, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9048575162887573, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2500}}
:::MLLOG {"namespace": "", "time_ms": 1634621924680, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2500}}
:::MLLOG {"namespace": "", "time_ms": 1634621924879, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5364.266485584891, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621924880, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621924880, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5364.266485584891, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2500}}
:::MLLOG {"namespace": "", "time_ms": 1634621924921, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621924922, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621924936, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1634621925366, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9052329063415527, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1634621925366, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1634621925575, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5143.400736280328, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621925576, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621925576, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5143.400736280328, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1634621925613, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621925613, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621925628, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2540}}
:::MLLOG {"namespace": "", "time_ms": 1634621926056, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9015951156616211, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2540}}
:::MLLOG {"namespace": "", "time_ms": 1634621926056, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2540}}
:::MLLOG {"namespace": "", "time_ms": 1634621926248, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5293.6541785834215, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621926248, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621926248, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5293.6541785834215, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2540}}
:::MLLOG {"namespace": "", "time_ms": 1634621926310, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621926310, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621926325, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2560}}
:::MLLOG {"namespace": "", "time_ms": 1634621926730, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8985595703125, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2560}}
:::MLLOG {"namespace": "", "time_ms": 1634621926730, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2560}}
:::MLLOG {"namespace": "", "time_ms": 1634621926924, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5471.101036425321, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621926925, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621926925, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5471.101036425321, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2560}}
:::MLLOG {"namespace": "", "time_ms": 1634621926973, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621926973, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621926987, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2580}}
:::MLLOG {"namespace": "", "time_ms": 1634621927421, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9051536321640015, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2580}}
:::MLLOG {"namespace": "", "time_ms": 1634621927421, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2580}}
:::MLLOG {"namespace": "", "time_ms": 1634621927619, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5203.441859743839, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621927619, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621927619, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5203.441859743839, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2580}}
:::MLLOG {"namespace": "", "time_ms": 1634621927666, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621927666, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621927681, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2600}}
:::MLLOG {"namespace": "", "time_ms": 1634621928140, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8944382071495056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2600}}
:::MLLOG {"namespace": "", "time_ms": 1634621928141, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2600}}
:::MLLOG {"namespace": "", "time_ms": 1634621928350, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4917.052126219419, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621928350, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621928350, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4917.052126219419, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2600}}
:::MLLOG {"namespace": "", "time_ms": 1634621928391, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621928392, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621928407, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2620}}
:::MLLOG {"namespace": "", "time_ms": 1634621928826, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8982692360877991, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2620}}
:::MLLOG {"namespace": "", "time_ms": 1634621928826, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2620}}
:::MLLOG {"namespace": "", "time_ms": 1634621929021, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5339.902127986887, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621929021, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621929021, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5339.902127986887, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2620}}
:::MLLOG {"namespace": "", "time_ms": 1634621929061, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621929062, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621929076, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2640}}
:::MLLOG {"namespace": "", "time_ms": 1634621929523, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.896323561668396, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2640}}
:::MLLOG {"namespace": "", "time_ms": 1634621929523, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2640}}
:::MLLOG {"namespace": "", "time_ms": 1634621929728, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5042.857893279153, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621929728, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621929729, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5042.857893279153, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2640}}
:::MLLOG {"namespace": "", "time_ms": 1634621929768, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621929768, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621929782, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1634621930242, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9040160179138184, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1634621930242, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1634621930449, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4935.437842744541, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621930449, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621930449, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4935.437842744541, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1634621930495, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621930496, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621930510, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2680}}
:::MLLOG {"namespace": "", "time_ms": 1634621930958, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9080075025558472, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2680}}
:::MLLOG {"namespace": "", "time_ms": 1634621930958, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2680}}
:::MLLOG {"namespace": "", "time_ms": 1634621930958, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 165, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1634621931177, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4936.032494845187, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621931177, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621931177, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4936.032494845187, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2680}}
ENDING TIMING RUN AT 2021-10-19 05:38:57 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:38:57 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:38:57 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:38:57 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:38:57 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:38:57 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:38:57 AM
ENDING TIMING RUN AT 2021-10-19 05:38:57 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:38:57 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:38:57 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:38:58 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:38:58 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:38:58 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:38:58 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:38:58 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:00 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:01 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:03 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:04 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:05 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:06 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:07 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:08 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:09 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
ENDING TIMING RUN AT 2021-10-19 05:39:10 AM
RESULT,image_segmentation,,238,nvidia,2021-10-19 05:35:12 AM
