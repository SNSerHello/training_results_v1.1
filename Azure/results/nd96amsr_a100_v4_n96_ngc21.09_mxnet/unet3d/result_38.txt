+ : DGXA100_96x8x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019064412324705290
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data
+ : /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ LOGBASE=unet3d_96x8x1_211019064412324705290
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019064412324705290
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019064412324705290
+ readonly _cont_name=image_segmentation
+ _cont_name=image_segmentation
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07401/slurm_script: line 39: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh --container-name=image_segmentation true
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019064412324705290_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=96 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C046E
Clearing cache on ip-0A0C0483
Clearing cache on ip-0A0C0473
Clearing cache on ip-0A0C0489
Clearing cache on ip-0A0C0492
Clearing cache on ip-0A0C0497
Clearing cache on ip-0A0C045F
Clearing cache on ip-0A0C0437
Clearing cache on ip-0A0C0449
Clearing cache on ip-0A0C040F
Clearing cache on ip-0A0C0435
Clearing cache on ip-0A0C0494
Clearing cache on ip-0A0C0441
Clearing cache on ip-0A0C0486
Clearing cache on ip-0A0C0488
Clearing cache on ip-0A0C0466
Clearing cache on ip-0A0C0487
Clearing cache on ip-0A0C046C
Clearing cache on ip-0A0C0438
Clearing cache on ip-0A0C049B
Clearing cache on ip-0A0C0436
Clearing cache on ip-0A0C0460
Clearing cache on ip-0A0C047E
Clearing cache on ip-0A0C0472
Clearing cache on ip-0A0C0491
Clearing cache on ip-0A0C048D
Clearing cache on ip-0A0C044D
Clearing cache on ip-0A0C0498
Clearing cache on ip-0A0C048B
Clearing cache on ip-0A0C0493
Clearing cache on ip-0A0C0484
Clearing cache on ip-0A0C0464
Clearing cache on ip-0A0C04A2
Clearing cache on ip-0A0C04A8
Clearing cache on ip-0A0C0482
Clearing cache on ip-0A0C04B4
Clearing cache on ip-0A0C04C8
Clearing cache on ip-0A0C0443
Clearing cache on ip-0A0C04AA
Clearing cache on ip-0A0C0485
Clearing cache on ip-0A0C046B
Clearing cache on ip-0A0C0429
Clearing cache on ip-0A0C04B0
Clearing cache on ip-0A0C04B3
Clearing cache on ip-0A0C04AC
Clearing cache on ip-0A0C04B5
Clearing cache on ip-0A0C04D9
Clearing cache on ip-0A0C04C2
Clearing cache on ip-0A0C04CC
Clearing cache on ip-0A0C0461
Clearing cache on ip-0A0C04AB
Clearing cache on ip-0A0C04CD
Clearing cache on ip-0A0C04A4
Clearing cache on ip-0A0C04A7
Clearing cache on ip-0A0C04B6
Clearing cache on ip-0A0C048F
Clearing cache on ip-0A0C04AD
Clearing cache on ip-0A0C048A
Clearing cache on ip-0A0C04C7
Clearing cache on ip-0A0C04A5
Clearing cache on ip-0A0C0499
Clearing cache on ip-0A0C04BE
Clearing cache on ip-0A0C048C
Clearing cache on ip-0A0C0490
Clearing cache on ip-0A0C04C9
Clearing cache on ip-0A0C04A9
Clearing cache on ip-0A0C04BB
Clearing cache on ip-0A0C0495
Clearing cache on ip-0A0C04DA
Clearing cache on ip-0A0C04D3
Clearing cache on ip-0A0C049F
Clearing cache on ip-0A0C049C
Clearing cache on ip-0A0C04D4
Clearing cache on ip-0A0C04C6
Clearing cache on ip-0A0C04BD
Clearing cache on ip-0A0C04A0
Clearing cache on ip-0A0C04DB
Clearing cache on ip-0A0C049D
Clearing cache on ip-0A0C04C0
Clearing cache on ip-0A0C042D
Clearing cache on ip-0A0C0496
Clearing cache on ip-0A0C04CF
Clearing cache on ip-0A0C04C3
Clearing cache on ip-0A0C04B9
Clearing cache on ip-0A0C04C5
Clearing cache on ip-0A0C04BC
Clearing cache on ip-0A0C04A6
Clearing cache on ip-0A0C04C4
Clearing cache on ip-0A0C04A1
Clearing cache on ip-0A0C04AF
Clearing cache on ip-0A0C04D8
Clearing cache on ip-0A0C04AE
Clearing cache on ip-0A0C04BA
Clearing cache on ip-0A0C04B1
Clearing cache on ip-0A0C04B7
Clearing cache on ip-0A0C04B2
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=768 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:44:15 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
[1634625860.486225] [ip-0A0C0464:74500:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.532049] [ip-0A0C042D:45823:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.534410] [ip-0A0C0464:74496:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.551291] [ip-0A0C0466:77105:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.551318] [ip-0A0C0466:77107:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.556469] [ip-0A0C0497:9473 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.564937] [ip-0A0C04BE:92417:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.572798] [ip-0A0C042D:45821:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.586212] [ip-0A0C0497:9476 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.587280] [ip-0A0C0437:70682:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.598414] [ip-0A0C04C5:93549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.603402] [ip-0A0C0435:16240:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.604267] [ip-0A0C04D9:15716:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.621661] [ip-0A0C04B4:69532:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.621692] [ip-0A0C04B4:69526:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.624147] [ip-0A0C042D:45818:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.625792] [ip-0A0C0487:74541:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.631869] [ip-0A0C0483:73317:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.631830] [ip-0A0C04D9:15715:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.637176] [ip-0A0C0497:9477 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.638510] [ip-0A0C0494:55882:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.639050] [ip-0A0C04B5:60000:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.640781] [ip-0A0C04D8:95102:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.641183] [ip-0A0C0499:60511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.644497] [ip-0A0C04C5:93551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.645127] [ip-0A0C0485:39547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.645398] [ip-0A0C0464:74499:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.645745] [ip-0A0C04B9:92590:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.648019] [ip-0A0C0435:16238:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.647998] [ip-0A0C046B:71000:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.648931] [ip-0A0C046B:71004:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.648215] [ip-0A0C04B9:92587:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.650948] [ip-0A0C0483:73321:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.650679] [ip-0A0C04AF:50910:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.651778] [ip-0A0C0489:74696:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.656331] [ip-0A0C0494:55885:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.661227] [ip-0A0C04B5:59998:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.662469] [ip-0A0C048B:57121:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.662792] [ip-0A0C0464:74501:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.664582] [ip-0A0C049D:64295:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.666402] [ip-0A0C0499:60515:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.669408] [ip-0A0C0487:74535:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.672633] [ip-0A0C04B5:59999:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.676543] [ip-0A0C0464:74498:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.677743] [ip-0A0C04A9:58455:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.681330] [ip-0A0C0487:74542:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.682308] [ip-0A0C042D:45817:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.683489] [ip-0A0C0437:70679:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.685924] [ip-0A0C04DB:87358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.685135] [ip-0A0C04AF:50911:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.685570] [ip-0A0C0490:60418:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.688068] [ip-0A0C04B9:92586:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.689937] [ip-0A0C04C5:93552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.694353] [ip-0A0C042D:45816:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.696711] [ip-0A0C04BC:87476:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.696720] [ip-0A0C04BC:87470:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.697917] [ip-0A0C046C:69723:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.697901] [ip-0A0C046C:69719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.697924] [ip-0A0C046C:69720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.698560] [ip-0A0C0466:77101:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.698692] [ip-0A0C0466:77104:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.698738] [ip-0A0C04BE:92418:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.698860] [ip-0A0C04BE:92422:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.701250] [ip-0A0C0494:55888:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.702124] [ip-0A0C04D9:15718:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.705155] [ip-0A0C04CD:91960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.705898] [ip-0A0C04B0:45848:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.706973] [ip-0A0C04A2:50810:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.705933] [ip-0A0C04B0:45850:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.707018] [ip-0A0C04A2:50811:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.705671] [ip-0A0C0486:74515:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.707102] [ip-0A0C0435:16252:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.707822] [ip-0A0C045F:72119:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.708201] [ip-0A0C0464:74494:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.707993] [ip-0A0C0438:75222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.709763] [ip-0A0C048B:57126:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.710376] [ip-0A0C0437:70680:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.710908] [ip-0A0C046E:76467:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.712819] [ip-0A0C0464:74497:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.713219] [ip-0A0C0485:39545:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.712899] [ip-0A0C04B6:28475:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.715041] [ip-0A0C0435:16241:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.715549] [ip-0A0C04BD:89509:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.715136] [ip-0A0C049F:47118:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.717844] [ip-0A0C04BE:92419:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.718398] [ip-0A0C04D4:91333:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.719744] [ip-0A0C0464:74495:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.720038] [ip-0A0C0482:61643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.722017] [ip-0A0C0466:77103:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.722334] [ip-0A0C0441:67353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.722879] [ip-0A0C0485:39546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.724787] [ip-0A0C048C:55110:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.725242] [ip-0A0C0489:74700:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.727689] [ip-0A0C04CC:95040:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.728595] [ip-0A0C048A:71228:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.729519] [ip-0A0C04BA:26696:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.728837] [ip-0A0C0497:9471 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.729524] [ip-0A0C04BA:26699:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.730453] [ip-0A0C042D:45819:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.731329] [ip-0A0C049F:47117:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.731435] [ip-0A0C04A9:58458:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.732561] [ip-0A0C04DB:87362:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.734052] [ip-0A0C0466:77106:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.734626] [ip-0A0C0466:77108:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.735906] [ip-0A0C04C4:91653:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.736253] [ip-0A0C04AF:50915:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.738375] [ip-0A0C04C5:93548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.737983] [ip-0A0C04A9:58459:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.739447] [ip-0A0C048D:60247:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.740973] [ip-0A0C04C6:87602:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.741014] [ip-0A0C04C6:87605:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.742735] [ip-0A0C04DB:87364:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.743719] [ip-0A0C042D:45820:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.744640] [ip-0A0C0496:40814:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.745389] [ip-0A0C04B3:67224:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.745187] [ip-0A0C04A5:62006:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.746705] [ip-0A0C0436:74803:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.747276] [ip-0A0C04D8:95098:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.747130] [ip-0A0C0435:16242:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.747463] [ip-0A0C04D8:95103:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.747289] [ip-0A0C042D:45822:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.746576] [ip-0A0C04B6:28479:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.747904] [ip-0A0C04A5:61980:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.748369] [ip-0A0C04A0:48837:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.748969] [ip-0A0C04C9:94104:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.749465] [ip-0A0C0489:74702:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.750528] [ip-0A0C04B4:69530:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.751872] [ip-0A0C0494:55884:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.752140] [ip-0A0C04B4:69529:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.753019] [ip-0A0C04BE:92416:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.753498] [ip-0A0C0496:40817:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.753531] [ip-0A0C04B4:69525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.754196] [ip-0A0C0466:77102:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.754190] [ip-0A0C0437:70681:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.754411] [ip-0A0C04D4:91338:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.755048] [ip-0A0C0436:74831:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.756408] [ip-0A0C04C3:90704:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.757117] [ip-0A0C04B0:45853:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.757157] [ip-0A0C048A:71231:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.759568] [ip-0A0C048B:57120:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.759722] [ip-0A0C0483:73343:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.758625] [ip-0A0C0497:9472 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.761523] [ip-0A0C048A:71227:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.762751] [ip-0A0C049D:64294:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.764568] [ip-0A0C04A7:36301:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.765172] [ip-0A0C04B2:35506:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.765478] [ip-0A0C0460:74137:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.768988] [ip-0A0C045F:72116:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.769106] [ip-0A0C0437:70693:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.768626] [ip-0A0C0497:9474 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.770945] [ip-0A0C04BE:92420:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.772339] [ip-0A0C04D9:15713:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.773261] [ip-0A0C0485:39542:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.773677] [ip-0A0C04D9:15719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.774949] [ip-0A0C04BE:92421:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.775273] [ip-0A0C04BD:89510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.775399] [ip-0A0C04BD:89512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.775427] [ip-0A0C0487:74540:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.777443] [ip-0A0C04A2:50815:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.776143] [ip-0A0C04CD:91962:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.776543] [ip-0A0C04B5:60003:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.777709] [ip-0A0C0437:70678:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.777805] [ip-0A0C0437:70685:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.778622] [ip-0A0C04CC:95042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.778917] [ip-0A0C04C8:95142:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.778242] [ip-0A0C04A9:58456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.779217] [ip-0A0C04CD:91967:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.779633] [ip-0A0C047E:70969:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.780111] [ip-0A0C04B9:92583:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.781550] [ip-0A0C04B4:69531:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.784078] [ip-0A0C04D8:95100:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.784824] [ip-0A0C0437:70686:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.784923] [ip-0A0C046B:70998:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.784986] [ip-0A0C040F:44452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.785491] [ip-0A0C04B4:69528:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.786652] [ip-0A0C046C:69721:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.786613] [ip-0A0C04DA:88768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.786974] [ip-0A0C04BE:92415:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.787032] [ip-0A0C0499:60508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.787177] [ip-0A0C04C0:91286:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.789740] [ip-0A0C0483:73316:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.789826] [ip-0A0C0472:76511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.791203] [ip-0A0C0488:73158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.791321] [ip-0A0C0435:16239:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.790307] [ip-0A0C044D:71598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.791211] [ip-0A0C0488:73155:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.791402] [ip-0A0C0435:16243:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.791981] [ip-0A0C04B7:30304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.792119] [ip-0A0C04B3:67222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.791138] [ip-0A0C0497:9475 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.792288] [ip-0A0C048B:57124:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.791375] [ip-0A0C0497:9479 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.792668] [ip-0A0C04B2:35504:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.793992] [ip-0A0C0489:74698:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.794373] [ip-0A0C0494:55887:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.793997] [ip-0A0C04AF:50912:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.794911] [ip-0A0C04C8:95139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.794767] [ip-0A0C0494:55889:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.795235] [ip-0A0C04D8:95097:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.795557] [ip-0A0C046C:69724:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.795325] [ip-0A0C04C5:93575:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.795615] [ip-0A0C04B5:59997:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.796534] [ip-0A0C0436:74801:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.795936] [ip-0A0C0482:61640:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.797266] [ip-0A0C04A7:36305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.798243] [ip-0A0C0484:76494:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.798550] [ip-0A0C046B:70999:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.797569] [ip-0A0C0486:74516:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.800376] [ip-0A0C04AE:64407:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.800350] [ip-0A0C04AE:64410:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.800233] [ip-0A0C04D3:93577:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.801549] [ip-0A0C0435:16246:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.800873] [ip-0A0C0482:61645:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.801790] [ip-0A0C046E:76463:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.802599] [ip-0A0C0490:60422:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.803014] [ip-0A0C0489:74695:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.803922] [ip-0A0C04B7:30310:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.805549] [ip-0A0C0496:40815:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.807547] [ip-0A0C0487:74536:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.806779] [ip-0A0C0498:69449:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.808208] [ip-0A0C04C9:94105:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.807879] [ip-0A0C0438:75196:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.809495] [ip-0A0C04A0:48840:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.810193] [ip-0A0C0429:64842:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.811114] [ip-0A0C0438:75198:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.810982] [ip-0A0C040F:44449:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.810458] [ip-0A0C0486:74519:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.812824] [ip-0A0C04B4:69527:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.814154] [ip-0A0C04CD:91964:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.814094] [ip-0A0C04C5:93555:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.814211] [ip-0A0C04C5:93554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.815019] [ip-0A0C0490:60421:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.816368] [ip-0A0C04D9:15717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.818096] [ip-0A0C046B:71002:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.817695] [ip-0A0C04C5:93550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.818585] [ip-0A0C0487:74539:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.818702] [ip-0A0C048D:60245:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.818531] [ip-0A0C04B9:92582:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.819899] [ip-0A0C0499:60510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.820702] [ip-0A0C04B5:60004:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.821343] [ip-0A0C048B:57122:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.821191] [ip-0A0C04B5:60001:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.821678] [ip-0A0C048D:60251:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.822256] [ip-0A0C04D9:15712:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.821274] [ip-0A0C04CF:17916:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.821275] [ip-0A0C04CF:17920:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.821258] [ip-0A0C04CF:17914:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.822615] [ip-0A0C048D:60249:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.822527] [ip-0A0C04A9:58454:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.824760] [ip-0A0C0494:55886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.825047] [ip-0A0C0499:60512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.824987] [ip-0A0C04C3:90703:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.824959] [ip-0A0C048C:55109:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.825255] [ip-0A0C0443:37666:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.825387] [ip-0A0C049B:48149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.826076] [ip-0A0C044D:71593:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.826323] [ip-0A0C0482:61646:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.826477] [ip-0A0C0429:64843:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.826366] [ip-0A0C044D:71595:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.827536] [ip-0A0C0483:73319:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.827632] [ip-0A0C0483:73320:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.828489] [ip-0A0C046B:71003:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.828958] [ip-0A0C0483:73322:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.828191] [ip-0A0C04D3:93584:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.828703] [ip-0A0C045F:72114:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.829821] [ip-0A0C0483:73318:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.830996] [ip-0A0C0492:54254:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.830081] [ip-0A0C04B9:92581:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.830987] [ip-0A0C04B0:45851:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.831916] [ip-0A0C04D9:15714:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.832335] [ip-0A0C04B5:60002:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.833028] [ip-0A0C046B:71012:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.833929] [ip-0A0C049D:64303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.834443] [ip-0A0C048F:63644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.834666] [ip-0A0C04B9:92584:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.836520] [ip-0A0C0489:74699:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.836475] [ip-0A0C04A6:58999:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.836513] [ip-0A0C04A6:59000:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.836817] [ip-0A0C0449:72014:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.836809] [ip-0A0C0449:72007:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.837962] [ip-0A0C046E:76465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.837427] [ip-0A0C04B9:92585:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.838738] [ip-0A0C0441:67349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.839080] [ip-0A0C0491:56181:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.839351] [ip-0A0C049D:64293:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.839936] [ip-0A0C046C:69718:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.839986] [ip-0A0C046C:69717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.840511] [ip-0A0C046B:71001:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.840775] [ip-0A0C04BD:89511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.840613] [ip-0A0C0494:55883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.841310] [ip-0A0C046C:69722:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.840194] [ip-0A0C04B6:28480:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.841849] [ip-0A0C048C:55116:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.842597] [ip-0A0C0487:74538:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.841900] [ip-0A0C04AF:50917:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.843257] [ip-0A0C04D8:95099:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.842469] [ip-0A0C048C:55112:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.843514] [ip-0A0C0495:58437:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.843713] [ip-0A0C04B3:67218:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.843944] [ip-0A0C04B1:62385:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.844333] [ip-0A0C0487:74537:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.845311] [ip-0A0C0499:60513:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.845127] [ip-0A0C04C7:96103:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.845135] [ip-0A0C04C7:96100:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.846234] [ip-0A0C0489:74701:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.846790] [ip-0A0C0485:39543:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.847912] [ip-0A0C04C4:91659:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.848571] [ip-0A0C04DB:87361:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.848088] [ip-0A0C0443:37664:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.848605] [ip-0A0C046E:76466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.849160] [ip-0A0C04D8:95096:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.848938] [ip-0A0C04B6:28478:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.849712] [ip-0A0C04AF:50916:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.851048] [ip-0A0C0490:60420:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.852381] [ip-0A0C0485:39548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.852565] [ip-0A0C04D8:95101:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.852239] [ip-0A0C0441:67348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.852172] [ip-0A0C04D3:93580:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.853168] [ip-0A0C0499:60509:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.853481] [ip-0A0C049D:64291:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.853619] [ip-0A0C0472:76509:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.855158] [ip-0A0C04C4:91655:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.855901] [ip-0A0C04A1:76888:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.857488] [ip-0A0C04A0:48838:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.857195] [ip-0A0C04B0:45849:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.857466] [ip-0A0C04DA:88767:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.857569] [ip-0A0C04DA:88773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.857909] [ip-0A0C04BC:87472:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.857988] [ip-0A0C0461:38060:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.857976] [ip-0A0C049B:48147:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.858757] [ip-0A0C0489:74697:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.859231] [ip-0A0C0499:60533:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.859594] [ip-0A0C0491:56176:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.859162] [ip-0A0C04AF:50914:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.860174] [ip-0A0C04AA:34004:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.859296] [ip-0A0C04C6:87601:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.860394] [ip-0A0C04C2:17004:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.860299] [ip-0A0C0438:75199:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.860412] [ip-0A0C04C2:17001:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.860970] [ip-0A0C0460:74133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.861849] [ip-0A0C04BC:87474:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.860908] [ip-0A0C0493:55706:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.861838] [ip-0A0C049C:45928:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.862068] [ip-0A0C04C4:91657:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.861845] [ip-0A0C049C:45929:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.862445] [ip-0A0C04A7:36298:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.862981] [ip-0A0C04BC:87469:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.863135] [ip-0A0C04C0:91284:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.864104] [ip-0A0C04BB:34409:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.863844] [ip-0A0C04C3:90705:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.863988] [ip-0A0C04CD:91966:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.864473] [ip-0A0C0460:74135:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.864692] [ip-0A0C0490:60417:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.865416] [ip-0A0C0492:54252:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.865677] [ip-0A0C0493:55705:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.867561] [ip-0A0C04D4:91335:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.868541] [ip-0A0C045F:72115:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.868099] [ip-0A0C0498:69453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.868295] [ip-0A0C04AF:50913:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.869159] [ip-0A0C0485:39544:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.868354] [ip-0A0C04A9:58452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.868424] [ip-0A0C04A9:58453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.869419] [ip-0A0C04BD:89507:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.869683] [ip-0A0C049D:64289:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.869013] [ip-0A0C04A9:58457:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.868974] [ip-0A0C0498:69452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.870347] [ip-0A0C048B:57123:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.871025] [ip-0A0C048B:57125:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.872088] [ip-0A0C04A2:50837:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.871781] [ip-0A0C0485:39541:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.871632] [ip-0A0C048F:63642:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.873097] [ip-0A0C048B:57127:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.874254] [ip-0A0C04BD:89506:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.874340] [ip-0A0C0484:76491:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.874695] [ip-0A0C04D4:91334:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.874413] [ip-0A0C0473:72614:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.874411] [ip-0A0C0473:72621:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.875168] [ip-0A0C04BA:26700:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.875228] [ip-0A0C0486:74521:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.876414] [ip-0A0C04C0:91288:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.875916] [ip-0A0C0486:74514:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.877285] [ip-0A0C04CD:91965:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.878604] [ip-0A0C04DB:87360:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.878197] [ip-0A0C048C:55113:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.879433] [ip-0A0C04C9:94101:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.879530] [ip-0A0C0472:76505:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.879236] [ip-0A0C0490:60416:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.879900] [ip-0A0C049D:64292:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.879335] [ip-0A0C049B:48150:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.880430] [ip-0A0C049D:64290:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.881918] [ip-0A0C04A7:36302:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.882431] [ip-0A0C04C4:91654:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.882598] [ip-0A0C046E:76470:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.882956] [ip-0A0C04B0:45847:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.882097] [ip-0A0C049F:47122:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.882969] [ip-0A0C04AD:36230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.883300] [ip-0A0C04AB:49594:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.883882] [ip-0A0C04A5:61987:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.885216] [ip-0A0C04A2:50808:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.884468] [ip-0A0C0436:74805:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.885507] [ip-0A0C04DB:87359:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.885965] [ip-0A0C0490:60423:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.885486] [ip-0A0C04A8:64485:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.886785] [ip-0A0C04C9:94106:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.886177] [ip-0A0C0490:60419:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.885764] [ip-0A0C04B6:28476:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.887054] [ip-0A0C04BC:87475:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.886911] [ip-0A0C0441:67354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.886220] [ip-0A0C049F:47120:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.886949] [ip-0A0C04C6:87606:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.888136] [ip-0A0C04B0:45846:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.888488] [ip-0A0C0460:74136:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.888698] [ip-0A0C040F:44447:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.888892] [ip-0A0C04A4:59304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.889765] [ip-0A0C04AC:52789:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.889631] [ip-0A0C04BA:26693:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.890951] [ip-0A0C04CC:95039:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.890849] [ip-0A0C04AE:64409:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.893360] [ip-0A0C04DA:88774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.893425] [ip-0A0C048A:71232:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.894872] [ip-0A0C0441:67351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.894058] [ip-0A0C04C6:87608:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.895359] [ip-0A0C04BC:87473:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.895730] [ip-0A0C04DB:87363:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.895923] [ip-0A0C04DB:87365:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.895547] [ip-0A0C0482:61644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.895696] [ip-0A0C0482:61647:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.896182] [ip-0A0C0461:38056:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.896930] [ip-0A0C046E:76469:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.897170] [ip-0A0C04C0:91281:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.897589] [ip-0A0C04A5:61982:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.898730] [ip-0A0C04CC:95035:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.899072] [ip-0A0C04BC:87471:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.899654] [ip-0A0C04C7:96102:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.901003] [ip-0A0C045F:72117:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.901809] [ip-0A0C047E:70966:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.900721] [ip-0A0C044D:71597:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.901887] [ip-0A0C0496:40816:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.901841] [ip-0A0C04CD:91961:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.902512] [ip-0A0C048C:55111:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.903926] [ip-0A0C04CC:95041:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.903411] [ip-0A0C04B6:28482:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.905071] [ip-0A0C04CD:91963:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.905611] [ip-0A0C04BD:89508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.905760] [ip-0A0C04BD:89505:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.906662] [ip-0A0C04C4:91658:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.907689] [ip-0A0C0496:40818:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.906853] [ip-0A0C04CF:17917:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.908069] [ip-0A0C04BB:34406:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.908541] [ip-0A0C0492:54250:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.909087] [ip-0A0C04B7:30308:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.908054] [ip-0A0C049F:47124:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.909799] [ip-0A0C0484:76506:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.910694] [ip-0A0C047E:70965:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.911902] [ip-0A0C04A2:50812:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.911053] [ip-0A0C04B0:45852:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.911594] [ip-0A0C04B1:62380:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.910933] [ip-0A0C0498:69450:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.912428] [ip-0A0C0491:56178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.913078] [ip-0A0C04BA:26698:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.912163] [ip-0A0C048A:71233:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.913025] [ip-0A0C046E:76468:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.913700] [ip-0A0C04BB:34402:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.912484] [ip-0A0C04A6:58997:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.913090] [ip-0A0C0438:75193:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.914125] [ip-0A0C04AA:33999:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.914108] [ip-0A0C04B2:35503:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.914100] [ip-0A0C046E:76464:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.914010] [ip-0A0C048F:63640:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.914819] [ip-0A0C0438:75197:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.915441] [ip-0A0C0438:75194:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.916722] [ip-0A0C04DA:88771:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.917571] [ip-0A0C04A0:48836:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.916491] [ip-0A0C0449:72013:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.919115] [ip-0A0C048A:71229:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.920162] [ip-0A0C0438:75195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.921729] [ip-0A0C04AB:49595:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.921696] [ip-0A0C04A5:61984:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.921433] [ip-0A0C04C6:87603:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.922554] [ip-0A0C04A5:61981:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.922702] [ip-0A0C048D:60250:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.922968] [ip-0A0C0495:58439:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.924054] [ip-0A0C04A2:50809:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.922423] [ip-0A0C0482:61642:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.922515] [ip-0A0C04CF:17913:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.923518] [ip-0A0C0436:74802:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.923955] [ip-0A0C045F:72113:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.923796] [ip-0A0C048A:71230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.924253] [ip-0A0C048A:71226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.924155] [ip-0A0C04C6:87625:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.925799] [ip-0A0C0488:73161:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.925046] [ip-0A0C04B6:28477:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.926513] [ip-0A0C04AD:36223:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.925699] [ip-0A0C04B6:28481:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.925803] [ip-0A0C0486:74517:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.927284] [ip-0A0C04CC:95036:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.927485] [ip-0A0C04C8:95136:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.929690] [ip-0A0C04A2:50822:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.927546] [ip-0A0C04C6:87604:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.928122] [ip-0A0C048C:55114:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.928174] [ip-0A0C049F:47119:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.929352] [ip-0A0C0482:61641:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.930516] [ip-0A0C04A5:61983:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.930656] [ip-0A0C04D4:91331:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.930458] [ip-0A0C0441:67355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.929929] [ip-0A0C04D3:93576:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.931314] [ip-0A0C04A5:61985:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.931764] [ip-0A0C048C:55115:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.932712] [ip-0A0C04A1:76882:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.931681] [ip-0A0C049F:47123:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.931850] [ip-0A0C0486:74518:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.933402] [ip-0A0C045F:72120:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.932545] [ip-0A0C04A8:64478:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.933662] [ip-0A0C04B3:67223:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.933308] [ip-0A0C04A6:59002:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.934634] [ip-0A0C04AC:52791:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.934836] [ip-0A0C04D4:91337:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.935054] [ip-0A0C047E:70962:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.934403] [ip-0A0C0493:55732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.934205] [ip-0A0C0486:74520:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.936293] [ip-0A0C04A0:48835:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.936460] [ip-0A0C045F:72118:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.935727] [ip-0A0C0449:72011:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.937229] [ip-0A0C04BA:26697:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.937335] [ip-0A0C048D:60274:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.937549] [ip-0A0C04B2:35507:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.937705] [ip-0A0C0436:74806:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.938034] [ip-0A0C04BA:26694:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.937565] [ip-0A0C049F:47121:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.938670] [ip-0A0C048D:60248:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.938911] [ip-0A0C04CC:95034:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.939356] [ip-0A0C040F:44450:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.939912] [ip-0A0C0496:40812:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.940121] [ip-0A0C04BA:26695:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.940366] [ip-0A0C0496:40813:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.940693] [ip-0A0C04D4:91332:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.941829] [ip-0A0C0436:74804:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.941918] [ip-0A0C0441:67352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.942094] [ip-0A0C04CC:95038:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.942217] [ip-0A0C048D:60244:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.942705] [ip-0A0C04C3:90708:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.942614] [ip-0A0C04C0:91285:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.944844] [ip-0A0C0491:56182:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.944442] [ip-0A0C04CF:17919:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.946258] [ip-0A0C04D4:91336:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.947294] [ip-0A0C0441:67350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.947259] [ip-0A0C0460:74134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.948007] [ip-0A0C04C4:91660:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.948300] [ip-0A0C0496:40819:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.948710] [ip-0A0C04A1:76885:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.948802] [ip-0A0C04A1:76889:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.948918] [ip-0A0C0472:76508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.948987] [ip-0A0C04C3:90706:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.949380] [ip-0A0C0491:56179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.950071] [ip-0A0C04C8:95156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.949455] [ip-0A0C0429:64840:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.950367] [ip-0A0C04B1:62381:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.950448] [ip-0A0C04A7:36304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.950735] [ip-0A0C04B3:67219:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.951138] [ip-0A0C04C8:95135:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.951658] [ip-0A0C04AA:33996:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.952037] [ip-0A0C04A7:36299:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.952514] [ip-0A0C04A7:36303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.952051] [ip-0A0C04CF:17918:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.952650] [ip-0A0C04A8:64479:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.953518] [ip-0A0C04C4:91656:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.952754] [ip-0A0C04D3:93581:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.954023] [ip-0A0C04C2:17000:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.954535] [ip-0A0C04B3:67221:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.954220] [ip-0A0C0460:74138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.954213] [ip-0A0C0498:69451:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.955732] [ip-0A0C04AD:36219:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.956353] [ip-0A0C04A0:48839:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.956692] [ip-0A0C0472:76507:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.957040] [ip-0A0C04C9:94100:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.957213] [ip-0A0C0495:58433:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.958357] [ip-0A0C04B7:30305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.959270] [ip-0A0C04A7:36300:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.959132] [ip-0A0C04CF:17915:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.959965] [ip-0A0C0436:74807:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.960404] [ip-0A0C04B2:35508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.960186] [ip-0A0C0460:74139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.961054] [ip-0A0C04B2:35501:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.962055] [ip-0A0C04C3:90702:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.961806] [ip-0A0C044D:71596:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.963179] [ip-0A0C0488:73159:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.963447] [ip-0A0C0488:73162:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.963682] [ip-0A0C044D:71594:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.963803] [ip-0A0C0449:72008:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.965486] [ip-0A0C04A0:48834:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.964962] [ip-0A0C040F:44453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.965461] [ip-0A0C04B3:67220:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.965678] [ip-0A0C04B3:67217:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.966659] [ip-0A0C04A0:48841:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.966192] [ip-0A0C04AE:64408:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.966179] [ip-0A0C04AE:64404:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.967692] [ip-0A0C047E:70968:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.967899] [ip-0A0C04C2:17003:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.968362] [ip-0A0C04C9:94103:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.968801] [ip-0A0C04C3:90707:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.969334] [ip-0A0C0484:76488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.969202] [ip-0A0C0473:72617:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.969067] [ip-0A0C04D3:93578:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.969970] [ip-0A0C0429:64846:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.970781] [ip-0A0C04C7:96106:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.971605] [ip-0A0C04C9:94102:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.971494] [ip-0A0C049C:45927:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.972708] [ip-0A0C04C3:90701:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.973087] [ip-0A0C0461:38057:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.973452] [ip-0A0C0460:74140:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.973258] [ip-0A0C044D:71600:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.976249] [ip-0A0C04C9:94099:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.976901] [ip-0A0C0488:73174:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.976774] [ip-0A0C04A6:59001:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.977247] [ip-0A0C04A6:58998:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.978518] [ip-0A0C04B2:35502:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.979187] [ip-0A0C0488:73156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.980203] [ip-0A0C0492:54253:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.980370] [ip-0A0C04B7:30302:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.980764] [ip-0A0C04B7:30303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.980880] [ip-0A0C044D:71599:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.983003] [ip-0A0C04C8:95137:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.983701] [ip-0A0C04B7:30309:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.983242] [ip-0A0C04AE:64405:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.983222] [ip-0A0C0443:37667:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.982585] [ip-0A0C049B:48154:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.984007] [ip-0A0C04AA:34002:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.984388] [ip-0A0C0472:76512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.984435] [ip-0A0C04B2:35505:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.985430] [ip-0A0C04AB:49600:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.986431] [ip-0A0C04DA:88772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.986498] [ip-0A0C04A6:59003:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.987429] [ip-0A0C04C8:95141:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.987541] [ip-0A0C04C8:95138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.987875] [ip-0A0C0492:54251:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.987643] [ip-0A0C04DA:88770:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.988098] [ip-0A0C04B7:30306:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.988745] [ip-0A0C047E:70963:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.988957] [ip-0A0C04C0:91283:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.989192] [ip-0A0C040F:44448:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.988765] [ip-0A0C0498:69456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.990379] [ip-0A0C04B1:62384:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.992412] [ip-0A0C04C0:91311:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.992451] [ip-0A0C04C0:91282:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.993085] [ip-0A0C04DA:88769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.993039] [ip-0A0C04AE:64406:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.993151] [ip-0A0C04AE:64411:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.992803] [ip-0A0C04A6:58996:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.993601] [ip-0A0C04A4:59301:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.993765] [ip-0A0C04A4:59302:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.993640] [ip-0A0C04D3:93582:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.993747] [ip-0A0C04D3:93579:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.995472] [ip-0A0C0443:37665:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.995357] [ip-0A0C0493:55708:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.997580] [ip-0A0C0429:64839:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.999691] [ip-0A0C047E:70967:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.000253] [ip-0A0C04A1:76886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.999907] [ip-0A0C04C7:96108:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.000162] [ip-0A0C0472:76506:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.000296] [ip-0A0C0472:76510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.000494] [ip-0A0C047E:70964:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.000461] [ip-0A0C04AD:36222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.000649] [ip-0A0C0495:58435:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625860.999931] [ip-0A0C049B:48148:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.001032] [ip-0A0C040F:44446:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.001774] [ip-0A0C0488:73160:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.001567] [ip-0A0C040F:44451:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.003901] [ip-0A0C0492:54249:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.009449] [ip-0A0C0484:76492:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.009000] [ip-0A0C0498:69457:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.010526] [ip-0A0C0449:72010:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.011567] [ip-0A0C04C7:96105:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.010830] [ip-0A0C0498:69458:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.013930] [ip-0A0C0484:76490:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.013563] [ip-0A0C0443:37668:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.013360] [ip-0A0C0449:72012:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.014405] [ip-0A0C0492:54272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.013967] [ip-0A0C0429:64841:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.014036] [ip-0A0C0429:64844:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.014447] [ip-0A0C0461:38064:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.015006] [ip-0A0C049C:45930:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.017754] [ip-0A0C0493:55709:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.020030] [ip-0A0C0484:76489:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.019194] [ip-0A0C0449:72009:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.021098] [ip-0A0C0429:64845:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.025260] [ip-0A0C0484:76493:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.024487] [ip-0A0C048F:63641:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.026931] [ip-0A0C04AA:34003:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.027529] [ip-0A0C0492:54248:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.026476] [ip-0A0C049B:48155:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.027817] [ip-0A0C0495:58432:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.028066] [ip-0A0C049C:45932:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.028034] [ip-0A0C0473:72620:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.027950] [ip-0A0C04A8:64482:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.029840] [ip-0A0C04AC:52793:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.029432] [ip-0A0C04C7:96107:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.032244] [ip-0A0C049B:48153:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.033617] [ip-0A0C04B1:62378:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.034362] [ip-0A0C04BB:34404:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.034021] [ip-0A0C04C2:17006:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.033683] [ip-0A0C0443:37663:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.036289] [ip-0A0C0495:58431:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.036700] [ip-0A0C049B:48151:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.038281] [ip-0A0C0493:55703:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.039562] [ip-0A0C0491:56175:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.041595] [ip-0A0C04BB:34408:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.041381] [ip-0A0C0491:56180:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.042149] [ip-0A0C0495:58434:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.042599] [ip-0A0C0495:58438:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.042845] [ip-0A0C04AD:36221:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.043193] [ip-0A0C0491:56177:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.043594] [ip-0A0C049C:45926:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.043701] [ip-0A0C04C7:96101:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.044190] [ip-0A0C0473:72619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.044511] [ip-0A0C0443:37662:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.045911] [ip-0A0C04AD:36220:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.046853] [ip-0A0C0493:55704:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.047886] [ip-0A0C0461:38063:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.048401] [ip-0A0C04AA:34001:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.047809] [ip-0A0C04A8:64481:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.048520] [ip-0A0C0461:38059:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.048855] [ip-0A0C048F:63639:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.049478] [ip-0A0C0443:37669:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.049675] [ip-0A0C0493:55707:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.049972] [ip-0A0C048F:63646:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.052699] [ip-0A0C04AA:33998:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.053603] [ip-0A0C04B1:62379:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.054236] [ip-0A0C049C:45931:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.054452] [ip-0A0C0473:72616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.054710] [ip-0A0C04AA:33997:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.055811] [ip-0A0C0473:72615:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.056334] [ip-0A0C04B1:62383:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.056781] [ip-0A0C048F:63647:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.057871] [ip-0A0C04AD:36226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.058134] [ip-0A0C049C:45933:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.059298] [ip-0A0C0473:72618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.060081] [ip-0A0C04B1:62382:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.063666] [ip-0A0C04C2:17002:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.065803] [ip-0A0C048F:63643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.066918] [ip-0A0C04A1:76887:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.067011] [ip-0A0C04A1:76883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.067253] [ip-0A0C04A1:76884:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.069076] [ip-0A0C04AC:52792:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.069883] [ip-0A0C04BB:34405:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.070543] [ip-0A0C04BB:34403:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.072021] [ip-0A0C04A4:59300:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.073710] [ip-0A0C04BB:34407:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.074499] [ip-0A0C04C2:17012:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.074928] [ip-0A0C04A8:64483:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.076307] [ip-0A0C04C2:17007:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.076785] [ip-0A0C04AD:36227:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.080762] [ip-0A0C0461:38058:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.082136] [ip-0A0C04AC:52788:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.082330] [ip-0A0C0461:38055:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.087102] [ip-0A0C04A8:64504:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.088963] [ip-0A0C04AB:49598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.092364] [ip-0A0C04AC:52794:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.092927] [ip-0A0C04AC:52787:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.092429] [ip-0A0C04A4:59305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.093603] [ip-0A0C04AC:52790:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.094596] [ip-0A0C04AB:49623:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.095201] [ip-0A0C04A4:59299:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.096109] [ip-0A0C04A4:59298:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.096441] [ip-0A0C04A4:59303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.101424] [ip-0A0C04AB:49596:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.101502] [ip-0A0C04A8:64480:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.113963] [ip-0A0C04AB:49597:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625861.114111] [ip-0A0C04AB:49599:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
:::MLLOG {"namespace": "", "time_ms": 1634625862007, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634625862048, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634625862049, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1634625862049, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634625862050, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1634625862050, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1634625862050, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "96xND96amsr_A100_v4", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[06:44:32] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:32] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:32] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:32] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:32] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:32] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:32] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:33] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:44:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[ip-0A0C0435:0:16238 - context.c:584] INFO job (ID: 867564275979637370) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:16238 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:16238 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:16240 - context.c:584] INFO job (ID: 867565106289022087) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:16240 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:16240 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:16246 - context.c:584] INFO job (ID: 867564183860267554) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:16246 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:16246 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:16242 - context.c:584] INFO job (ID: 867564622611332239) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:16242 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:16242 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:16252 - context.c:584] INFO job (ID: 867564732080198676) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:16252 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:16252 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:16241 - context.c:584] INFO job (ID: 867564769887771609) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:16241 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:16241 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:16239 - context.c:584] INFO job (ID: 867564248061548553) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:16239 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:16239 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:16243 - context.c:584] INFO job (ID: 867564411251035772) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:16243 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:16243 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625954890, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2213676579, "metadata": {"file": "main.py", "lineno": 72}}
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625954891, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 138}}
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625954891, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 139}}
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625954891, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1500, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 140}}
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625954891, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 142}}
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625954891, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 143}}
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625954891, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 144}}
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625954891, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 145}}
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625954891, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 146}}
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625954891, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 147}}
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625954891, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 148}}
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625954891, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 149}}
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:54] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:45:56] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625978996, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1634625979023, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625979028, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1634625979028, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 95}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634625981586, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 84, "metadata": {"file": "main.py", "lineno": 136}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634625981586, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 137}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634625981586, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634625981643, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1, "epoch_count": 20}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634625983310, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2016.679005167746, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625983310, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.02989933774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625983310, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2016.679005167746, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634625983311, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625983311, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625983993, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4927.672138920251, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625983993, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.04976556291390729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625983993, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4927.672138920251, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625983994, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625983994, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625984643, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5176.585807354035, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625984643, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0696317880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625984643, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5176.585807354035, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634625984644, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625984644, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625985280, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5280.034708523707, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625985280, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.08949801324503312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625985281, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5280.034708523707, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 60}}
:::MLLOG {"namespace": "", "time_ms": 1634625985281, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625985281, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625985915, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5302.469659025236, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625985915, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.10936423841059603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625985915, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5302.469659025236, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 80}}
:::MLLOG {"namespace": "", "time_ms": 1634625985915, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625985915, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625986537, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5406.963645264707, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625986537, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.12923046357615892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625986537, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5406.963645264707, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 100}}
:::MLLOG {"namespace": "", "time_ms": 1634625986538, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625986538, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625987152, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5466.682482820685, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625987153, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.14909668874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625987153, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5466.682482820685, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634625987153, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625987153, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625987774, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5416.364877412849, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625987774, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.16896291390728477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625987774, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5416.364877412849, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1634625987774, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625987774, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625988389, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5467.19782504795, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625988389, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.18882913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625988389, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5467.19782504795, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 160}}
:::MLLOG {"namespace": "", "time_ms": 1634625988390, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625988390, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625989004, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5473.736039272393, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625989004, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.20869536423841056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625989004, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5473.736039272393, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 180}}
:::MLLOG {"namespace": "", "time_ms": 1634625989004, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625989005, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625989619, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5466.355937627152, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625989620, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.22856158940397348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625989620, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5466.355937627152, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 200}}
:::MLLOG {"namespace": "", "time_ms": 1634625989620, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625989620, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625990234, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5473.733913247475, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625990234, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.24842781456953641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625990235, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5473.733913247475, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 220}}
:::MLLOG {"namespace": "", "time_ms": 1634625990235, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625990235, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625990851, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5453.486423034193, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625990851, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26829403973509935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625990851, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5453.486423034193, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 240}}
:::MLLOG {"namespace": "", "time_ms": 1634625990852, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625990852, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625991470, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5436.4315241291515, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625991470, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.28816026490066227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625991470, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5436.4315241291515, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 260}}
:::MLLOG {"namespace": "", "time_ms": 1634625991470, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625991471, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625992088, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5447.253325087451, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625992088, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3080264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625992088, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5447.253325087451, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1634625992088, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625992088, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625992711, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5397.9278463883165, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625992711, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32789271523178803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625992711, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5397.9278463883165, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 300}}
:::MLLOG {"namespace": "", "time_ms": 1634625992712, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625992712, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625993332, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5416.629265305981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625993332, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.347758940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625993333, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5416.629265305981, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 320}}
:::MLLOG {"namespace": "", "time_ms": 1634625993333, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625993333, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625993950, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5443.09602545415, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625993951, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36762516556291386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625993951, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5443.09602545415, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 340}}
:::MLLOG {"namespace": "", "time_ms": 1634625993951, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625993951, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625994572, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5407.907695129612, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625994573, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3874913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625994573, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5407.907695129612, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 360}}
:::MLLOG {"namespace": "", "time_ms": 1634625994573, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625994573, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625995201, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5351.675501404103, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625995201, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.40735761589403974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625995202, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5351.675501404103, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 380}}
:::MLLOG {"namespace": "", "time_ms": 1634625995202, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625995202, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625995822, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5415.638464054033, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625995823, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625995823, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5415.638464054033, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 400}}
:::MLLOG {"namespace": "", "time_ms": 1634625995823, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625995823, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625996438, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5461.369312406339, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625996439, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.44709006622516556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625996439, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5461.369312406339, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1634625996439, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625996439, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625997062, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5391.315676820864, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625997063, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4669562913907285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625997063, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5391.315676820864, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 440}}
:::MLLOG {"namespace": "", "time_ms": 1634625997063, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625997064, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625997688, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5380.381986824749, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625997689, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4868225165562914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625997689, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5380.381986824749, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 460}}
:::MLLOG {"namespace": "", "time_ms": 1634625997689, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625997689, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625998312, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5392.435837685817, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625998313, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5066887417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625998313, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5392.435837685817, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 480}}
:::MLLOG {"namespace": "", "time_ms": 1634625998313, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625998313, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625998933, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5426.09968443376, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625998933, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5265549668874172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625998933, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5426.09968443376, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 500}}
:::MLLOG {"namespace": "", "time_ms": 1634625998934, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625998934, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625999548, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5471.729806563733, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625999548, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5464211920529801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625999549, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5471.729806563733, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 520}}
:::MLLOG {"namespace": "", "time_ms": 1634625999549, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625999549, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626000159, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5506.876117319145, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626000159, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.566287417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626000159, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5506.876117319145, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 540}}
:::MLLOG {"namespace": "", "time_ms": 1634626000160, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626000160, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626000775, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5465.041669752813, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626000775, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5861536423841059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626000775, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5465.041669752813, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1634626000776, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626000776, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626001386, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5506.792196556863, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626001387, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6060198675496689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626001387, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5506.792196556863, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634626001387, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626001387, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626002009, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5399.224508498317, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626002010, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6258860927152318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626002010, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5399.224508498317, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 600}}
:::MLLOG {"namespace": "", "time_ms": 1634626002010, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626002010, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626002623, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5480.142866975447, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626002624, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6457523178807947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626002624, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5480.142866975447, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 620}}
:::MLLOG {"namespace": "", "time_ms": 1634626002624, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626002624, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626003241, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5447.859777599269, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626003242, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6656185430463576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626003242, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5447.859777599269, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 640}}
:::MLLOG {"namespace": "", "time_ms": 1634626003242, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626003242, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626003864, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5402.221414672966, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626003865, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6854847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626003865, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5402.221414672966, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 660}}
:::MLLOG {"namespace": "", "time_ms": 1634626003865, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626003865, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626004478, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5482.108358770623, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626004478, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7053509933774835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626004479, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5482.108358770623, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 680}}
:::MLLOG {"namespace": "", "time_ms": 1634626004479, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626004479, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626005088, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5514.137404436786, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626005088, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7252172185430463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626005089, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5514.137404436786, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 700}}
:::MLLOG {"namespace": "", "time_ms": 1634626005089, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626005089, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626005708, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5429.793782934799, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626005708, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7450834437086092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626005708, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5429.793782934799, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 720}}
:::MLLOG {"namespace": "", "time_ms": 1634626005708, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626005708, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626006321, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5482.101961174838, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626006322, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7649496688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626006322, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5482.101961174838, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 740}}
:::MLLOG {"namespace": "", "time_ms": 1634626006322, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626006322, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626006941, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5428.819072896664, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626006941, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7848158940397352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626006941, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5428.819072896664, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 760}}
:::MLLOG {"namespace": "", "time_ms": 1634626006941, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626006942, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626007557, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5463.054510524033, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626007557, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8046821192052981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626007557, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5463.054510524033, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634626007557, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626007557, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626008176, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5435.716491407796, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626008176, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8245483443708609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626008176, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5435.716491407796, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 800}}
:::MLLOG {"namespace": "", "time_ms": 1634626008176, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626008176, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626008788, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5488.906768679623, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626008789, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626008789, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5488.906768679623, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 820}}
:::MLLOG {"namespace": "", "time_ms": 1634626008789, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626008789, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626009406, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5443.442925559713, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626009407, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8642807947019867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626009407, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5443.442925559713, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 840}}
:::MLLOG {"namespace": "", "time_ms": 1634626009407, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626009407, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626010015, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5527.039320292587, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626010015, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8841470198675497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626010016, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5527.039320292587, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 860}}
:::MLLOG {"namespace": "", "time_ms": 1634626010016, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626010016, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626010634, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5440.71517172607, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626010634, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9040132450331126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626010634, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5440.71517172607, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 880}}
:::MLLOG {"namespace": "", "time_ms": 1634626010635, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626010635, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626011252, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5440.755080610291, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626011253, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9238794701986754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626011253, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5440.755080610291, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 900}}
:::MLLOG {"namespace": "", "time_ms": 1634626011253, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626011253, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626011867, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5480.586151982468, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626011867, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9437456953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626011867, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5480.586151982468, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 920}}
:::MLLOG {"namespace": "", "time_ms": 1634626011867, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626011867, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626012480, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5490.016525139482, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626012480, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9636119205298014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626012480, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5490.016525139482, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 940}}
:::MLLOG {"namespace": "", "time_ms": 1634626012481, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626012481, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626013096, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5464.715320547694, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626013096, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9834781456953643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626013096, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5464.715320547694, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 960}}
:::MLLOG {"namespace": "", "time_ms": 1634626013096, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626013097, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626013719, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5398.124270309527, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626013720, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0033443708609273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626013720, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5398.124270309527, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 980}}
:::MLLOG {"namespace": "", "time_ms": 1634626013792, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626013793, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626013810, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634626014239, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8732872605323792, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634626014239, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634626014400, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5530.676834662022, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626014401, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0232105960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626014401, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5530.676834662022, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634626014507, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626014507, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626014523, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634626014995, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8880965709686279, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634626014995, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634626015222, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4698.627552505421, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626015223, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.043076821192053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626015223, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4698.627552505421, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634626015304, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626015304, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626015319, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634626015717, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8479127883911133, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634626015717, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634626015911, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5540.391609249356, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626015912, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.062943046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626015912, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5540.391609249356, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634626015988, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626015988, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626016003, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634626016401, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8635234832763672, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634626016401, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634626016583, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5647.59262235135, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626016584, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0828092715231787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626016584, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5647.59262235135, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634626016658, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626016659, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626016673, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634626017071, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8860032558441162, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634626017071, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634626017259, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5600.557255560872, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626017259, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1026754966887418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626017259, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5600.557255560872, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634626017332, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626017333, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626017347, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634626017746, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8880544900894165, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634626017746, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634626017933, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5595.114079038264, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626017934, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1225417218543046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626017934, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5595.114079038264, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634626017993, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626017993, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626018008, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634626018407, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8652281761169434, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634626018407, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634626018590, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5627.054142511648, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626018591, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1424079470198676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626018591, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5627.054142511648, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634626018661, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626018662, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626018676, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634626019074, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8926184177398682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634626019074, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634626019261, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5604.6243039388255, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626019262, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1622741721854304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626019262, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5604.6243039388255, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634626019336, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626019336, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626019351, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634626019749, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8650350570678711, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634626019749, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634626019934, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5621.492093415095, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626019935, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1821403973509934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626019935, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5621.492093415095, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634626020010, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626020010, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626020025, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634626020422, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8616693019866943, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634626020422, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634626020615, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5552.036301132677, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626020616, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2020066225165562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626020616, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5552.036301132677, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634626020700, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626020701, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626020715, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634626021113, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8758156299591064, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634626021113, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634626021315, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5468.551326038755, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626021316, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2218728476821192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626021316, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5468.551326038755, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634626021386, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626021386, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626021400, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634626021799, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8824138641357422, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634626021799, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634626021997, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5499.601736413006, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626021998, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.241739072847682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626021998, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5499.601736413006, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634626022062, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626022063, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626022077, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634626022486, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8814404606819153, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634626022486, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634626022687, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5378.544172200595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626022688, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626022688, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5378.544172200595, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634626022756, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626022757, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626022771, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634626023170, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8840069770812988, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634626023170, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634626023353, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5636.423113841428, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626023353, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.281471523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626023353, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5636.423113841428, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634626023414, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626023414, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626023432, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634626023833, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8735463619232178, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634626023833, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634626024021, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5538.316638574619, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626024021, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3013377483443709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626024022, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5538.316638574619, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634626024087, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626024087, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626024102, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634626024509, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8868116736412048, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634626024509, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634626024707, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5421.398921633799, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626024707, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3212039735099337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626024708, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5421.398921633799, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634626024773, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626024774, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626024788, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634626025187, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8825112581253052, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634626025187, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634626025379, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5555.030120754999, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626025380, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3410701986754967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626025380, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5555.030120754999, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634626025448, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626025448, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626025464, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634626025862, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8873789310455322, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634626025862, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634626026056, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5536.006172041735, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626026056, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3609364238410595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626026056, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5536.006172041735, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634626026131, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626026131, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626026146, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634626026545, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8712303638458252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634626026545, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634626026737, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5549.205211177429, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626026737, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3808026490066225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626026738, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5549.205211177429, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634626026813, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626026813, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626026827, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634626027226, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8554214239120483, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634626027226, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634626027426, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5478.0680534106195, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626027427, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4006688741721853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626027427, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5478.0680534106195, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634626027492, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626027492, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626027507, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634626027906, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.44392839074134827, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634626027906, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634626028106, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5478.528040752905, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626028106, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4205350993377484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626028107, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5478.528040752905, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634626028173, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626028174, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626028188, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634626028587, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7517448663711548, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634626028588, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634626028779, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5557.255691087207, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626028779, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4404013245033112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626028779, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5557.255691087207, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634626028852, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626028853, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626028867, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634626029266, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7782059907913208, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634626029266, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634626029464, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5499.069538765056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626029464, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4602675496688742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626029465, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5499.069538765056, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634626029534, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626029535, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626029549, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634626029948, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8459934592247009, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634626029948, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634626030157, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5397.987805858979, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626030158, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4801337748344372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626030158, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5397.987805858979, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634626030233, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626030233, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626030247, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634626030646, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8774223327636719, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634626030646, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634626030843, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5504.123129847107, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626030844, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626030844, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5504.123129847107, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634626030918, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626030918, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626030933, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634626031332, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8673652410507202, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634626031333, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634626031519, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5591.355844716448, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626031520, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626031520, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5591.355844716448, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634626031596, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626031596, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626031611, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634626032011, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8677108287811279, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634626032011, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634626032201, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5557.332391131526, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626032202, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626032202, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5557.332391131526, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634626032280, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626032280, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626032295, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634626032694, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8875410556793213, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634626032694, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634626032913, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5307.645917445014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626032914, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626032914, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5307.645917445014, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634626032990, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626032990, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626033005, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634626033404, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8904924392700195, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634626033404, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634626033631, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5242.932663386127, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626033632, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626033632, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5242.932663386127, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634626033706, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626033707, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626033721, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634626034120, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8893395662307739, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634626034120, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634626034329, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5400.989548581982, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626034329, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626034329, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5400.989548581982, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634626034406, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626034407, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626034421, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634626034820, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8841931819915771, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634626034820, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634626035013, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5544.607298038654, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626035014, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626035014, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5544.607298038654, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634626035091, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626035092, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626035106, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634626035505, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8943446278572083, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634626035505, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634626035702, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5510.394482122225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626035702, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626035702, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5510.394482122225, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634626035771, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626035772, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626035786, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634626036186, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.894716203212738, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634626036186, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634626036376, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5564.261651188078, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626036376, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626036376, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5564.261651188078, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634626036441, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626036442, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626036456, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634626036856, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8911939859390259, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634626036856, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634626037039, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5624.502943184898, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626037040, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626037040, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5624.502943184898, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634626037099, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626037099, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626037114, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634626037513, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8919789791107178, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634626037513, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634626037697, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5619.1184440315465, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626037698, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626037698, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5619.1184440315465, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634626037766, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626037766, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626037781, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634626038180, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9000110626220703, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634626038180, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634626038372, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5546.545089883802, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626038373, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626038373, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5546.545089883802, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634626038447, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626038447, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626038462, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634626038860, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9009379148483276, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634626038861, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634626039043, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5640.9781847743725, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626039043, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626039043, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5640.9781847743725, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634626039116, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626039116, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626039131, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634626039530, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8881217241287231, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634626039530, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634626039721, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5558.941388545936, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626039721, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626039721, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5558.941388545936, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634626039793, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626039793, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626039807, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634626040207, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9000903367996216, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634626040207, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634626040396, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5566.773874102693, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626040397, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626040397, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5566.773874102693, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634626040473, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626040473, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626040487, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634626040888, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8918273448944092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634626040888, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634626041075, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5582.6887964043535, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626041076, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626041076, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5582.6887964043535, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634626041150, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626041151, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626041165, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634626041564, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8926129937171936, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634626041564, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634626041759, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5524.396071693591, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626041759, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626041760, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5524.396071693591, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634626041834, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626041834, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626041849, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634626042248, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9006690979003906, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634626042248, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634626042439, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5553.635667199455, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626042440, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626042440, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5553.635667199455, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634626042516, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626042516, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626042530, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634626042929, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8960543870925903, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634626042929, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634626043124, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5527.681014407884, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626043125, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626043125, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5527.681014407884, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634626043201, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626043202, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626043216, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634626043615, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8948318958282471, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634626043616, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634626043803, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5591.766274330553, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626043803, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626043804, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5591.766274330553, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634626043880, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626043881, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626043895, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634626044295, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9035124182701111, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634626044295, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634626044492, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5502.996919494109, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626044492, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626044492, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5502.996919494109, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634626044561, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626044561, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626044576, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634626044976, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.895456850528717, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634626044976, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634626045164, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5579.634170676009, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626045164, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626045164, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5579.634170676009, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634626045240, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626045240, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626045255, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634626045653, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8937661647796631, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634626045653, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634626045847, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5534.69515480647, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626045847, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626045848, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5534.69515480647, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634626045921, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626045921, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626045935, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634626046335, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8833634257316589, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634626046335, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634626046520, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5616.061879703593, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626046520, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626046520, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5616.061879703593, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634626046594, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626046595, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626046609, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634626047009, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.892049252986908, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634626047010, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634626047198, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5566.404481289975, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626047199, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626047199, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5566.404481289975, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634626047267, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626047267, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626047282, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634626047855, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8940167427062988, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634626047856, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634626048090, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4083.3179595320753, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626048091, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626048091, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4083.3179595320753, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634626048164, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626048164, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626048178, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634626048578, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9031362533569336, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634626048578, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634626048770, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5550.127457667702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626048770, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626048770, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5550.127457667702, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634626048846, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626048847, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626048861, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634626049261, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8992030620574951, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634626049261, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634626049447, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5595.08520152311, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626049448, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626049448, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5595.08520152311, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634626049523, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626049524, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626049538, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634626049938, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8893823623657227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634626049938, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634626050125, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5586.2781615719905, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626050126, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626050126, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5586.2781615719905, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634626050209, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626050209, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626050223, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634626050624, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8886188268661499, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634626050624, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634626050808, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5607.155266771201, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626050809, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626050809, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5607.155266771201, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634626050886, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626050886, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626050900, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634626051300, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8611421585083008, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634626051300, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634626051497, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5506.03917597307, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626051497, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626051497, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5506.03917597307, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634626051574, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626051575, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626051589, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634626051989, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8929237127304077, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634626051989, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634626052176, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5586.2183748079015, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626052177, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626052177, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5586.2183748079015, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634626052237, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626052237, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626052252, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634626052652, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8925937414169312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634626052652, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634626052833, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5643.2980281699165, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626052834, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626052834, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5643.2980281699165, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634626052900, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626052901, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626052915, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634626053315, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9002147912979126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634626053315, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634626053510, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5521.980362354871, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626053510, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626053510, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5521.980362354871, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634626053584, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626053585, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626053598, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634626053999, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9000381827354431, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634626053999, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634626054183, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5620.043906401601, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626054183, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626054183, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5620.043906401601, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634626054253, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626054253, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626054268, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634626054667, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8954129219055176, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634626054667, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634626054850, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5629.49521789792, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626054851, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626054851, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5629.49521789792, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634626054924, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626054924, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626054938, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634626055339, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8908859491348267, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634626055340, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634626055530, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5548.610939843851, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626055531, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626055531, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5548.610939843851, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634626055606, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626055607, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626055621, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634626056022, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8849918246269226, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634626056022, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634626056217, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5506.26290915456, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626056218, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626056218, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5506.26290915456, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634626056282, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626056283, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626056297, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634626056698, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8806167840957642, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634626056698, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634626056895, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5487.739763393655, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626056895, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626056896, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5487.739763393655, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634626056960, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626056961, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626056975, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634626057375, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8609360456466675, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634626057375, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634626057559, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5611.506724079028, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626057560, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626057560, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5611.506724079028, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634626057630, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626057631, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626057645, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634626058044, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.898315966129303, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634626058044, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634626058230, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5608.630299557052, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626058231, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626058231, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5608.630299557052, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634626058306, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626058306, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626058320, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634626058720, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8993474841117859, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634626058720, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634626058913, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5539.910286613475, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626058914, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626058914, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5539.910286613475, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634626058988, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626058988, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626059002, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634626059402, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8930191397666931, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634626059403, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634626059584, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5638.599334628334, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626059585, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626059585, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5638.599334628334, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634626059659, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626059660, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626059674, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634626060075, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8982809782028198, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634626060075, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634626060256, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5636.4253681230275, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626060257, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626060257, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5636.4253681230275, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634626060331, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626060332, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626060346, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634626060746, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9070481061935425, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634626060746, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634626060937, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5553.893927583101, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626060938, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626060938, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5553.893927583101, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634626061013, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626061014, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626061028, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634626061428, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8979908227920532, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634626061428, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634626061615, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5585.195555102877, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626061616, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626061616, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5585.195555102877, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634626061692, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626061692, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626061706, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634626062106, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9077212810516357, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634626062106, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634626062286, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5662.323797462556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626062286, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626062286, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5662.323797462556, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634626062362, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626062362, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634626062376, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634626062777, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.909909188747406, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634626062777, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634626062777, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 165, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1634626062967, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5555.489984212051, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634626062968, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634626062968, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5555.489984212051, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2420}}
ENDING TIMING RUN AT 2021-10-19 06:47:49 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:49 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:49 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:49 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:49 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:49 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:49 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:49 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:49 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:49 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:49 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:50 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:50 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:51 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:51 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
ENDING TIMING RUN AT 2021-10-19 06:47:52 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:53 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:53 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:53 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:53 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:53 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:53 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:53 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:53 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:53 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:53 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:53 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:53 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:54 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:55 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:55 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:55 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:55 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:56 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:57 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:58 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:47:59 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:00 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:01 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
ENDING TIMING RUN AT 2021-10-19 06:48:02 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:44:15 AM
